{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_merged = pd.read_csv('../../datasets/df_merged.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'AAPL', 'ADI', 'ADM', 'AIG', 'ALL', 'AMZN', 'ARE', 'AXP',\n",
       "       'BA', 'BAC', 'BEN', 'BX', 'C', 'CAG', 'CAT', 'CI', 'CMA', 'CME',\n",
       "       'CMS', 'COF', 'COO', 'COST', 'CRM', 'CSCO', 'CVS', 'CVX', 'D',\n",
       "       'DD', 'DIS', 'ED', 'EFX', 'ES', 'ETR', 'F', 'FCX', 'FMC', 'GE',\n",
       "       'GIS', 'GLW', 'GM', 'GOOG', 'GS', 'HAS', 'HD', 'HES', 'HIG', 'IBM',\n",
       "       'IP', 'ISRG', 'IT', 'JPM', 'K', 'KEY', 'L', 'LVS', 'MA', 'MAA',\n",
       "       'MCD', 'MDT', 'MGM', 'MSFT', 'NI', 'O', 'ORCL', 'PFE', 'PM', 'RL',\n",
       "       'SJM', 'SO', 'T', 'TXN', 'UPS', 'USB', 'V', 'VLO', 'VZ', 'WAB',\n",
       "       'WFC', 'WMT', 'ABBV', 'ABT', 'AMAT', 'BLK', 'CHTR', 'CMG', 'DAL',\n",
       "       'DE', 'FDX', 'GILD', 'GOOGL', 'GWW', 'HAL', 'HON', 'HPE', 'HPQ',\n",
       "       'JBHT', 'JNJ', 'MAR', 'MRK', 'MS', 'NFLX', 'NOW', 'PNC', 'QCOM',\n",
       "       'SBUX', 'SLB', 'TAP', 'TMO', 'TSLA', 'UAL', 'UNH', 'XOM', 'AEE',\n",
       "       'AMD', 'BMY', 'CB', 'CCL', 'DG', 'EBAY', 'ETSY', 'FAST', 'FIS',\n",
       "       'INTC', 'INTU', 'IRM', 'KEYS', 'KR', 'LIN', 'LLY', 'LMT', 'LYB',\n",
       "       'MMM', 'MOH', 'NCLH', 'NEE', 'NEM', 'PYPL', 'REGN', 'RSG', 'RTX',\n",
       "       'SPGI', 'TGT', 'TRGP', 'UBER', 'WRB', 'AAL', 'ACN', 'AMGN', 'APA',\n",
       "       'APD', 'APTV', 'AVGO', 'BBY', 'BIIB', 'BIO', 'BKNG', 'BWA', 'CAH',\n",
       "       'CLX', 'CMCSA', 'CMI', 'CNC', 'COP', 'CPB', 'CTVA', 'DHI', 'DOW',\n",
       "       'DRI', 'EMR', 'EXPE', 'GD', 'HCA', 'HUM', 'IVZ', 'KHC', 'KMI',\n",
       "       'KO', 'LHX', 'LOW', 'LULU', 'MCK', 'MRNA', 'MU', 'NOC', 'NUE',\n",
       "       'OKE', 'OXY', 'PEP', 'PG', 'PGR', 'PHM', 'RCL', 'SCHW', 'SPG',\n",
       "       'SYY', 'TMUS', 'TSCO', 'TSN', 'UNP', 'WBA', 'YUM', 'AKAM', 'AWK',\n",
       "       'BK', 'BSX', 'DPZ', 'DXCM', 'EA', 'INVH', 'KIM', 'MDLZ', 'MHK',\n",
       "       'MKTX', 'MPC', 'NVDA', 'STZ', 'TTWO', 'BKR', 'CDNS', 'CFG', 'CZR',\n",
       "       'DFS', 'EOG', 'EW', 'EXR', 'FANG', 'HBAN', 'INCY', 'JNPR', 'LYV',\n",
       "       'MCO', 'NSC', 'PXD', 'RF', 'STT', 'TJX', 'VRTX', 'AEP', 'CHRW',\n",
       "       'CNP', 'DHR', 'FOX', 'FOXA', 'ICE', 'KLAC', 'LRCX', 'LUV', 'MTB',\n",
       "       'PCAR', 'PEG', 'PSX', 'STLD', 'SWKS', 'TFC', 'ZION', 'FITB', 'LH',\n",
       "       'NTRS', 'PLD', 'PRU', 'SNA', 'SYF', 'TER', 'TRV', 'VTR', 'APH',\n",
       "       'BAX', 'BDX', 'CSX', 'DGX', 'DOV', 'FSLR', 'KMB', 'NDAQ', 'NKE',\n",
       "       'ORLY', 'REG', 'STX', 'TDY', 'VFC', 'ALLE', 'FE', 'FRT', 'HSY',\n",
       "       'IEX', 'ODFL', 'POOL', 'RHI', 'SHW', 'VRSN', 'WST', 'BLDR', 'CCI',\n",
       "       'EQR', 'FFIV', 'HST', 'ILMN', 'PODD', 'XEL', 'KDP', 'MRO', 'PKG',\n",
       "       'PPG', 'TROW', 'URI', 'WMB', 'CINF', 'COR', 'CSGP', 'DLR', 'DTE',\n",
       "       'ECL', 'EQIX', 'IQV', 'MPWR', 'MSCI', 'OMC', 'PAYC', 'ROK', 'ROP',\n",
       "       'SBAC', 'TEL', 'WAT', 'ZBRA', 'ADP', 'AFL', 'ALB', 'AVY', 'CE',\n",
       "       'ENPH', 'GRMN', 'HOLX', 'HRL', 'IFF', 'MAS', 'MNST', 'NXPI', 'PH',\n",
       "       'RJF', 'TPR', 'UHS', 'ZTS', 'ADBE', 'AJG', 'CHD', 'EIX', 'EMN',\n",
       "       'ETN', 'HUBB', 'LDOS', 'LEN', 'LKQ', 'MMC', 'MO', 'PSA', 'RMD',\n",
       "       'SWK', 'SYK', 'TECH', 'TXT', 'WDC', 'WHR', 'WRK', 'ADSK', 'AON',\n",
       "       'CL', 'CTLT', 'EL', 'JCI', 'PCG', 'WY', 'CTRA', 'AIZ', 'AME',\n",
       "       'ANET', 'AOS', 'DVA', 'DVN', 'EXPD', 'HSIC', 'ITW', 'MLM', 'ROL',\n",
       "       'TDG', 'VRSK', 'XYL', 'MET', 'AES', 'AMP', 'CRL', 'CTSH', 'FLT',\n",
       "       'HII', 'HLT', 'LNT', 'MSI', 'MTD', 'NRG', 'PWR', 'QRVO', 'EXC',\n",
       "       'IDXX', 'OTIS', 'PPL', 'XRAY', 'CARR', 'FTNT', 'NTAP', 'IR', 'KMX',\n",
       "       'ON', 'PNW', 'ZBH', 'BXP', 'STE', 'MKC', 'ROST', 'CTAS', 'JKHY',\n",
       "       'TYL', 'NVR', 'ULTA', 'CPRT', 'NDSN', 'SNPS', 'AZO', 'PANW', 'AMT',\n",
       "       'DLTR', 'GNRC', 'HWM', 'WM', 'MCHP', 'EVRG', 'FDS', 'PTC', 'CDW',\n",
       "       'DUK', 'SRE', 'EPAM', 'PFG', 'JBL', 'MTCH', 'CBOE', 'FTV', 'J',\n",
       "       'ANSS', 'PAYX', 'EQT', 'PNR', 'ALGN', 'WYNN', 'MOS', 'GL', 'IPG',\n",
       "       'FI', 'BRO', 'LW', 'UDR', 'ACGL', 'AVB', 'BG', 'FICO', 'TT',\n",
       "       'VICI', 'CPT', 'GPC', 'TFX', 'CBRE', 'BR', 'PEAK', 'VMC', 'WEC',\n",
       "       'NWSA', 'TRMB', 'AMCR', 'NWS', 'GPN', 'CF', 'WELL', 'GEN', 'ESS',\n",
       "       'VTRS', 'AXON', 'ATO', 'ABNB', 'EG', 'META', 'BBWI', 'WTW', 'PARA',\n",
       "       'CEG', 'WBD', 'BALL', 'ELV', 'GEHC', 'RVTY', 'KVUE'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['symbol'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'date', 'symbol', 'adj close', 'close', 'high', 'low', 'open',\n",
       "       'volume', 'lag_1', 'lag_2', 'lag_3', 'weekly_return', '5_day_ma',\n",
       "       '20_day_ma', '5_day_volatility', 'momentum', 'macd', 'macd_signal',\n",
       "       'macd_histogram', 'week_of_year', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_without_embeddings = df_merged.columns[~df_merged.columns.str.contains('embedding')]\n",
    "columns_without_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['title_embedding_0', 'title_embedding_1', 'title_embedding_2',\n",
       "        'title_embedding_3', 'title_embedding_4', 'title_embedding_5',\n",
       "        'title_embedding_6', 'title_embedding_7', 'title_embedding_8',\n",
       "        'title_embedding_9',\n",
       "        ...\n",
       "        'title_embedding_374', 'title_embedding_375', 'title_embedding_376',\n",
       "        'title_embedding_377', 'title_embedding_378', 'title_embedding_379',\n",
       "        'title_embedding_380', 'title_embedding_381', 'title_embedding_382',\n",
       "        'title_embedding_383'],\n",
       "       dtype='object', length=384),\n",
       " Index(['body_embedding_0', 'body_embedding_1', 'body_embedding_2',\n",
       "        'body_embedding_3', 'body_embedding_4', 'body_embedding_5',\n",
       "        'body_embedding_6', 'body_embedding_7', 'body_embedding_8',\n",
       "        'body_embedding_9',\n",
       "        ...\n",
       "        'body_embedding_374', 'body_embedding_375', 'body_embedding_376',\n",
       "        'body_embedding_377', 'body_embedding_378', 'body_embedding_379',\n",
       "        'body_embedding_380', 'body_embedding_381', 'body_embedding_382',\n",
       "        'body_embedding_383'],\n",
       "       dtype='object', length=384))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_title_embeddings = df_merged.columns[df_merged.columns.str.contains('title_embedding')]\n",
    "columns_body_embeddings = df_merged.columns[df_merged.columns.str.contains('body_embedding')]\n",
    "columns_title_embeddings, columns_body_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from sklearn.metrics import r2_score\n",
    "import plotly \n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects\n",
    "from IPython.display import clear_output\n",
    "# import wandb\n",
    "\n",
    "# Initialize wandb\n",
    "# wandb.init(project=\"stock-predictor\", entity=\"your_wandb_username\")\n",
    "\n",
    "# Класс модели с LSTM\n",
    "class StockPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout_prob=0.5):\n",
    "        super(StockPredictor, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_dim, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(128)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(64)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Изменим форму входного тензора\n",
    "        x = x.unsqueeze(1)  # Добавляем размерность для sequence_length, чтобы стало (batch_size, sequence_length, input_dim)\n",
    "        \n",
    "        # Инициализация скрытых состояний\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Получение только последнего выходного состояния\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        # Полносвязные слои с нормализацией и дроп-аутом\n",
    "        out = self.fc1(out)\n",
    "        out = self.batch_norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.batch_norm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "def plot_losses(train_losses: List[float], val_losses: List[float]):\n",
    "    \"\"\"\n",
    "    Plot loss and perplexity of train and validation samples using plotly\n",
    "    :param train_losses: list of train losses at each epoch\n",
    "    :param val_losses: list of validation losses at each epoch\n",
    "    \"\"\"\n",
    "    clear_output()\n",
    "    fig = make_subplots(rows=1, cols=1)\n",
    "    fig.add_trace(plotly.graph_objects.Scatter(y=train_losses, mode='lines', name='train'), row=1, col=1)\n",
    "    fig.add_trace(plotly.graph_objects.Scatter(y=val_losses, mode='lines', name='validation'), row=1, col=1)\n",
    "    fig.update_layout(title='Losses', xaxis_title='Epoch', yaxis_title='Loss')\n",
    "    fig.show()\n",
    "# Метод обучения\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in tqdm(train_loader):\n",
    "            inputs = inputs.to(model.device)\n",
    "            targets = targets.to(model.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_mae = 0.0\n",
    "        val_r2 = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(val_loader):\n",
    "                inputs = inputs.to(model.device)\n",
    "                targets = targets.to(model.device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), targets)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_mae += torch.nn.functional.l1_loss(outputs.squeeze(), targets, reduction='sum').item()\n",
    "\n",
    "                val_r2 += r2_score(outputs.squeeze(), targets).item() * inputs.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_mae /= len(val_loader.dataset)\n",
    "        val_r2 /= len(val_loader.dataset)\n",
    "\n",
    "        val_losses.append(val_loss)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        # plot\n",
    "        plot_losses(train_losses, val_losses)\n",
    "        # Log metrics to wandb\n",
    "        # wandb.log({\"epoch\": epoch+1, \"training_loss\": epoch_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "    print(f\"Training complete. Final training loss: {train_losses[-1]}, final validation loss: {val_losses[-1]}\")\n",
    "    print(f\"Final validation MAE: {val_mae}, final validation R2: {val_r2}\")\n",
    "    return model\n",
    "\n",
    "# Пример данных\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_test = columns_without_embeddings.to_list() + columns_title_embeddings.to_list()\n",
    "columns_to_test = [item for item in columns_to_test if item not in ['index', 'date', 'title', 'body', 'symbol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize weekly_return\n",
    "def normalize(data, mean, std, eps=1e-6):\n",
    "    return (data - mean) / (std + eps)\n",
    "def denormalize(data, mean, std):\n",
    "    return data * std + mean\n",
    "\n",
    "targets = df_merged['weekly_return'].values\n",
    "targets = torch.from_numpy(targets).to(dtype=torch.float)\n",
    "combined_features = df_merged[columns_to_test].values\n",
    "combined_features = torch.from_numpy(combined_features).to(dtype=torch.float)\n",
    "\n",
    "targets_mean = targets.mean()\n",
    "targets_std = targets.std()\n",
    "targets_normalized = normalize(targets, targets_mean, targets_std)\n",
    "features_mean, features_std = combined_features.mean(axis=0), combined_features.std(axis=0)\n",
    "features_normalized = normalize(combined_features, features_mean, features_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>weekly_return</th>\n",
       "      <th>...</th>\n",
       "      <th>title_embedding_374</th>\n",
       "      <th>title_embedding_375</th>\n",
       "      <th>title_embedding_376</th>\n",
       "      <th>title_embedding_377</th>\n",
       "      <th>title_embedding_378</th>\n",
       "      <th>title_embedding_379</th>\n",
       "      <th>title_embedding_380</th>\n",
       "      <th>title_embedding_381</th>\n",
       "      <th>title_embedding_382</th>\n",
       "      <th>title_embedding_383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.517937</td>\n",
       "      <td>27.174536</td>\n",
       "      <td>27.360516</td>\n",
       "      <td>26.909870</td>\n",
       "      <td>27.181688</td>\n",
       "      <td>3521842.0</td>\n",
       "      <td>26.938484</td>\n",
       "      <td>27.918455</td>\n",
       "      <td>27.982834</td>\n",
       "      <td>-0.076792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004133</td>\n",
       "      <td>0.008691</td>\n",
       "      <td>-0.042434</td>\n",
       "      <td>-0.002215</td>\n",
       "      <td>-0.043523</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.038139</td>\n",
       "      <td>-0.136477</td>\n",
       "      <td>-0.011128</td>\n",
       "      <td>0.057885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.295727</td>\n",
       "      <td>20.429644</td>\n",
       "      <td>20.517500</td>\n",
       "      <td>20.261786</td>\n",
       "      <td>20.404642</td>\n",
       "      <td>276536400.0</td>\n",
       "      <td>20.384644</td>\n",
       "      <td>20.789286</td>\n",
       "      <td>20.631071</td>\n",
       "      <td>-0.026183</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016463</td>\n",
       "      <td>-0.029878</td>\n",
       "      <td>-0.049738</td>\n",
       "      <td>-0.050536</td>\n",
       "      <td>-0.057034</td>\n",
       "      <td>0.036203</td>\n",
       "      <td>0.049257</td>\n",
       "      <td>-0.144588</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.051053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.117611</td>\n",
       "      <td>36.630001</td>\n",
       "      <td>37.070000</td>\n",
       "      <td>36.230000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>2434700.0</td>\n",
       "      <td>36.959999</td>\n",
       "      <td>37.730000</td>\n",
       "      <td>37.320000</td>\n",
       "      <td>-0.036053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024606</td>\n",
       "      <td>-0.001802</td>\n",
       "      <td>-0.047134</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>-0.075411</td>\n",
       "      <td>0.044010</td>\n",
       "      <td>0.091576</td>\n",
       "      <td>-0.203208</td>\n",
       "      <td>-0.010621</td>\n",
       "      <td>0.068538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.902025</td>\n",
       "      <td>28.629999</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>28.549999</td>\n",
       "      <td>28.780001</td>\n",
       "      <td>4786800.0</td>\n",
       "      <td>28.790001</td>\n",
       "      <td>29.280001</td>\n",
       "      <td>29.379999</td>\n",
       "      <td>-0.050415</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018906</td>\n",
       "      <td>0.022677</td>\n",
       "      <td>-0.068706</td>\n",
       "      <td>-0.022873</td>\n",
       "      <td>-0.106041</td>\n",
       "      <td>-0.014542</td>\n",
       "      <td>0.013619</td>\n",
       "      <td>-0.174847</td>\n",
       "      <td>-0.051576</td>\n",
       "      <td>0.097726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.347980</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>31.240000</td>\n",
       "      <td>30.370001</td>\n",
       "      <td>31.020000</td>\n",
       "      <td>13756800.0</td>\n",
       "      <td>30.629999</td>\n",
       "      <td>31.440001</td>\n",
       "      <td>31.040001</td>\n",
       "      <td>-0.035692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006847</td>\n",
       "      <td>-0.006129</td>\n",
       "      <td>-0.050931</td>\n",
       "      <td>-0.134466</td>\n",
       "      <td>-0.052448</td>\n",
       "      <td>-0.029073</td>\n",
       "      <td>-0.009584</td>\n",
       "      <td>-0.111398</td>\n",
       "      <td>0.087133</td>\n",
       "      <td>0.026309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 403 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adj close      close       high        low       open       volume  \\\n",
       "0  24.517937  27.174536  27.360516  26.909870  27.181688    3521842.0   \n",
       "1  17.295727  20.429644  20.517500  20.261786  20.404642  276536400.0   \n",
       "2  28.117611  36.630001  37.070000  36.230000  37.000000    2434700.0   \n",
       "3  20.902025  28.629999  29.000000  28.549999  28.780001    4786800.0   \n",
       "4  24.347980  30.799999  31.240000  30.370001  31.020000   13756800.0   \n",
       "\n",
       "       lag_1      lag_2      lag_3  weekly_return  ...  title_embedding_374  \\\n",
       "0  26.938484  27.918455  27.982834      -0.076792  ...            -0.004133   \n",
       "1  20.384644  20.789286  20.631071      -0.026183  ...            -0.016463   \n",
       "2  36.959999  37.730000  37.320000      -0.036053  ...            -0.024606   \n",
       "3  28.790001  29.280001  29.379999      -0.050415  ...            -0.018906   \n",
       "4  30.629999  31.440001  31.040001      -0.035692  ...            -0.006847   \n",
       "\n",
       "   title_embedding_375  title_embedding_376  title_embedding_377  \\\n",
       "0             0.008691            -0.042434            -0.002215   \n",
       "1            -0.029878            -0.049738            -0.050536   \n",
       "2            -0.001802            -0.047134             0.003014   \n",
       "3             0.022677            -0.068706            -0.022873   \n",
       "4            -0.006129            -0.050931            -0.134466   \n",
       "\n",
       "   title_embedding_378  title_embedding_379  title_embedding_380  \\\n",
       "0            -0.043523             0.006658             0.038139   \n",
       "1            -0.057034             0.036203             0.049257   \n",
       "2            -0.075411             0.044010             0.091576   \n",
       "3            -0.106041            -0.014542             0.013619   \n",
       "4            -0.052448            -0.029073            -0.009584   \n",
       "\n",
       "   title_embedding_381  title_embedding_382  title_embedding_383  \n",
       "0            -0.136477            -0.011128             0.057885  \n",
       "1            -0.144588             0.004800             0.051053  \n",
       "2            -0.203208            -0.010621             0.068538  \n",
       "3            -0.174847            -0.051576             0.097726  \n",
       "4            -0.111398             0.087133             0.026309  \n",
       "\n",
       "[5 rows x 403 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[columns_to_test].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, val_features, train_targets, val_targets = train_test_split(features_normalized, targets_normalized, test_size=0.2, random_state=42)\n",
    "train_dataset = StockDataset(train_features, train_targets)\n",
    "val_dataset = StockDataset(val_features, val_targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = train_features.size(1)\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "output_dim = 1\n",
    "model = StockPredictor(input_dim, hidden_dim, num_layers, output_dim)\n",
    "\n",
    "model.load_state_dict(torch.load('../models/dl_average_pooling.pt', map_location=torch.device('cpu'), weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StockPredictor(\n",
       "  (lstm): LSTM(403, 128, num_layers=2, batch_first=True)\n",
       "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (batch_norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch_norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "train",
         "type": "scatter",
         "xaxis": "x",
         "y": [
          0.26746434485150744,
          0.1290811167706908,
          0.11526840792935962,
          0.11805466017468037,
          0.11070977071256727,
          0.1069521329286153,
          0.10956066711182447,
          0.10030357045365816,
          0.09855400109317765,
          0.09352332703015036,
          0.0896362714083614,
          0.09137535822347803,
          0.08750100268197554,
          0.08699484539709632,
          0.08610364991266628,
          0.08308302882889991,
          0.08444964764865309,
          0.0847174285980781,
          0.08358195355667172,
          0.07942838555620735,
          0.08306064529622471,
          0.07980487420757312,
          0.08148506870078857,
          0.07590732443302647,
          0.07769932389845319,
          0.07740471481946215,
          0.07760710421715075,
          0.07653315137836138,
          0.07723123920480002,
          0.07573305901240115,
          0.07556107073625354,
          0.07561239070140113,
          0.07637780991119807,
          0.07326848255745225,
          0.07287712963742012,
          0.07494453242537331,
          0.07268251147338697,
          0.07115731966611356,
          0.07228358394614301,
          0.07073766761178009,
          0.06956217219194805,
          0.07047901473088128,
          0.07026774603997686,
          0.07048556217784609,
          0.06761746500031612,
          0.0682372184807011,
          0.06983765601020114,
          0.07022488642612013,
          0.06764370955026304,
          0.06956687331503272
         ],
         "yaxis": "y"
        },
        {
         "mode": "lines",
         "name": "validation",
         "type": "scatter",
         "xaxis": "x",
         "y": [
          0.06243998804859985,
          0.06494656036111832,
          0.04601855544347649,
          0.0714923921083191,
          0.056245569925580975,
          0.0384473090494745,
          0.035663040521278534,
          0.036758923134891916,
          0.03896295730222552,
          0.04036322527308648,
          0.0396834537401398,
          0.03164524181211906,
          0.028747213302898953,
          0.04879771779450812,
          0.05607961777755515,
          0.02314025173168604,
          0.0324021440423456,
          0.04500111149316148,
          0.030799142779081037,
          0.039660554203608436,
          0.03841358721696204,
          0.0410761626014401,
          0.05324450423009754,
          0.07290754689760741,
          0.02768348335916901,
          0.0354355745464486,
          0.03638184176899706,
          0.035758330127928124,
          0.04636850208841759,
          0.03558994567765166,
          0.059415826862471856,
          0.030420893169666365,
          0.04828083164357584,
          0.03774658735266439,
          0.04037428849498388,
          0.04642670723051171,
          0.038880069714191126,
          0.03223286687837804,
          0.044429103060967,
          0.036497311239170015,
          0.047091493831216094,
          0.02694756837728399,
          0.03691972411920482,
          0.0322402841718225,
          0.0318148356072697,
          0.05320539538221653,
          0.044818849074696285,
          0.06229641568997417,
          0.09753020673731116,
          0.02506735268079823
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Losses"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Final training loss: 0.06956687331503272, final validation loss: 0.02506735268079823\n",
      "Final validation MAE: 0.09179490159158309, final validation R2: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StockPredictor(\n",
       "  (lstm): LSTM(403, 128, num_layers=2, batch_first=True)\n",
       "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (batch_norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch_norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = StockPredictor(input_dim, hidden_dim, num_layers, output_dim)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.device = device\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 8.228811202570796e-05\n",
      "mae 0.005259359255433083\n",
      "r2-score: 0.9681331409876758\n",
      "Have same sign: 0.971124529838562\n",
      "Example of predcitions: [-0.07886821776628494, -0.018322942778468132, 0.023021450266242027, -0.18347500264644623, 0.004382627084851265, -0.016448847949504852, -0.007681734394282103, 0.04562047868967056, 0.06402567774057388, 0.008089784532785416]\n",
      "True values: [-0.0856386348605156, -0.02415516786277294, 0.02146715112030506, -0.18781840801239014, 0.006663176231086254, -0.028289422392845154, -0.010420558974146843, 0.0445161834359169, 0.062368981540203094, 0.010641969740390778]\n"
     ]
    }
   ],
   "source": [
    "# calculate mse mae r2\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_mae = 0.0\n",
    "test_r2 = 0.0\n",
    "with torch.no_grad():\n",
    "    val_features = val_features.to(device)\n",
    "    val_targets = val_targets.to(device)\n",
    "    outputs = model(val_features)\n",
    "    denormalized_outputs = denormalize(outputs.squeeze(), targets_mean, targets_std)\n",
    "    denormalized_targets = denormalize(val_targets.squeeze(), targets_mean, targets_std)\n",
    "    loss = criterion(denormalized_outputs, denormalized_targets)\n",
    "    test_loss += loss.item() * val_features.size(0)\n",
    "    print('mse', loss.item())\n",
    "    test_mae += torch.nn.functional.l1_loss(denormalized_outputs, denormalized_targets).item()\n",
    "    print('mae', test_mae)\n",
    "    test_r2 += r2_score(denormalized_outputs.cpu().numpy(), denormalized_targets.cpu().numpy())\n",
    "    # calculate that true and predicted values both bigger or less than 0\n",
    "    our_metric = ((denormalized_outputs > 0) == (denormalized_targets > 0)).sum() / len(denormalized_targets)\n",
    "    print('r2-score:', test_r2)\n",
    "    print('Have same sign:', our_metric.item())\n",
    "    print('Example of predcitions:', denormalized_outputs[:10].tolist())\n",
    "    print('True values:', denormalized_targets[:10].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "historical_data_df = pd.read_csv('../../datasets/sp500_historical_data.csv')\n",
    "title_embeddings_df = pd.read_csv('../../datasets/all-MiniLM-L6-v2-embedding-news-title.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "title_embeddings_df['date'] = pd.to_datetime(title_embeddings_df['created'])\n",
    "title_embeddings_df['stocks'] = title_embeddings_df['stocks'].apply(ast.literal_eval)\n",
    "title_embeddings_df = title_embeddings_df.explode('stocks').reset_index(drop=True)\n",
    "title_embeddings_df['date'] = title_embeddings_df['date'].dt.date\n",
    "title_embeddings_df['stocks'] = title_embeddings_df['stocks'].apply(lambda x: x['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>A</td>\n",
       "      <td>20.154915</td>\n",
       "      <td>22.389128</td>\n",
       "      <td>22.625179</td>\n",
       "      <td>22.267525</td>\n",
       "      <td>22.453505</td>\n",
       "      <td>3815561.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>A</td>\n",
       "      <td>19.935982</td>\n",
       "      <td>22.145924</td>\n",
       "      <td>22.331903</td>\n",
       "      <td>22.002861</td>\n",
       "      <td>22.324751</td>\n",
       "      <td>4186031.0</td>\n",
       "      <td>2010-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>A</td>\n",
       "      <td>19.865147</td>\n",
       "      <td>22.067240</td>\n",
       "      <td>22.174536</td>\n",
       "      <td>22.002861</td>\n",
       "      <td>22.067240</td>\n",
       "      <td>3243779.0</td>\n",
       "      <td>2010-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>A</td>\n",
       "      <td>19.839396</td>\n",
       "      <td>22.038628</td>\n",
       "      <td>22.045780</td>\n",
       "      <td>21.816881</td>\n",
       "      <td>22.017166</td>\n",
       "      <td>3095172.0</td>\n",
       "      <td>2010-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>A</td>\n",
       "      <td>19.832952</td>\n",
       "      <td>22.031473</td>\n",
       "      <td>22.067240</td>\n",
       "      <td>21.745352</td>\n",
       "      <td>21.917025</td>\n",
       "      <td>3733918.0</td>\n",
       "      <td>2010-01-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Symbol  Adj Close      Close       High        Low       Open  \\\n",
       "0  2010-01-04      A  20.154915  22.389128  22.625179  22.267525  22.453505   \n",
       "1  2010-01-05      A  19.935982  22.145924  22.331903  22.002861  22.324751   \n",
       "2  2010-01-06      A  19.865147  22.067240  22.174536  22.002861  22.067240   \n",
       "3  2010-01-07      A  19.839396  22.038628  22.045780  21.816881  22.017166   \n",
       "4  2010-01-08      A  19.832952  22.031473  22.067240  21.745352  21.917025   \n",
       "\n",
       "      Volume        date  \n",
       "0  3815561.0  2010-01-04  \n",
       "1  4186031.0  2010-01-05  \n",
       "2  3243779.0  2010-01-06  \n",
       "3  3095172.0  2010-01-07  \n",
       "4  3733918.0  2010-01-08  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_data_df['date'] = pd.to_datetime(historical_data_df['Date'])\n",
    "historical_data_df['date'] = historical_data_df['date'].dt.date\n",
    "historical_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stocks</th>\n",
       "      <th>title_embedding_0</th>\n",
       "      <th>title_embedding_1</th>\n",
       "      <th>title_embedding_2</th>\n",
       "      <th>title_embedding_3</th>\n",
       "      <th>title_embedding_4</th>\n",
       "      <th>title_embedding_5</th>\n",
       "      <th>title_embedding_6</th>\n",
       "      <th>title_embedding_7</th>\n",
       "      <th>title_embedding_8</th>\n",
       "      <th>...</th>\n",
       "      <th>title_embedding_375</th>\n",
       "      <th>title_embedding_376</th>\n",
       "      <th>title_embedding_377</th>\n",
       "      <th>title_embedding_378</th>\n",
       "      <th>title_embedding_379</th>\n",
       "      <th>title_embedding_380</th>\n",
       "      <th>title_embedding_381</th>\n",
       "      <th>title_embedding_382</th>\n",
       "      <th>title_embedding_383</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIT</td>\n",
       "      <td>0.027524</td>\n",
       "      <td>-0.028871</td>\n",
       "      <td>-0.060342</td>\n",
       "      <td>0.053199</td>\n",
       "      <td>0.046198</td>\n",
       "      <td>-0.037971</td>\n",
       "      <td>0.135296</td>\n",
       "      <td>-0.022271</td>\n",
       "      <td>0.029455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019922</td>\n",
       "      <td>-0.055372</td>\n",
       "      <td>0.011424</td>\n",
       "      <td>-0.067690</td>\n",
       "      <td>-0.015036</td>\n",
       "      <td>0.037755</td>\n",
       "      <td>-0.089164</td>\n",
       "      <td>-0.005867</td>\n",
       "      <td>-0.016719</td>\n",
       "      <td>2009-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CME</td>\n",
       "      <td>0.027524</td>\n",
       "      <td>-0.028871</td>\n",
       "      <td>-0.060342</td>\n",
       "      <td>0.053199</td>\n",
       "      <td>0.046198</td>\n",
       "      <td>-0.037971</td>\n",
       "      <td>0.135296</td>\n",
       "      <td>-0.022271</td>\n",
       "      <td>0.029455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019922</td>\n",
       "      <td>-0.055372</td>\n",
       "      <td>0.011424</td>\n",
       "      <td>-0.067690</td>\n",
       "      <td>-0.015036</td>\n",
       "      <td>0.037755</td>\n",
       "      <td>-0.089164</td>\n",
       "      <td>-0.005867</td>\n",
       "      <td>-0.016719</td>\n",
       "      <td>2009-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISRG</td>\n",
       "      <td>0.027524</td>\n",
       "      <td>-0.028871</td>\n",
       "      <td>-0.060342</td>\n",
       "      <td>0.053199</td>\n",
       "      <td>0.046198</td>\n",
       "      <td>-0.037971</td>\n",
       "      <td>0.135296</td>\n",
       "      <td>-0.022271</td>\n",
       "      <td>0.029455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019922</td>\n",
       "      <td>-0.055372</td>\n",
       "      <td>0.011424</td>\n",
       "      <td>-0.067690</td>\n",
       "      <td>-0.015036</td>\n",
       "      <td>0.037755</td>\n",
       "      <td>-0.089164</td>\n",
       "      <td>-0.005867</td>\n",
       "      <td>-0.016719</td>\n",
       "      <td>2009-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.027524</td>\n",
       "      <td>-0.028871</td>\n",
       "      <td>-0.060342</td>\n",
       "      <td>0.053199</td>\n",
       "      <td>0.046198</td>\n",
       "      <td>-0.037971</td>\n",
       "      <td>0.135296</td>\n",
       "      <td>-0.022271</td>\n",
       "      <td>0.029455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019922</td>\n",
       "      <td>-0.055372</td>\n",
       "      <td>0.011424</td>\n",
       "      <td>-0.067690</td>\n",
       "      <td>-0.015036</td>\n",
       "      <td>0.037755</td>\n",
       "      <td>-0.089164</td>\n",
       "      <td>-0.005867</td>\n",
       "      <td>-0.016719</td>\n",
       "      <td>2009-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.021890</td>\n",
       "      <td>-0.027628</td>\n",
       "      <td>0.035083</td>\n",
       "      <td>0.050099</td>\n",
       "      <td>0.067462</td>\n",
       "      <td>0.026903</td>\n",
       "      <td>0.029803</td>\n",
       "      <td>0.023311</td>\n",
       "      <td>0.047869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030781</td>\n",
       "      <td>-0.083482</td>\n",
       "      <td>-0.012103</td>\n",
       "      <td>-0.065227</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>-0.005367</td>\n",
       "      <td>-0.121527</td>\n",
       "      <td>-0.053555</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>2009-07-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  stocks  title_embedding_0  title_embedding_1  title_embedding_2  \\\n",
       "0    CIT           0.027524          -0.028871          -0.060342   \n",
       "1    CME           0.027524          -0.028871          -0.060342   \n",
       "2   ISRG           0.027524          -0.028871          -0.060342   \n",
       "3   MSFT           0.027524          -0.028871          -0.060342   \n",
       "4   AAPL           0.021890          -0.027628           0.035083   \n",
       "\n",
       "   title_embedding_3  title_embedding_4  title_embedding_5  title_embedding_6  \\\n",
       "0           0.053199           0.046198          -0.037971           0.135296   \n",
       "1           0.053199           0.046198          -0.037971           0.135296   \n",
       "2           0.053199           0.046198          -0.037971           0.135296   \n",
       "3           0.053199           0.046198          -0.037971           0.135296   \n",
       "4           0.050099           0.067462           0.026903           0.029803   \n",
       "\n",
       "   title_embedding_7  title_embedding_8  ...  title_embedding_375  \\\n",
       "0          -0.022271           0.029455  ...            -0.019922   \n",
       "1          -0.022271           0.029455  ...            -0.019922   \n",
       "2          -0.022271           0.029455  ...            -0.019922   \n",
       "3          -0.022271           0.029455  ...            -0.019922   \n",
       "4           0.023311           0.047869  ...            -0.030781   \n",
       "\n",
       "   title_embedding_376  title_embedding_377  title_embedding_378  \\\n",
       "0            -0.055372             0.011424            -0.067690   \n",
       "1            -0.055372             0.011424            -0.067690   \n",
       "2            -0.055372             0.011424            -0.067690   \n",
       "3            -0.055372             0.011424            -0.067690   \n",
       "4            -0.083482            -0.012103            -0.065227   \n",
       "\n",
       "   title_embedding_379  title_embedding_380  title_embedding_381  \\\n",
       "0            -0.015036             0.037755            -0.089164   \n",
       "1            -0.015036             0.037755            -0.089164   \n",
       "2            -0.015036             0.037755            -0.089164   \n",
       "3            -0.015036             0.037755            -0.089164   \n",
       "4             0.015232            -0.005367            -0.121527   \n",
       "\n",
       "   title_embedding_382  title_embedding_383        date  \n",
       "0            -0.005867            -0.016719  2009-07-27  \n",
       "1            -0.005867            -0.016719  2009-07-27  \n",
       "2            -0.005867            -0.016719  2009-07-27  \n",
       "3            -0.005867            -0.016719  2009-07-27  \n",
       "4            -0.053555             0.001270  2009-07-27  \n",
       "\n",
       "[5 rows x 386 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_data_df.drop('Date', inplace=True, axis=1)\n",
    "title_embeddings_df.drop('created', inplace=True, axis=1)\n",
    "title_embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>20.154915</td>\n",
       "      <td>22.389128</td>\n",
       "      <td>22.625179</td>\n",
       "      <td>22.267525</td>\n",
       "      <td>22.453505</td>\n",
       "      <td>3815561.0</td>\n",
       "      <td>2010-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>19.935982</td>\n",
       "      <td>22.145924</td>\n",
       "      <td>22.331903</td>\n",
       "      <td>22.002861</td>\n",
       "      <td>22.324751</td>\n",
       "      <td>4186031.0</td>\n",
       "      <td>2010-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>19.865147</td>\n",
       "      <td>22.067240</td>\n",
       "      <td>22.174536</td>\n",
       "      <td>22.002861</td>\n",
       "      <td>22.067240</td>\n",
       "      <td>3243779.0</td>\n",
       "      <td>2010-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>19.839396</td>\n",
       "      <td>22.038628</td>\n",
       "      <td>22.045780</td>\n",
       "      <td>21.816881</td>\n",
       "      <td>22.017166</td>\n",
       "      <td>3095172.0</td>\n",
       "      <td>2010-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>19.832952</td>\n",
       "      <td>22.031473</td>\n",
       "      <td>22.067240</td>\n",
       "      <td>21.745352</td>\n",
       "      <td>21.917025</td>\n",
       "      <td>3733918.0</td>\n",
       "      <td>2010-01-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol  Adj Close      Close       High        Low       Open     Volume  \\\n",
       "0      A  20.154915  22.389128  22.625179  22.267525  22.453505  3815561.0   \n",
       "1      A  19.935982  22.145924  22.331903  22.002861  22.324751  4186031.0   \n",
       "2      A  19.865147  22.067240  22.174536  22.002861  22.067240  3243779.0   \n",
       "3      A  19.839396  22.038628  22.045780  21.816881  22.017166  3095172.0   \n",
       "4      A  19.832952  22.031473  22.067240  21.745352  21.917025  3733918.0   \n",
       "\n",
       "         date  \n",
       "0  2010-01-04  \n",
       "1  2010-01-05  \n",
       "2  2010-01-06  \n",
       "3  2010-01-07  \n",
       "4  2010-01-08  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/ps3k66h11hjf_56rkxfbt3tm0000gn/T/ipykernel_51978/709461921.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_stocks = historical_data_df.groupby('Symbol').apply(apply_features)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>...</th>\n",
       "      <th>weekly_return</th>\n",
       "      <th>5_day_MA</th>\n",
       "      <th>20_day_MA</th>\n",
       "      <th>5_day_volatility</th>\n",
       "      <th>momentum</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_signal</th>\n",
       "      <th>MACD_histogram</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-22</td>\n",
       "      <td>A</td>\n",
       "      <td>20.058334</td>\n",
       "      <td>22.281832</td>\n",
       "      <td>22.381973</td>\n",
       "      <td>22.067240</td>\n",
       "      <td>22.381973</td>\n",
       "      <td>4038123.0</td>\n",
       "      <td>22.317596</td>\n",
       "      <td>22.160229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039026</td>\n",
       "      <td>22.061516</td>\n",
       "      <td>21.189199</td>\n",
       "      <td>0.285560</td>\n",
       "      <td>-0.035765</td>\n",
       "      <td>0.115873</td>\n",
       "      <td>-0.086697</td>\n",
       "      <td>0.202570</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-23</td>\n",
       "      <td>A</td>\n",
       "      <td>19.865147</td>\n",
       "      <td>22.067240</td>\n",
       "      <td>22.288984</td>\n",
       "      <td>21.838341</td>\n",
       "      <td>22.238913</td>\n",
       "      <td>4366373.0</td>\n",
       "      <td>22.281832</td>\n",
       "      <td>22.317596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019835</td>\n",
       "      <td>22.147353</td>\n",
       "      <td>21.239270</td>\n",
       "      <td>0.165868</td>\n",
       "      <td>-0.214592</td>\n",
       "      <td>0.139780</td>\n",
       "      <td>-0.041401</td>\n",
       "      <td>0.181181</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-24</td>\n",
       "      <td>A</td>\n",
       "      <td>20.109842</td>\n",
       "      <td>22.339056</td>\n",
       "      <td>22.346209</td>\n",
       "      <td>22.074392</td>\n",
       "      <td>22.153076</td>\n",
       "      <td>3945855.0</td>\n",
       "      <td>22.067240</td>\n",
       "      <td>22.281832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019589</td>\n",
       "      <td>22.233191</td>\n",
       "      <td>21.308655</td>\n",
       "      <td>0.115716</td>\n",
       "      <td>0.271816</td>\n",
       "      <td>0.178601</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.176002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-25</td>\n",
       "      <td>A</td>\n",
       "      <td>20.019684</td>\n",
       "      <td>22.238913</td>\n",
       "      <td>22.267525</td>\n",
       "      <td>21.623749</td>\n",
       "      <td>22.060085</td>\n",
       "      <td>4778504.0</td>\n",
       "      <td>22.339056</td>\n",
       "      <td>22.067240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>22.248927</td>\n",
       "      <td>21.377325</td>\n",
       "      <td>0.108434</td>\n",
       "      <td>-0.100143</td>\n",
       "      <td>0.198992</td>\n",
       "      <td>0.041878</td>\n",
       "      <td>0.157114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>A</td>\n",
       "      <td>20.257940</td>\n",
       "      <td>22.503576</td>\n",
       "      <td>22.546495</td>\n",
       "      <td>22.160229</td>\n",
       "      <td>22.296137</td>\n",
       "      <td>4678127.0</td>\n",
       "      <td>22.238913</td>\n",
       "      <td>22.339056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>22.286123</td>\n",
       "      <td>21.476395</td>\n",
       "      <td>0.158307</td>\n",
       "      <td>0.264664</td>\n",
       "      <td>0.233813</td>\n",
       "      <td>0.080265</td>\n",
       "      <td>0.153548</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Symbol  Adj Close      Close       High        Low       Open  \\\n",
       "0  2010-02-22      A  20.058334  22.281832  22.381973  22.067240  22.381973   \n",
       "1  2010-02-23      A  19.865147  22.067240  22.288984  21.838341  22.238913   \n",
       "2  2010-02-24      A  20.109842  22.339056  22.346209  22.074392  22.153076   \n",
       "3  2010-02-25      A  20.019684  22.238913  22.267525  21.623749  22.060085   \n",
       "4  2010-02-26      A  20.257940  22.503576  22.546495  22.160229  22.296137   \n",
       "\n",
       "      Volume      lag_1      lag_2  ...  weekly_return   5_day_MA  20_day_MA  \\\n",
       "0  4038123.0  22.317596  22.160229  ...       0.039026  22.061516  21.189199   \n",
       "1  4366373.0  22.281832  22.317596  ...       0.019835  22.147353  21.239270   \n",
       "2  3945855.0  22.067240  22.281832  ...       0.019589  22.233191  21.308655   \n",
       "3  4778504.0  22.339056  22.067240  ...       0.003551  22.248927  21.377325   \n",
       "4  4678127.0  22.238913  22.339056  ...       0.008333  22.286123  21.476395   \n",
       "\n",
       "   5_day_volatility  momentum      MACD  MACD_signal  MACD_histogram  \\\n",
       "0          0.285560 -0.035765  0.115873    -0.086697        0.202570   \n",
       "1          0.165868 -0.214592  0.139780    -0.041401        0.181181   \n",
       "2          0.115716  0.271816  0.178601     0.002599        0.176002   \n",
       "3          0.108434 -0.100143  0.198992     0.041878        0.157114   \n",
       "4          0.158307  0.264664  0.233813     0.080265        0.153548   \n",
       "\n",
       "   week_of_year  month  \n",
       "0             1      1  \n",
       "1             1      1  \n",
       "2             1      1  \n",
       "3             1      1  \n",
       "4             1      1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from ta.trend import MACD\n",
    "\n",
    "def apply_features(group):\n",
    "    group.index = pd.to_datetime(group.index)\n",
    "\n",
    "    # Compute lag features, moving averages, etc., for the group\n",
    "    for lag in range(1, 4):\n",
    "        group[f'lag_{lag}'] = group['Close'].shift(lag)\n",
    "    group['weekly_return'] = group['Close'].pct_change(5)\n",
    "    group['5_day_MA'] = group['Close'].rolling(window=5).mean()\n",
    "    group['20_day_MA'] = group['Close'].rolling(window=20).mean()\n",
    "    group['5_day_volatility'] = group['Close'].rolling(window=5).std()\n",
    "    group['momentum'] = group['Close'] - group['Close'].shift(1)\n",
    "    \n",
    "    # MACD, ensuring you handle NaNs as per your strategy\n",
    "\n",
    "    macd = MACD(close=group['Close'], window_slow=26, window_fast=12, window_sign=9)\n",
    "    group['MACD'] = macd.macd()\n",
    "    group['MACD_signal'] = macd.macd_signal()\n",
    "    group['MACD_histogram'] = macd.macd_diff()\n",
    "\n",
    "    # Adjusting for multi-stock data: adding week_of_year and month\n",
    "    group['week_of_year'] = group.index.isocalendar().week\n",
    "    group['month'] = group.index.month\n",
    "    \n",
    "    return group.dropna()  # Optionally drop NaNs\n",
    "\n",
    "df_stocks = historical_data_df.groupby('Symbol').apply(apply_features)\n",
    "df_stocks.index = df_stocks.index.droplevel()\n",
    "df_stocks.reset_index(inplace=True)\n",
    "df_stocks.drop('index', inplace=True, axis=1)\n",
    "df_stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 344182/344182 [53:38<00:00, 106.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date stocks  title_embedding_0  title_embedding_1  \\\n",
      "0       2009-07-27   AAPL          -0.041291          -0.027628   \n",
      "1       2009-07-27   AMZN          -0.019739          -0.070451   \n",
      "2       2009-07-27   BIDU          -0.030594          -0.065926   \n",
      "3       2009-07-27    CIT           0.027524          -0.028871   \n",
      "4       2009-07-27    CME           0.027524          -0.028871   \n",
      "...            ...    ...                ...                ...   \n",
      "344177  2023-10-30    XPO          -0.058720          -0.046279   \n",
      "344178  2023-10-30    XRX           0.021734           0.014859   \n",
      "344179  2023-10-30    YUM           0.021734           0.014859   \n",
      "344180  2023-10-30   YUMC           0.021734           0.014859   \n",
      "344181  2023-10-30     ZI          -0.058720          -0.020790   \n",
      "\n",
      "        title_embedding_2  title_embedding_3  title_embedding_4  \\\n",
      "0                0.035083           0.088277           0.067462   \n",
      "1               -0.061547           0.132563           0.059887   \n",
      "2                0.049317           0.133437           0.025950   \n",
      "3               -0.060342           0.053199           0.046198   \n",
      "4               -0.060342           0.053199           0.046198   \n",
      "...                   ...                ...                ...   \n",
      "344177           0.005582           0.051844           0.070572   \n",
      "344178           0.012015           0.048510           0.063754   \n",
      "344179           0.012015           0.048510           0.063754   \n",
      "344180           0.012015           0.048510           0.063754   \n",
      "344181          -0.000900           0.051844          -0.027587   \n",
      "\n",
      "        title_embedding_5  title_embedding_6  title_embedding_7  ...  \\\n",
      "0                0.026903           0.051503           0.023311  ...   \n",
      "1                0.021348           0.026229          -0.047518  ...   \n",
      "2                0.045548          -0.003803          -0.003965  ...   \n",
      "3               -0.037971           0.135296          -0.022271  ...   \n",
      "4               -0.037971           0.135296          -0.022271  ...   \n",
      "...                   ...                ...                ...  ...   \n",
      "344177           0.052418          -0.078451          -0.044454  ...   \n",
      "344178          -0.006546          -0.008298           0.013803  ...   \n",
      "344179          -0.006546          -0.008298           0.013803  ...   \n",
      "344180          -0.006546          -0.008298           0.013803  ...   \n",
      "344181          -0.032041          -0.078451          -0.044412  ...   \n",
      "\n",
      "        title_embedding_374  title_embedding_375  title_embedding_376  \\\n",
      "0                  0.017781            -0.093676            -0.083482   \n",
      "1                 -0.002127             0.004179            -0.023619   \n",
      "2                  0.024294            -0.003300            -0.067783   \n",
      "3                  0.036538            -0.019922            -0.055372   \n",
      "4                  0.036538            -0.019922            -0.055372   \n",
      "...                     ...                  ...                  ...   \n",
      "344177             0.061931            -0.077949            -0.074183   \n",
      "344178             0.014185            -0.003808            -0.112009   \n",
      "344179             0.014185            -0.003808            -0.112009   \n",
      "344180             0.014185            -0.003808            -0.112009   \n",
      "344181             0.061931            -0.002718            -0.074183   \n",
      "\n",
      "        title_embedding_377  title_embedding_378  title_embedding_379  \\\n",
      "0                 -0.012103            -0.065227            -0.040412   \n",
      "1                 -0.002995            -0.056145             0.003105   \n",
      "2                  0.066965            -0.090206            -0.054115   \n",
      "3                  0.011424            -0.067690            -0.015036   \n",
      "4                  0.011424            -0.067690            -0.015036   \n",
      "...                     ...                  ...                  ...   \n",
      "344177            -0.078736            -0.116677            -0.060279   \n",
      "344178             0.018683            -0.022287            -0.073879   \n",
      "344179             0.018683            -0.022287            -0.073879   \n",
      "344180             0.018683            -0.022287            -0.073879   \n",
      "344181            -0.078736            -0.116677            -0.060279   \n",
      "\n",
      "        title_embedding_380  title_embedding_381  title_embedding_382  \\\n",
      "0                  0.084345            -0.121527            -0.053555   \n",
      "1                  0.040468            -0.050079            -0.080013   \n",
      "2                  0.017559            -0.071829             0.060755   \n",
      "3                  0.037755            -0.089164            -0.005867   \n",
      "4                  0.037755            -0.089164            -0.005867   \n",
      "...                     ...                  ...                  ...   \n",
      "344177             0.089311            -0.165473            -0.036443   \n",
      "344178             0.085654            -0.102545             0.008079   \n",
      "344179             0.085654            -0.102545             0.008079   \n",
      "344180             0.085654            -0.102545             0.008079   \n",
      "344181             0.024103            -0.165473            -0.036443   \n",
      "\n",
      "        title_embedding_383  \n",
      "0                  0.055776  \n",
      "1                  0.070316  \n",
      "2                  0.027583  \n",
      "3                 -0.016719  \n",
      "4                 -0.016719  \n",
      "...                     ...  \n",
      "344177             0.026441  \n",
      "344178             0.017200  \n",
      "344179             0.017200  \n",
      "344180             0.017200  \n",
      "344181            -0.016168  \n",
      "\n",
      "[344182 rows x 386 columns]\n"
     ]
    }
   ],
   "source": [
    "# max pooling of embedding by date and stock. So we need to group by date and stock and take max (by module) of each dimension of embedding\n",
    "# from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm  # for notebooks\n",
    "# from tqdm import tqdm\n",
    "# from tqdm.gui import tqdm as tqdm_gui\n",
    "# tqdm.pandas(ncols=50)\n",
    "from tqdm import tqdm\n",
    "# from pandarallel import pandarallel\n",
    "\n",
    "import pandas as pd\n",
    "# Create new pandas methods which use tqdm progress\n",
    "# (can use tqdm_gui, optional kwargs, etc.)\n",
    "tqdm.pandas()\n",
    "# pandarallel.initialize(progress_bar=True)\n",
    "def signed_abs_max(series):\n",
    "    abs_max_idx = series.abs().idxmax()\n",
    "    return series[abs_max_idx]\n",
    "\n",
    "\n",
    "# aggregation = {}\n",
    "# agg_func = lambda x: x.abs().max()\n",
    "# for title_emb in title_embeddings_columns:\n",
    "#     aggregation[title_emb] = agg_func\n",
    "# title_embeddings_df_grouped = title_embeddings_df.groupby(['date', 'stocks'])[title_embeddings_columns].progress_apply(*aggregation)\n",
    "# title_embeddings_df_grouped.reset_index(inplace=True)\n",
    "# title_embeddings_df_grouped.head()\n",
    "# resulted_df = None\n",
    "# for name, group in tqdm(title_embeddings_df.groupby(['date', 'stocks'])):\n",
    "#     group = group[title_embeddings_columns].abs().max()\n",
    "#     group = group.to_frame().T\n",
    "#     group['date'] = name[0]\n",
    "#     group['stocks'] = name[1]\n",
    "#     if resulted_df is None:\n",
    "#         resulted_df = group\n",
    "#     else:\n",
    "#         resulted_df = pd.concat([resulted_df, group])\n",
    "# title_embeddings_df_grouped = title_embeddings_df.groupby(['date', 'stocks'])[title_embeddings_columns].max()\n",
    "\n",
    "# Group by 'date' and 'stocks'\n",
    "grouped = title_embeddings_df.groupby(['date', 'stocks'])\n",
    "\n",
    "max_df = grouped.progress_apply(lambda group: group.iloc[:, 1:-1].apply(signed_abs_max))\n",
    "max_df.reset_index(inplace=True)\n",
    "print(max_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_df.to_csv('../../datasets/max_title_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>...</th>\n",
       "      <th>title_embedding_374</th>\n",
       "      <th>title_embedding_375</th>\n",
       "      <th>title_embedding_376</th>\n",
       "      <th>title_embedding_377</th>\n",
       "      <th>title_embedding_378</th>\n",
       "      <th>title_embedding_379</th>\n",
       "      <th>title_embedding_380</th>\n",
       "      <th>title_embedding_381</th>\n",
       "      <th>title_embedding_382</th>\n",
       "      <th>title_embedding_383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>20.058334</td>\n",
       "      <td>22.281832</td>\n",
       "      <td>22.381973</td>\n",
       "      <td>22.067240</td>\n",
       "      <td>22.381973</td>\n",
       "      <td>4038123.0</td>\n",
       "      <td>22.317596</td>\n",
       "      <td>22.160229</td>\n",
       "      <td>21.909870</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>19.865147</td>\n",
       "      <td>22.067240</td>\n",
       "      <td>22.288984</td>\n",
       "      <td>21.838341</td>\n",
       "      <td>22.238913</td>\n",
       "      <td>4366373.0</td>\n",
       "      <td>22.281832</td>\n",
       "      <td>22.317596</td>\n",
       "      <td>22.160229</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>20.109842</td>\n",
       "      <td>22.339056</td>\n",
       "      <td>22.346209</td>\n",
       "      <td>22.074392</td>\n",
       "      <td>22.153076</td>\n",
       "      <td>3945855.0</td>\n",
       "      <td>22.067240</td>\n",
       "      <td>22.281832</td>\n",
       "      <td>22.317596</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>20.019684</td>\n",
       "      <td>22.238913</td>\n",
       "      <td>22.267525</td>\n",
       "      <td>21.623749</td>\n",
       "      <td>22.060085</td>\n",
       "      <td>4778504.0</td>\n",
       "      <td>22.339056</td>\n",
       "      <td>22.067240</td>\n",
       "      <td>22.281832</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>20.257940</td>\n",
       "      <td>22.503576</td>\n",
       "      <td>22.546495</td>\n",
       "      <td>22.160229</td>\n",
       "      <td>22.296137</td>\n",
       "      <td>4678127.0</td>\n",
       "      <td>22.238913</td>\n",
       "      <td>22.339056</td>\n",
       "      <td>22.067240</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 404 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol  Adj Close      Close       High        Low       Open     Volume  \\\n",
       "0      A  20.058334  22.281832  22.381973  22.067240  22.381973  4038123.0   \n",
       "1      A  19.865147  22.067240  22.288984  21.838341  22.238913  4366373.0   \n",
       "2      A  20.109842  22.339056  22.346209  22.074392  22.153076  3945855.0   \n",
       "3      A  20.019684  22.238913  22.267525  21.623749  22.060085  4778504.0   \n",
       "4      A  20.257940  22.503576  22.546495  22.160229  22.296137  4678127.0   \n",
       "\n",
       "       lag_1      lag_2      lag_3  ...  title_embedding_374  \\\n",
       "0  22.317596  22.160229  21.909870  ...                  NaN   \n",
       "1  22.281832  22.317596  22.160229  ...                  NaN   \n",
       "2  22.067240  22.281832  22.317596  ...                  NaN   \n",
       "3  22.339056  22.067240  22.281832  ...                  NaN   \n",
       "4  22.238913  22.339056  22.067240  ...                  NaN   \n",
       "\n",
       "   title_embedding_375  title_embedding_376  title_embedding_377  \\\n",
       "0                  NaN                  NaN                  NaN   \n",
       "1                  NaN                  NaN                  NaN   \n",
       "2                  NaN                  NaN                  NaN   \n",
       "3                  NaN                  NaN                  NaN   \n",
       "4                  NaN                  NaN                  NaN   \n",
       "\n",
       "   title_embedding_378  title_embedding_379  title_embedding_380  \\\n",
       "0                  NaN                  NaN                  NaN   \n",
       "1                  NaN                  NaN                  NaN   \n",
       "2                  NaN                  NaN                  NaN   \n",
       "3                  NaN                  NaN                  NaN   \n",
       "4                  NaN                  NaN                  NaN   \n",
       "\n",
       "   title_embedding_381  title_embedding_382  title_embedding_383  \n",
       "0                  NaN                  NaN                  NaN  \n",
       "1                  NaN                  NaN                  NaN  \n",
       "2                  NaN                  NaN                  NaN  \n",
       "3                  NaN                  NaN                  NaN  \n",
       "4                  NaN                  NaN                  NaN  \n",
       "\n",
       "[5 rows x 404 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.merge(df_stocks, max_df, left_on=['date', 'Symbol'], right_on=['date', 'stocks'], how='left')\n",
    "df_merged.drop(['stocks', 'date'], inplace=True, axis=1)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv('../../datasets/max_title_embeddings_merged.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_merged = pd.read_csv('../../datasets/average_title_embeddings_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Symbol'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data \u001b[38;5;241m*\u001b[39m std \u001b[38;5;241m+\u001b[39m mean\n\u001b[1;32m      6\u001b[0m targets \u001b[38;5;241m=\u001b[39m df_merged[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweekly_return\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m----> 7\u001b[0m combined_features \u001b[38;5;241m=\u001b[39m \u001b[43mdf_merged\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweekly_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSymbol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      8\u001b[0m targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(targets)\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m      9\u001b[0m targets_mean \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/portfolio-optimisation-qXJsKVfj-py3.11/lib/python3.11/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/portfolio-optimisation-qXJsKVfj-py3.11/lib/python3.11/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/portfolio-optimisation-qXJsKVfj-py3.11/lib/python3.11/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/portfolio-optimisation-qXJsKVfj-py3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Symbol'] not found in axis\""
     ]
    }
   ],
   "source": [
    "def normalize(data, mean, std, eps=1e-6):\n",
    "    return (data - mean) / (std + eps)\n",
    "def denormalize(data, mean, std):\n",
    "    return data * std + mean\n",
    "\n",
    "targets = df_merged['weekly_return'].values\n",
    "combined_features = df_merged.drop(['weekly_return', 'Symbol'], axis=1).values\n",
    "targets = torch.from_numpy(targets).to(dtype=torch.float)\n",
    "targets_mean = targets.mean()\n",
    "targets_std = targets.std()\n",
    "targets_normalized = normalize(targets, targets_mean, targets_std)\n",
    "features_mean, features_std = combined_features.mean(axis=0), combined_features.std(axis=0)\n",
    "features_normalized = normalize(combined_features, features_mean, features_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_merged\n",
    "del combined_features\n",
    "del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_features, val_features, train_targets, val_targets \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m StockDataset(train_features, train_targets)\n\u001b[1;32m      3\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m StockDataset(val_features, val_targets)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/portfolio-optimisation-qXJsKVfj-py3.11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/portfolio-optimisation-qXJsKVfj-py3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2683\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2679\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m   2681\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m-> 2683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2685\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\n\u001b[1;32m   2686\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2687\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/portfolio-optimisation-qXJsKVfj-py3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2685\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2679\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m   2681\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[1;32m   2683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2684\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m-> 2685\u001b[0m         (_safe_indexing(a, train), \u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m   2686\u001b[0m     )\n\u001b[1;32m   2687\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/portfolio-optimisation-qXJsKVfj-py3.11/lib/python3.11/site-packages/sklearn/utils/__init__.py:320\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_indexing\u001b[39m(X, indices, \u001b[38;5;241m*\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    321\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return rows, items or columns of X using indices.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \n\u001b[1;32m    323\u001b[0m \u001b[38;5;124;03m    .. warning::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    array([1, 3, 5])\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_features, val_features, train_targets, val_targets = train_test_split(features_normalized, targets_normalized, test_size=0.2, random_state=42)\n",
    "train_dataset = StockDataset(train_features, train_targets)\n",
    "val_dataset = StockDataset(val_features, val_targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StockPredictor(input_dim, hidden_dim, num_layers, output_dim)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.device = device\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mse mae r2\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_mae = 0.0\n",
    "test_r2 = 0.0\n",
    "with torch.no_grad():\n",
    "    val_features = val_features.to(device)\n",
    "    val_targets = val_targets.to(device)\n",
    "    outputs = model(val_features)\n",
    "    denormalized_outputs = denormalize(outputs.squeeze(), targets_mean, targets_std)\n",
    "    denormalized_targets = denormalize(val_targets.squeeze(), targets_mean, targets_std)\n",
    "    loss = criterion(denormalized_outputs, denormalized_targets)\n",
    "    test_loss += loss.item() * val_features.size(0)\n",
    "    print('mse', loss.item())\n",
    "    test_mae += torch.nn.functional.l1_loss(denormalized_outputs, denormalized_targets).item()\n",
    "    print('mae', test_mae)\n",
    "    test_r2 += r2_score(denormalized_outputs.cpu().numpy(), denormalized_targets.cpu().numpy())\n",
    "    # calculate that true and predicted values both bigger or less than 0\n",
    "    our_metric = ((denormalized_outputs > 0) == (denormalized_targets > 0)).sum() / len(denormalized_targets)\n",
    "    print('r2-score:', test_r2)\n",
    "    print('Have same sign:', our_metric.item())\n",
    "    print('Example of predcitions:', denormalized_outputs[:10].tolist())\n",
    "    print('True values:', denormalized_targets[:10].tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfoloi-optimisation",
   "language": "python",
   "name": "portfoloi-optimisation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
