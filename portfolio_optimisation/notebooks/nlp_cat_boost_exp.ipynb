{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c2b5bcff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T11:19:06.583620Z",
     "start_time": "2024-02-05T11:19:06.461435Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pathlib\n",
    "import os\n",
    "import sys\n",
    "import concurrent.futures\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from benzinga import news_data\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup, MarkupResemblesLocatorWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c6d8a3b-8804-4236-a415-d2ac593aa6f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T11:19:08.149163Z",
     "start_time": "2024-02-05T11:19:08.143154Z"
    }
   },
   "outputs": [],
   "source": [
    "api_key = '092fe3da34ad421f99c42265ce3a7cbd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4642691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T11:19:10.942357Z",
     "start_time": "2024-02-05T11:19:10.918196Z"
    }
   },
   "outputs": [],
   "source": [
    "project_folder = pathlib.Path(os.path.abspath(\"__file__\")).resolve().parent.parent\n",
    "sys.path.insert(1, str(project_folder))\n",
    "\n",
    "from classes.yahoo_parser import SP500Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e4d8bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T11:22:16.440312Z",
     "start_time": "2024-02-05T11:21:54.011687Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  503 of 503 completed\n",
      "\n",
      "2 Failed downloads:\n",
      "['BF.B']: Exception('%ticker%: No price data found, symbol may be delisted (1d 2013-01-01 -> 2024-02-23)')\n",
      "['BRK.B']: Exception('%ticker%: No timezone found, symbol may be delisted')\n"
     ]
    }
   ],
   "source": [
    "yahoo_parser = SP500Parser()\n",
    "\n",
    "start = '2013-01-01'\n",
    "end = datetime.today().strftime('%Y-%m-%d')\n",
    "stocks = yahoo_parser.download_sp500_data(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed24fdc-6853-464c-b3b6-196ba526ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def get_news(ticker, page, date_from, date_to, display_output=\"full\"):\n",
    "    news = paper.news(company_tickers=ticker, display_output=display_output, date_from=date_from, date_to=date_to, page=page, pagesize=100)\n",
    "    if (len(news) == 0):\n",
    "        return []\n",
    "    df = pd.DataFrame(news)\n",
    "    df['teaser'] = df['teaser'].apply(remove_html_tags)\n",
    "    df['body'] = df['body'].apply(remove_html_tags)\n",
    "    return df\n",
    "\n",
    "def create_datasets_folder():\n",
    "    if not os.path.exists('datasets'):\n",
    "        os.makedirs('datasets')\n",
    "\n",
    "def get_news_by_ticker(ticker):\n",
    "    try:\n",
    "        page = 0\n",
    "        main_df = pd.DataFrame()\n",
    "        date_from = start\n",
    "        total = 0\n",
    "        while True:\n",
    "            if page > 100:\n",
    "                date_from  = datetime.strptime(main_df['updated'].iloc[-1], \"%a, %d %b %Y %H:%M:%S %z\").strftime('%Y-%m-%d')\n",
    "                page = 0\n",
    "            news_df = get_news(ticker, page, date_from, today_date, 'full')\n",
    "            if (len(news_df) == 0):\n",
    "                break\n",
    "            main_df = pd.concat([main_df, news_df], ignore_index=True)\n",
    "            main_df = main_df.drop_duplicates(subset=['id'])\n",
    "            page += 1\n",
    "            total += 1\n",
    "            print(f\"{ticker} - {total} page. Added rows: {len(news_df)} total: {len(main_df)}\")\n",
    "        if ticker == 'BRK.B' or ticker == 'BRK.A':\n",
    "            ticker = 'BRK-B'\n",
    "        main_df.to_csv(f\"datasets/news_sp_500_{ticker}.csv\")\n",
    "        return ticker\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def merge_all_in_one_file():\n",
    "    main_df = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "        if ticker == 'BRK.B':\n",
    "            ticker = 'BRK-B'\n",
    "        df = pd.read_csv(f\"datasets/news_sp_500_{ticker}.csv\")\n",
    "        main_df = pd.concat([main_df, df], ignore_index=True)\n",
    "        main_df = main_df.drop_duplicates(subset=['id'])\n",
    "        os.remove(f\"datasets/news_sp_500_{ticker}.csv\")\n",
    "    print(f\"Rows in total {len(main_df)}\")\n",
    "    main_df.to_csv(f\"datasets/news_sp_500.csv\")\n",
    "\n",
    "def run_concurent(max_workers=10):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(get_news_by_ticker, ticker) for ticker in tickers]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            ticker = future.result()\n",
    "            print(f\"Ticker {ticker} done\")\n",
    "\n",
    "def check_all_files():\n",
    "    for ticker in tickers:\n",
    "        if ticker == 'BRK.B':\n",
    "            ticker = 'BRK-B'\n",
    "        df = pd.read_csv(f\"datasets/news_sp_500_{ticker}.csv\")\n",
    "        if len(df) == 0:\n",
    "            print(f\"{ticker} - {len(df)}\")\n",
    "\n",
    "def zip_all_datasets():\n",
    "    zf = zipfile.ZipFile('news_datasets.zip', mode='w')\n",
    "    for ticker in tickers:\n",
    "        if ticker == 'BRK.B':\n",
    "            ticker = 'BRK-B'\n",
    "        zf.write(f\"datasets/news_sp_500_{ticker}.csv\")\n",
    "    zf.write(f\"datasets/news_sp_500.csv\")\n",
    "    zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b91e8d-9d88-4a9a-928f-db5420372f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()\n",
    "today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "paper = news_data.News(api_key, log=False)\n",
    "tickers = yahoo_parser.get_sp500_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31745866-2341-4e80-abca-8dcdf375f1ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker AAL done\n",
      "Ticker ABNB done\n",
      "Ticker ACGL done\n",
      "Ticker ABT done\n",
      "Ticker ACN done\n",
      "Ticker ADI done\n",
      "Ticker ABBV done\n",
      "Ticker ADBE done\n",
      "Ticker A done\n",
      "AAPL - 1 page. Added rows: 100 total: 29\n",
      "Ticker ADP done\n",
      "Ticker ADM done\n",
      "Ticker ADSK done\n",
      "Ticker AIZ done\n",
      "Ticker AFL done\n",
      "Ticker AIG done\n",
      "Ticker AEP done\n",
      "Ticker AEE done\n",
      "Ticker AES done\n",
      "Ticker AJG done\n",
      "Ticker ALB done\n",
      "Ticker ALL done\n",
      "Ticker ALGN done\n",
      "Ticker ALLE done\n",
      "Ticker AMAT done\n",
      "Ticker AMCR done\n",
      "Ticker AKAM done\n",
      "Ticker AMD done\n",
      "Ticker AME done\n",
      "Ticker AMT done\n",
      "Ticker ANSS done\n",
      "Ticker AMZN done\n",
      "Ticker AMP done\n",
      "AAPL - 2 page. Added rows: 100 total: 58\n",
      "Ticker ANET done\n",
      "Ticker AOS done\n",
      "AMGN - 1 page. Added rows: 100 total: 28\n",
      "Ticker APD done\n",
      "Ticker AVGO done\n",
      "Ticker AVY done\n",
      "AMGN - 2 page. Added rows: 100 total: 60\n",
      "Ticker AWK done\n",
      "Ticker APTV done\n",
      "Ticker ARE done\n",
      "Ticker APH done\n",
      "Ticker ATO done\n",
      "Ticker APA done\n",
      "Ticker AVB done\n",
      "Ticker AXON done\n",
      "Ticker AON done\n",
      "Ticker AZO done\n",
      "Ticker BALL done\n",
      "Ticker BAC done\n",
      "Ticker BAX done\n",
      "AAPL - 3 page. Added rows: 100 total: 85\n",
      "Ticker BBWI done\n",
      "Ticker BDX done\n",
      "Ticker BBY done\n",
      "Ticker BEN done\n",
      "AXP - 1 page. Added rows: 100 total: 27\n",
      "Ticker BF.B done\n",
      "AMGN - 3 page. Added rows: 100 total: 87\n",
      "Ticker BG done\n",
      "BA - 1 page. Added rows: 100 total: 28\n",
      "Ticker BK done\n",
      "Ticker BIIB done\n",
      "Ticker BIO done\n",
      "Ticker BKNG done\n",
      "Ticker BKR done\n",
      "Ticker BLDR done\n",
      "Ticker BR done\n",
      "Ticker BLK done\n",
      "Ticker BMY done\n",
      "AAPL - 4 page. Added rows: 100 total: 112\n",
      "Ticker BRK-B done\n",
      "AXP - 2 page. Added rows: 100 total: 52\n",
      "Ticker BRO done\n",
      "BA - 2 page. Added rows: 100 total: 54\n",
      "Ticker BSX done\n",
      "Ticker BWA done\n",
      "Ticker BX done\n",
      "Ticker BXP done\n",
      "AMGN - 4 page. Added rows: 100 total: 118\n",
      "Ticker C done\n",
      "Ticker CAG done\n",
      "Ticker CAH done\n",
      "AAPL - 5 page. Added rows: 100 total: 138\n",
      "Ticker CB done\n",
      "Ticker CBOE done\n",
      "Ticker CARR done\n",
      "Ticker CBRE done\n",
      "CAT - 1 page. Added rows: 100 total: 28\n",
      "Ticker CCI done\n",
      "Ticker CCL done\n",
      "Ticker CDNS done\n",
      "BA - 3 page. Added rows: 100 total: 85\n",
      "Ticker CDW done\n",
      "Ticker CE done\n",
      "AXP - 3 page. Added rows: 100 total: 79\n",
      "AMGN - 5 page. Added rows: 100 total: 142\n",
      "Ticker CEG done\n",
      "AAPL - 6 page. Added rows: 100 total: 165\n",
      "Ticker CHD done\n",
      "Ticker CHRW done\n",
      "Ticker CHTR done\n",
      "Ticker CFG done\n",
      "CAT - 2 page. Added rows: 100 total: 56\n",
      "Ticker CF done\n",
      "Ticker CL done\n",
      "Ticker CINF done\n",
      "Ticker CI done\n",
      "AMGN - 6 page. Added rows: 100 total: 167\n",
      "Ticker CMA done\n",
      "AAPL - 7 page. Added rows: 100 total: 194\n",
      "Ticker CLX done\n",
      "AXP - 4 page. Added rows: 100 total: 98\n",
      "BA - 4 page. Added rows: 100 total: 121\n",
      "Ticker CMG done\n",
      "Ticker CMCSA done\n",
      "Ticker CME done\n",
      "Ticker CMS done\n",
      "Ticker CNC done\n",
      "CAT - 3 page. Added rows: 100 total: 81\n",
      "Ticker CMI done\n",
      "Ticker CNP done\n",
      "Ticker COF done\n",
      "AMGN - 7 page. Added rows: 100 total: 194\n",
      "Ticker COO done\n",
      "Ticker COP done\n",
      "Ticker COR done\n",
      "AAPL - 8 page. Added rows: 100 total: 222\n",
      "Ticker CPB done\n",
      "Ticker CPRT done\n",
      "Ticker COST done\n",
      "Ticker CPT done\n",
      "Ticker CRL done\n",
      "Ticker CTAS done\n",
      "Ticker CSX done\n",
      "Ticker CTLT done\n",
      "AMGN - 8 page. Added rows: 100 total: 227\n",
      "Ticker CSGP done\n",
      "Ticker CTRA done\n",
      "AXP - 5 page. Added rows: 100 total: 125\n",
      "AAPL - 9 page. Added rows: 100 total: 249\n",
      "BA - 5 page. Added rows: 100 total: 146\n",
      "CAT - 4 page. Added rows: 100 total: 100\n",
      "CSCO - 1 page. Added rows: 100 total: 28\n",
      "Ticker CTSH done\n",
      "Ticker CTVA done\n",
      "Ticker CVS done\n",
      "AMGN - 9 page. Added rows: 100 total: 263\n",
      "AXP - 6 page. Added rows: 100 total: 155\n",
      "Ticker D done\n",
      "Ticker CZR done\n",
      "AAPL - 10 page. Added rows: 100 total: 276\n",
      "CRM - 1 page. Added rows: 100 total: 28\n",
      "BA - 6 page. Added rows: 100 total: 181\n",
      "CSCO - 2 page. Added rows: 100 total: 57\n",
      "CVX - 1 page. Added rows: 100 total: 27\n",
      "Ticker DAY done\n",
      "Ticker DAL done\n",
      "AMGN - 10 page. Added rows: 100 total: 284\n",
      "CAT - 5 page. Added rows: 100 total: 127\n",
      "AXP - 7 page. Added rows: 100 total: 181\n",
      "Ticker DD done\n",
      "Ticker DE done\n",
      "AAPL - 11 page. Added rows: 100 total: 299\n",
      "CRM - 2 page. Added rows: 100 total: 55\n",
      "BA - 7 page. Added rows: 100 total: 211\n",
      "Ticker DG done\n",
      "Ticker DFS done\n",
      "CSCO - 3 page. Added rows: 100 total: 83\n",
      "AMGN - 11 page. Added rows: 100 total: 332\n",
      "CVX - 2 page. Added rows: 100 total: 53\n",
      "Ticker DGX done\n",
      "AXP - 8 page. Added rows: 100 total: 210\n",
      "Ticker DHI done\n",
      "CAT - 6 page. Added rows: 100 total: 151\n",
      "AAPL - 12 page. Added rows: 100 total: 323\n",
      "CRM - 3 page. Added rows: 100 total: 80\n",
      "CSCO - 4 page. Added rows: 100 total: 108\n",
      "Ticker DHR done\n",
      "BA - 8 page. Added rows: 100 total: 241\n",
      "AXP - 9 page. Added rows: 100 total: 239\n",
      "Ticker DLR done\n",
      "AMGN - 12 page. Added rows: 100 total: 432\n",
      "DIS - 1 page. Added rows: 100 total: 28\n",
      "CVX - 3 page. Added rows: 100 total: 77\n",
      "AAPL - 13 page. Added rows: 100 total: 348\n",
      "CAT - 7 page. Added rows: 100 total: 176\n",
      "Ticker DLTR done\n",
      "CRM - 4 page. Added rows: 100 total: 106\n",
      "CSCO - 5 page. Added rows: 100 total: 135\n",
      "AXP - 10 page. Added rows: 100 total: 314\n",
      "DIS - 2 page. Added rows: 100 total: 54\n",
      "BA - 9 page. Added rows: 100 total: 264\n",
      "AAPL - 14 page. Added rows: 100 total: 371\n",
      "CVX - 4 page. Added rows: 100 total: 102\n",
      "Ticker DOV done\n",
      "CSCO - 6 page. Added rows: 100 total: 159\n",
      "CAT - 8 page. Added rows: 100 total: 200\n",
      "AMGN - 13 page. Added rows: 100 total: 532\n",
      "DIS - 3 page. Added rows: 100 total: 80\n",
      "AAPL - 15 page. Added rows: 100 total: 394\n",
      "CRM - 5 page. Added rows: 100 total: 129AXP - 11 page. Added rows: 100 total: 413\n",
      "\n",
      "DOW - 1 page. Added rows: 100 total: 28\n",
      "CAT - 9 page. Added rows: 100 total: 228\n",
      "CSCO - 7 page. Added rows: 100 total: 183\n",
      "BA - 10 page. Added rows: 100 total: 284\n",
      "CVX - 5 page. Added rows: 100 total: 125\n",
      "DIS - 4 page. Added rows: 100 total: 103\n",
      "AAPL - 16 page. Added rows: 100 total: 419\n",
      "DOW - 2 page. Added rows: 100 total: 55\n",
      "CRM - 6 page. Added rows: 100 total: 154\n",
      "AMGN - 14 page. Added rows: 100 total: 632\n",
      "AAPL - 17 page. Added rows: 100 total: 444\n",
      "BA - 11 page. Added rows: 100 total: 308\n",
      "DIS - 5 page. Added rows: 100 total: 130\n",
      "CSCO - 8 page. Added rows: 100 total: 212\n",
      "CAT - 10 page. Added rows: 100 total: 255\n",
      "CVX - 6 page. Added rows: 100 total: 144\n",
      "AAPL - 18 page. Added rows: 100 total: 467\n",
      "DOW - 3 page. Added rows: 100 total: 80\n",
      "DIS - 6 page. Added rows: 100 total: 155\n",
      "BA - 12 page. Added rows: 100 total: 333\n",
      "CRM - 7 page. Added rows: 100 total: 179\n",
      "AMGN - 15 page. Added rows: 100 total: 732\n",
      "CVX - 7 page. Added rows: 100 total: 164\n",
      "AAPL - 19 page. Added rows: 100 total: 491\n",
      "CAT - 11 page. Added rows: 100 total: 284\n",
      "DIS - 7 page. Added rows: 100 total: 177\n",
      "CSCO - 9 page. Added rows: 100 total: 235\n",
      "CRM - 8 page. Added rows: 100 total: 207\n",
      "BA - 13 page. Added rows: 100 total: 351\n",
      "AAPL - 20 page. Added rows: 100 total: 515\n",
      "AXP - 12 page. Added rows: 100 total: 513\n",
      "CAT - 12 page. Added rows: 100 total: 310\n",
      "AMGN - 16 page. Added rows: 100 total: 832\n",
      "DOW - 4 page. Added rows: 100 total: 100\n",
      "DIS - 8 page. Added rows: 100 total: 198\n",
      "CVX - 8 page. Added rows: 100 total: 186\n",
      "CRM - 9 page. Added rows: 100 total: 229\n",
      "CSCO - 10 page. Added rows: 100 total: 257\n",
      "AAPL - 21 page. Added rows: 100 total: 539\n",
      "BA - 14 page. Added rows: 100 total: 373\n",
      "AMGN - 17 page. Added rows: 100 total: 932\n",
      "DOW - 5 page. Added rows: 100 total: 123\n",
      "AXP - 13 page. Added rows: 100 total: 613\n",
      "CAT - 13 page. Added rows: 100 total: 370\n",
      "BA - 15 page. Added rows: 100 total: 400\n",
      "AAPL - 22 page. Added rows: 100 total: 563\n",
      "CVX - 9 page. Added rows: 100 total: 216\n",
      "AMGN - 18 page. Added rows: 48 total: 980\n",
      "CSCO - 11 page. Added rows: 100 total: 281\n",
      "DIS - 9 page. Added rows: 100 total: 230\n",
      "CRM - 10 page. Added rows: 100 total: 256\n",
      "AXP - 14 page. Added rows: 100 total: 713\n",
      "BA - 16 page. Added rows: 100 total: 430\n",
      "DOW - 6 page. Added rows: 100 total: 149\n",
      "AAPL - 23 page. Added rows: 100 total: 587\n",
      "CSCO - 12 page. Added rows: 100 total: 312\n",
      "CAT - 14 page. Added rows: 100 total: 470\n",
      "CVX - 10 page. Added rows: 100 total: 242\n",
      "CRM - 11 page. Added rows: 100 total: 285\n",
      "AXP - 15 page. Added rows: 87 total: 799\n",
      "Ticker AMGN done\n",
      "DIS - 10 page. Added rows: 100 total: 255\n",
      "AAPL - 24 page. Added rows: 100 total: 612\n",
      "BA - 17 page. Added rows: 100 total: 466\n",
      "DOW - 7 page. Added rows: 100 total: 175\n",
      "CSCO - 13 page. Added rows: 100 total: 344\n",
      "Ticker DPZ done\n",
      "CVX - 11 page. Added rows: 100 total: 265\n",
      "CRM - 12 page. Added rows: 100 total: 314\n",
      "Ticker AXP done\n",
      "AAPL - 25 page. Added rows: 100 total: 634\n",
      "CAT - 15 page. Added rows: 100 total: 570\n",
      "Ticker DRI done\n",
      "DIS - 11 page. Added rows: 100 total: 271\n",
      "CSCO - 14 page. Added rows: 100 total: 372\n",
      "CRM - 13 page. Added rows: 100 total: 342\n",
      "CVX - 12 page. Added rows: 100 total: 293\n",
      "Ticker DTE done\n",
      "Ticker DUK done\n",
      "DOW - 8 page. Added rows: 100 total: 233\n",
      "AAPL - 26 page. Added rows: 100 total: 658\n",
      "BA - 18 page. Added rows: 100 total: 495\n",
      "Ticker DVA done\n",
      "Ticker DVN done\n",
      "CSCO - 15 page. Added rows: 100 total: 395\n",
      "Ticker EA done\n",
      "CRM - 14 page. Added rows: 100 total: 385\n",
      "CAT - 16 page. Added rows: 100 total: 670\n",
      "BA - 19 page. Added rows: 100 total: 522\n",
      "Ticker DXCM done\n",
      "Ticker EBAY done\n",
      "DIS - 12 page. Added rows: 100 total: 291\n",
      "CVX - 13 page. Added rows: 100 total: 332\n",
      "AAPL - 27 page. Added rows: 100 total: 683\n",
      "CRM - 15 page. Added rows: 100 total: 485\n",
      "CSCO - 16 page. Added rows: 100 total: 421\n",
      "Ticker ED done\n",
      "Ticker ECL done\n",
      "Ticker EFX done\n",
      "Ticker EG done\n",
      "Ticker EIX done\n",
      "BA - 20 page. Added rows: 100 total: 590\n",
      "DOW - 9 page. Added rows: 100 total: 333\n",
      "DIS - 13 page. Added rows: 100 total: 316\n",
      "CSCO - 17 page. Added rows: 100 total: 450\n",
      "CVX - 14 page. Added rows: 100 total: 432\n",
      "AAPL - 28 page. Added rows: 100 total: 707\n",
      "CRM - 16 page. Added rows: 100 total: 585\n",
      "Ticker EL done\n",
      "Ticker ELV done\n",
      "AAPL - 29 page. Added rows: 100 total: 731\n",
      "CSCO - 18 page. Added rows: 100 total: 495\n",
      "Ticker EMN done\n",
      "Ticker EMR done\n",
      "DOW - 10 page. Added rows: 59 total: 392\n",
      "BA - 21 page. Added rows: 100 total: 690\n",
      "DIS - 14 page. Added rows: 100 total: 337\n",
      "Ticker EOG done\n",
      "Ticker ENPH done\n",
      "CRM - 17 page. Added rows: 100 total: 685\n",
      "Ticker EPAM done\n",
      "Ticker EQIX done\n",
      "CAT - 17 page. Added rows: 100 total: 770\n",
      "Ticker DOW done\n",
      "CSCO - 19 page. Added rows: 100 total: 595Ticker EQR done\n",
      "\n",
      "AAPL - 30 page. Added rows: 100 total: 751\n",
      "Ticker EQT done\n",
      "BA - 22 page. Added rows: 100 total: 789\n",
      "DIS - 15 page. Added rows: 100 total: 367\n",
      "Ticker ES done\n",
      "Ticker ESS done\n",
      "Ticker ETN done\n",
      "Ticker ETR done\n",
      "Ticker ETSY done\n",
      "Ticker EVRG done\n",
      "CAT - 18 page. Added rows: 100 total: 870\n",
      "DIS - 16 page. Added rows: 100 total: 388\n",
      "Ticker EW done\n",
      "Ticker EXC done\n",
      "AAPL - 31 page. Added rows: 100 total: 775\n",
      "Ticker EXPD done\n",
      "CSCO - 20 page. Added rows: 100 total: 695\n",
      "Ticker EXR done\n",
      "Ticker EXPE done\n",
      "Ticker F done\n",
      "DIS - 17 page. Added rows: 100 total: 411\n",
      "Ticker FANG done\n",
      "Ticker FAST done\n",
      "CRM - 18 page. Added rows: 100 total: 785CAT - 19 page. Added rows: 100 total: 970\n",
      "\n",
      "BA - 23 page. Added rows: 100 total: 889\n",
      "Ticker FCX done\n",
      "Ticker FDS done\n",
      "Ticker FDX done\n",
      "DIS - 18 page. Added rows: 100 total: 444\n",
      "CVX - 15 page. Added rows: 100 total: 532\n",
      "Ticker FFIV done\n",
      "Ticker FE done\n",
      "AAPL - 32 page. Added rows: 100 total: 797\n",
      "CAT - 20 page. Added rows: 1 total: 971\n",
      "Ticker FI done\n",
      "Ticker FIS done\n",
      "Ticker FICO done\n",
      "CRM - 19 page. Added rows: 100 total: 885\n",
      "Ticker FITB done\n",
      "DIS - 19 page. Added rows: 100 total: 477\n",
      "BA - 24 page. Added rows: 100 total: 989\n",
      "Ticker FLT done\n",
      "Ticker FOX done\n",
      "Ticker FMC done\n",
      "Ticker CAT done\n",
      "AAPL - 33 page. Added rows: 100 total: 822\n",
      "Ticker FRT done\n",
      "Ticker FOXA done\n",
      "Ticker FTNT done\n",
      "Ticker GD done\n",
      "Ticker FTV done\n",
      "Ticker FSLR done\n",
      "DIS - 20 page. Added rows: 100 total: 503\n",
      "Ticker GEN done\n",
      "Ticker GE done\n",
      "CSCO - 21 page. Added rows: 100 total: 795\n",
      "AAPL - 34 page. Added rows: 100 total: 843\n",
      "Ticker GILD done\n",
      "Ticker GEHC done\n",
      "BA - 25 page. Added rows: 100 total: 1089\n",
      "CRM - 20 page. Added rows: 100 total: 985\n",
      "Ticker GLW done\n",
      "Ticker GIS done\n",
      "Ticker GM done\n",
      "Ticker GL done\n",
      "CVX - 16 page. Added rows: 100 total: 632\n",
      "AAPL - 35 page. Added rows: 100 total: 866\n",
      "DIS - 21 page. Added rows: 100 total: 528\n",
      "Ticker GNRC done\n",
      "Ticker GOOG done\n",
      "Ticker GPC done\n",
      "Ticker GOOGL done\n",
      "CSCO - 22 page. Added rows: 100 total: 895\n",
      "Ticker GWW done\n",
      "Ticker GPN done\n",
      "Ticker GRMN done\n",
      "CVX - 17 page. Added rows: 100 total: 732\n",
      "AAPL - 36 page. Added rows: 100 total: 889\n",
      "Ticker HBAN done\n",
      "Ticker HAS done\n",
      "Ticker HAL done\n",
      "CRM - 21 page. Added rows: 100 total: 1085\n",
      "DIS - 22 page. Added rows: 100 total: 554\n",
      "GS - 1 page. Added rows: 100 total: 28\n",
      "Ticker HES done\n",
      "Ticker HCA done\n",
      "Ticker HIG done\n",
      "BA - 26 page. Added rows: 100 total: 1189\n",
      "Ticker HII done\n",
      "CVX - 18 page. Added rows: 100 total: 832\n",
      "HD - 1 page. Added rows: 100 total: 29\n",
      "DIS - 23 page. Added rows: 100 total: 577\n",
      "GS - 2 page. Added rows: 100 total: 55\n",
      "Ticker HLT done\n",
      "CRM - 22 page. Added rows: 100 total: 1184\n",
      "Ticker HOLX done\n",
      "CSCO - 23 page. Added rows: 100 total: 995\n",
      "Ticker HPE done\n",
      "HD - 2 page. Added rows: 100 total: 52\n",
      "DIS - 24 page. Added rows: 100 total: 598\n",
      "BA - 27 page. Added rows: 100 total: 1289\n",
      "CVX - 19 page. Added rows: 100 total: 932\n",
      "CRM - 23 page. Added rows: 100 total: 1284\n",
      "AAPL - 37 page. Added rows: 100 total: 912\n",
      "Ticker HPQ done\n",
      "GS - 3 page. Added rows: 100 total: 79\n",
      "HON - 1 page. Added rows: 100 total: 32\n",
      "Ticker HRL done\n",
      "CSCO - 24 page. Added rows: 100 total: 1094\n",
      "DIS - 25 page. Added rows: 100 total: 623HD - 3 page. Added rows: 100 total: 74\n",
      "\n",
      "BA - 28 page. Added rows: 100 total: 1389\n",
      "CVX - 20 page. Added rows: 100 total: 1032\n",
      "CRM - 24 page. Added rows: 100 total: 1384\n",
      "GS - 4 page. Added rows: 100 total: 105\n",
      "Ticker HSIC done\n",
      "HON - 2 page. Added rows: 100 total: 60\n",
      "CSCO - 25 page. Added rows: 100 total: 1194\n",
      "CVX - 21 page. Added rows: 7 total: 1039\n",
      "DIS - 26 page. Added rows: 100 total: 644\n",
      "AAPL - 38 page. Added rows: 100 total: 939\n",
      "Ticker HST done\n",
      "HD - 4 page. Added rows: 100 total: 96\n",
      "Ticker HSY done\n",
      "BA - 29 page. Added rows: 100 total: 1489\n",
      "CRM - 25 page. Added rows: 33 total: 1417\n",
      "Ticker CVX done\n",
      "AAPL - 39 page. Added rows: 100 total: 962GS - 5 page. Added rows: 100 total: 133\n",
      "\n",
      "Ticker HUBB done\n",
      "DIS - 27 page. Added rows: 100 total: 670\n",
      "HON - 3 page. Added rows: 100 total: 87\n",
      "CSCO - 26 page. Added rows: 54 total: 1248\n",
      "Ticker CRM done\n",
      "BA - 30 page. Added rows: 100 total: 1588\n",
      "Ticker HWM done\n",
      "Ticker HUM done\n",
      "HD - 5 page. Added rows: 100 total: 122\n",
      "Ticker ICE done\n",
      "Ticker IDXX done\n",
      "GS - 6 page. Added rows: 100 total: 155\n",
      "HON - 4 page. Added rows: 100 total: 114\n",
      "AAPL - 40 page. Added rows: 100 total: 987\n",
      "DIS - 28 page. Added rows: 100 total: 698\n",
      "Ticker CSCO done\n",
      "IBM - 1 page. Added rows: 100 total: 29\n",
      "Ticker IEX done\n",
      "Ticker IFF done\n",
      "BA - 31 page. Added rows: 100 total: 1688\n",
      "Ticker ILMN done\n",
      "HD - 6 page. Added rows: 100 total: 147\n",
      "HON - 5 page. Added rows: 100 total: 146\n",
      "AAPL - 41 page. Added rows: 100 total: 1014\n",
      "Ticker INTU done\n",
      "Ticker INCY done\n",
      "Ticker IP done\n",
      "Ticker INVH done\n",
      "INTC - 1 page. Added rows: 100 total: 27\n",
      "GS - 7 page. Added rows: 100 total: 179\n",
      "DIS - 29 page. Added rows: 100 total: 728\n",
      "AAPL - 42 page. Added rows: 100 total: 1037\n",
      "Ticker IPG doneIBM - 2 page. Added rows: 100 total: 54\n",
      "\n",
      "HON - 6 page. Added rows: 100 total: 173\n",
      "Ticker IQV done\n",
      "HD - 7 page. Added rows: 100 total: 174\n",
      "Ticker IR done\n",
      "BA - 32 page. Added rows: 100 total: 1788\n",
      "Ticker IRM done\n",
      "INTC - 2 page. Added rows: 100 total: 53\n",
      "GS - 8 page. Added rows: 100 total: 204\n",
      "Ticker ISRG done\n",
      "DIS - 30 page. Added rows: 100 total: 756\n",
      "Ticker IT done\n",
      "HON - 7 page. Added rows: 100 total: 239\n",
      "AAPL - 43 page. Added rows: 100 total: 1062\n",
      "IBM - 3 page. Added rows: 100 total: 82\n",
      "Ticker IVZ done\n",
      "Ticker ITW done\n",
      "HD - 8 page. Added rows: 100 total: 191\n",
      "Ticker JBHT done\n",
      "Ticker J done\n",
      "Ticker JCI done\n",
      "Ticker JBL done\n",
      "BA - 33 page. Added rows: 100 total: 1888\n",
      "INTC - 3 page. Added rows: 100 total: 80\n",
      "AAPL - 44 page. Added rows: 100 total: 1087\n",
      "Ticker JKHY done\n",
      "DIS - 31 page. Added rows: 100 total: 837\n",
      "GS - 9 page. Added rows: 100 total: 227\n",
      "IBM - 4 page. Added rows: 100 total: 110\n",
      "HD - 9 page. Added rows: 100 total: 213\n",
      "Ticker JNPR done\n",
      "AAPL - 45 page. Added rows: 100 total: 1111\n",
      "INTC - 4 page. Added rows: 100 total: 107\n",
      "JNJ - 1 page. Added rows: 100 total: 27\n",
      "BA - 34 page. Added rows: 100 total: 1988\n",
      "DIS - 32 page. Added rows: 100 total: 935\n",
      "HD - 10 page. Added rows: 100 total: 246\n",
      "IBM - 5 page. Added rows: 100 total: 135\n",
      "JPM - 1 page. Added rows: 100 total: 28\n",
      "HON - 8 page. Added rows: 100 total: 339\n",
      "GS - 10 page. Added rows: 100 total: 249\n",
      "JNJ - 2 page. Added rows: 100 total: 50\n",
      "AAPL - 46 page. Added rows: 100 total: 1132\n",
      "BA - 35 page. Added rows: 100 total: 2088\n",
      "INTC - 5 page. Added rows: 100 total: 131\n",
      "DIS - 33 page. Added rows: 100 total: 1035\n",
      "HD - 11 page. Added rows: 100 total: 276\n",
      "JPM - 2 page. Added rows: 100 total: 56\n",
      "IBM - 6 page. Added rows: 100 total: 161\n",
      "GS - 11 page. Added rows: 100 total: 277\n",
      "JNJ - 3 page. Added rows: 100 total: 77\n",
      "BA - 36 page. Added rows: 100 total: 2188\n",
      "HD - 12 page. Added rows: 100 total: 307\n",
      "DIS - 34 page. Added rows: 100 total: 1135\n",
      "AAPL - 47 page. Added rows: 100 total: 1157\n",
      "INTC - 6 page. Added rows: 100 total: 157\n",
      "JPM - 3 page. Added rows: 100 total: 81\n",
      "GS - 12 page. Added rows: 100 total: 304\n",
      "HON - 9 page. Added rows: 100 total: 439\n",
      "IBM - 7 page. Added rows: 100 total: 183\n",
      "HD - 13 page. Added rows: 100 total: 337\n",
      "AAPL - 48 page. Added rows: 100 total: 1178\n",
      "DIS - 35 page. Added rows: 100 total: 1234\n",
      "JNJ - 4 page. Added rows: 100 total: 102\n",
      "JPM - 4 page. Added rows: 100 total: 105\n",
      "BA - 37 page. Added rows: 100 total: 2288\n",
      "INTC - 7 page. Added rows: 100 total: 179\n",
      "GS - 13 page. Added rows: 100 total: 327\n",
      "HON - 10 page. Added rows: 100 total: 539\n",
      "IBM - 8 page. Added rows: 100 total: 211\n",
      "HD - 14 page. Added rows: 100 total: 365\n",
      "AAPL - 49 page. Added rows: 100 total: 1200\n",
      "JPM - 5 page. Added rows: 100 total: 131\n",
      "GS - 14 page. Added rows: 100 total: 358\n",
      "DIS - 36 page. Added rows: 100 total: 1334\n",
      "BA - 38 page. Added rows: 100 total: 2388\n",
      "INTC - 8 page. Added rows: 100 total: 205\n",
      "HON - 11 page. Added rows: 83 total: 622\n",
      "JNJ - 5 page. Added rows: 100 total: 130\n",
      "GS - 15 page. Added rows: 100 total: 389\n",
      "HD - 15 page. Added rows: 100 total: 434\n",
      "BA - 39 page. Added rows: 9 total: 2397\n",
      "IBM - 9 page. Added rows: 100 total: 238\n",
      "JPM - 6 page. Added rows: 100 total: 152\n",
      "AAPL - 50 page. Added rows: 100 total: 1223\n",
      "INTC - 9 page. Added rows: 100 total: 231\n",
      "Ticker HON done\n",
      "DIS - 37 page. Added rows: 100 total: 1432\n",
      "JPM - 7 page. Added rows: 100 total: 174\n",
      "Ticker K done\n",
      "HD - 16 page. Added rows: 100 total: 534GS - 16 page. Added rows: 100 total: 420\n",
      "\n",
      "JNJ - 6 page. Added rows: 100 total: 150\n",
      "AAPL - 51 page. Added rows: 100 total: 1248\n",
      "IBM - 10 page. Added rows: 100 total: 263\n",
      "Ticker KDP done\n",
      "INTC - 10 page. Added rows: 100 total: 252\n",
      "Ticker BA done\n",
      "JPM - 8 page. Added rows: 100 total: 198\n",
      "Ticker KEY done\n",
      "HD - 17 page. Added rows: 100 total: 634\n",
      "Ticker KEYS done\n",
      "JNJ - 7 page. Added rows: 100 total: 173\n",
      "AAPL - 52 page. Added rows: 100 total: 1272\n",
      "Ticker KHC done\n",
      "GS - 17 page. Added rows: 100 total: 446\n",
      "IBM - 11 page. Added rows: 100 total: 286\n",
      "Ticker KIM done\n",
      "INTC - 11 page. Added rows: 100 total: 279\n",
      "JPM - 9 page. Added rows: 100 total: 222\n",
      "Ticker KLAC done\n",
      "Ticker KMB done\n",
      "Ticker KMX done\n",
      "Ticker KMI done\n",
      "DIS - 38 page. Added rows: 100 total: 1532\n",
      "GS - 18 page. Added rows: 100 total: 474\n",
      "Ticker KR done\n",
      "IBM - 12 page. Added rows: 100 total: 312JNJ - 8 page. Added rows: 100 total: 194\n",
      "\n",
      "AAPL - 53 page. Added rows: 100 total: 1295\n",
      "KO - 1 page. Added rows: 100 total: 29\n",
      "JPM - 10 page. Added rows: 100 total: 251\n",
      "Ticker KVUE done\n",
      "INTC - 12 page. Added rows: 100 total: 304\n",
      "GS - 19 page. Added rows: 100 total: 505\n",
      "DIS - 39 page. Added rows: 100 total: 1631\n",
      "IBM - 13 page. Added rows: 100 total: 333\n",
      "Ticker L done\n",
      "AAPL - 54 page. Added rows: 100 total: 1324\n",
      "Ticker LDOS done\n",
      "JNJ - 9 page. Added rows: 100 total: 214\n",
      "HD - 18 page. Added rows: 100 total: 734KO - 2 page. Added rows: 100 total: 55\n",
      "\n",
      "GS - 20 page. Added rows: 100 total: 542\n",
      "IBM - 14 page. Added rows: 100 total: 363\n",
      "JPM - 11 page. Added rows: 100 total: 274\n",
      "Ticker LEN done\n",
      "DIS - 40 page. Added rows: 100 total: 1731\n",
      "INTC - 13 page. Added rows: 100 total: 329\n",
      "AAPL - 55 page. Added rows: 100 total: 1347\n",
      "Ticker LH done\n",
      "JNJ - 10 page. Added rows: 100 total: 237\n",
      "IBM - 15 page. Added rows: 100 total: 389\n",
      "KO - 3 page. Added rows: 100 total: 82\n",
      "GS - 21 page. Added rows: 100 total: 642\n",
      "Ticker LHX done\n",
      "JPM - 12 page. Added rows: 100 total: 299\n",
      "Ticker LIN done\n",
      "INTC - 14 page. Added rows: 100 total: 351\n",
      "JNJ - 11 page. Added rows: 100 total: 262\n",
      "AAPL - 56 page. Added rows: 100 total: 1370\n",
      "Ticker LKQ done\n",
      "HD - 19 page. Added rows: 100 total: 834\n",
      "IBM - 16 page. Added rows: 100 total: 417\n",
      "DIS - 41 page. Added rows: 100 total: 1831\n",
      "Ticker LLY done\n",
      "INTC - 15 page. Added rows: 100 total: 384\n",
      "KO - 4 page. Added rows: 100 total: 105\n",
      "JNJ - 12 page. Added rows: 100 total: 298\n",
      "GS - 22 page. Added rows: 100 total: 742\n",
      "Ticker LMT done\n",
      "AAPL - 57 page. Added rows: 100 total: 1394\n",
      "JPM - 13 page. Added rows: 100 total: 324\n",
      "HD - 20 page. Added rows: 100 total: 934\n",
      "IBM - 17 page. Added rows: 100 total: 446\n",
      "Ticker LNT done\n",
      "INTC - 16 page. Added rows: 100 total: 406\n",
      "KO - 5 page. Added rows: 100 total: 126\n",
      "JNJ - 13 page. Added rows: 100 total: 329\n",
      "DIS - 42 page. Added rows: 100 total: 1931\n",
      "Ticker LOW done\n",
      "GS - 23 page. Added rows: 100 total: 842\n",
      "JPM - 14 page. Added rows: 100 total: 345\n",
      "AAPL - 58 page. Added rows: 100 total: 1415\n",
      "Ticker LRCX done\n",
      "INTC - 17 page. Added rows: 100 total: 436\n",
      "IBM - 18 page. Added rows: 100 total: 476\n",
      "KO - 6 page. Added rows: 100 total: 149\n",
      "HD - 21 page. Added rows: 100 total: 1034\n",
      "DIS - 43 page. Added rows: 100 total: 2031\n",
      "JNJ - 14 page. Added rows: 100 total: 355\n",
      "Ticker LULU done\n",
      "Ticker LUV done\n",
      "INTC - 18 page. Added rows: 100 total: 467\n",
      "JPM - 15 page. Added rows: 100 total: 361\n",
      "GS - 24 page. Added rows: 100 total: 942\n",
      "Ticker LVS done\n",
      "AAPL - 59 page. Added rows: 100 total: 1440\n",
      "JNJ - 15 page. Added rows: 100 total: 381\n",
      "IBM - 19 page. Added rows: 100 total: 501\n",
      "INTC - 19 page. Added rows: 100 total: 498\n",
      "DIS - 44 page. Added rows: 100 total: 2131\n",
      "HD - 22 page. Added rows: 100 total: 1134\n",
      "KO - 7 page. Added rows: 100 total: 174\n",
      "JPM - 16 page. Added rows: 100 total: 388\n",
      "Ticker LW done\n",
      "IBM - 20 page. Added rows: 100 total: 528\n",
      "JNJ - 16 page. Added rows: 100 total: 406\n",
      "AAPL - 60 page. Added rows: 100 total: 1461\n",
      "Ticker LYB done\n",
      "HD - 23 page. Added rows: 61 total: 1195\n",
      "DIS - 45 page. Added rows: 100 total: 2231\n",
      "Ticker LYV done\n",
      "JPM - 17 page. Added rows: 100 total: 420\n",
      "GS - 25 page. Added rows: 100 total: 1042\n",
      "Ticker MA done\n",
      "IBM - 21 page. Added rows: 100 total: 555\n",
      "INTC - 20 page. Added rows: 100 total: 525\n",
      "KO - 8 page. Added rows: 100 total: 192\n",
      "JNJ - 17 page. Added rows: 100 total: 483\n",
      "Ticker MAA done\n",
      "AAPL - 61 page. Added rows: 100 total: 1482\n",
      "Ticker HD done\n",
      "DIS - 46 page. Added rows: 100 total: 2331\n",
      "Ticker MAR done\n",
      "IBM - 22 page. Added rows: 100 total: 584\n",
      "GS - 26 page. Added rows: 100 total: 1142\n",
      "Ticker MAS done\n",
      "JPM - 18 page. Added rows: 100 total: 450\n",
      "INTC - 21 page. Added rows: 100 total: 548\n",
      "AAPL - 62 page. Added rows: 100 total: 1507\n",
      "DIS - 47 page. Added rows: 100 total: 2431\n",
      "Ticker MCHP done\n",
      "JNJ - 18 page. Added rows: 100 total: 583\n",
      "MCD - 1 page. Added rows: 100 total: 25\n",
      "IBM - 23 page. Added rows: 100 total: 605\n",
      "JPM - 19 page. Added rows: 100 total: 472\n",
      "Ticker MCK done\n",
      "KO - 9 page. Added rows: 100 total: 216\n",
      "INTC - 22 page. Added rows: 100 total: 573\n",
      "AAPL - 63 page. Added rows: 100 total: 1533\n",
      "DIS - 48 page. Added rows: 100 total: 2531\n",
      "Ticker MCO done\n",
      "MCD - 2 page. Added rows: 100 total: 50\n",
      "IBM - 24 page. Added rows: 100 total: 695\n",
      "Ticker MDLZ done\n",
      "GS - 27 page. Added rows: 100 total: 1242\n",
      "INTC - 23 page. Added rows: 100 total: 599\n",
      "JPM - 20 page. Added rows: 100 total: 498\n",
      "DIS - 49 page. Added rows: 100 total: 2630\n",
      "Ticker MDT done\n",
      "AAPL - 64 page. Added rows: 100 total: 1555\n",
      "KO - 10 page. Added rows: 100 total: 237\n",
      "JNJ - 19 page. Added rows: 100 total: 683\n",
      "MCD - 3 page. Added rows: 100 total: 74\n",
      "IBM - 25 page. Added rows: 100 total: 795\n",
      "INTC - 24 page. Added rows: 100 total: 636\n",
      "Ticker MET done\n",
      "JPM - 21 page. Added rows: 100 total: 526\n",
      "Ticker META done\n",
      "GS - 28 page. Added rows: 100 total: 1341\n",
      "MCD - 4 page. Added rows: 100 total: 95\n",
      "KO - 11 page. Added rows: 100 total: 263\n",
      "Ticker MGM done\n",
      "INTC - 25 page. Added rows: 100 total: 736\n",
      "DIS - 50 page. Added rows: 100 total: 2730\n",
      "AAPL - 65 page. Added rows: 100 total: 1576\n",
      "Ticker MHK done\n",
      "JNJ - 20 page. Added rows: 100 total: 783\n",
      "JPM - 22 page. Added rows: 100 total: 553\n",
      "IBM - 26 page. Added rows: 100 total: 895\n",
      "MCD - 5 page. Added rows: 100 total: 118\n",
      "Ticker MKC done\n",
      "GS - 29 page. Added rows: 100 total: 1440\n",
      "KO - 12 page. Added rows: 100 total: 293\n",
      "INTC - 26 page. Added rows: 100 total: 836\n",
      "Ticker MKTX done\n",
      "JPM - 23 page. Added rows: 100 total: 577\n",
      "AAPL - 66 page. Added rows: 100 total: 1598\n",
      "MCD - 6 page. Added rows: 100 total: 139\n",
      "Ticker MLM done\n",
      "Ticker MMC done\n",
      "IBM - 27 page. Added rows: 100 total: 995\n",
      "GS - 30 page. Added rows: 100 total: 1540\n",
      "DIS - 51 page. Added rows: 100 total: 2828\n",
      "AAPL - 67 page. Added rows: 100 total: 1620\n",
      "JPM - 24 page. Added rows: 100 total: 605\n",
      "KO - 13 page. Added rows: 100 total: 314INTC - 27 page. Added rows: 100 total: 936\n",
      "\n",
      "MCD - 7 page. Added rows: 100 total: 160\n",
      "MMM - 1 page. Added rows: 100 total: 27\n",
      "AAPL - 68 page. Added rows: 100 total: 1650\n",
      "IBM - 28 page. Added rows: 100 total: 1095\n",
      "JPM - 25 page. Added rows: 100 total: 652\n",
      "KO - 14 page. Added rows: 100 total: 339\n",
      "DIS - 52 page. Added rows: 100 total: 2928\n",
      "JNJ - 21 page. Added rows: 100 total: 883\n",
      "GS - 31 page. Added rows: 100 total: 1640\n",
      "MCD - 8 page. Added rows: 100 total: 184\n",
      "INTC - 28 page. Added rows: 100 total: 1036\n",
      "AAPL - 69 page. Added rows: 100 total: 1679\n",
      "MMM - 2 page. Added rows: 100 total: 52\n",
      "IBM - 29 page. Added rows: 100 total: 1195\n",
      "KO - 15 page. Added rows: 100 total: 369\n",
      "JPM - 26 page. Added rows: 100 total: 752\n",
      "GS - 32 page. Added rows: 100 total: 1740\n",
      "DIS - 53 page. Added rows: 100 total: 3027\n",
      "MCD - 9 page. Added rows: 100 total: 207\n",
      "AAPL - 70 page. Added rows: 100 total: 1706\n",
      "JNJ - 22 page. Added rows: 100 total: 983\n",
      "KO - 16 page. Added rows: 100 total: 397\n",
      "JPM - 27 page. Added rows: 100 total: 852\n",
      "GS - 33 page. Added rows: 100 total: 1840\n",
      "IBM - 30 page. Added rows: 100 total: 1294\n",
      "MMM - 3 page. Added rows: 100 total: 74\n",
      "INTC - 29 page. Added rows: 100 total: 1136\n",
      "DIS - 54 page. Added rows: 100 total: 3126\n",
      "AAPL - 71 page. Added rows: 100 total: 1731\n",
      "KO - 17 page. Added rows: 100 total: 422\n",
      "JPM - 28 page. Added rows: 100 total: 952\n",
      "MCD - 10 page. Added rows: 100 total: 230\n",
      "JNJ - 23 page. Added rows: 100 total: 1083\n",
      "IBM - 31 page. Added rows: 100 total: 1394\n",
      "MMM - 4 page. Added rows: 100 total: 103\n",
      "INTC - 30 page. Added rows: 100 total: 1235\n",
      "AAPL - 72 page. Added rows: 100 total: 1752\n",
      "KO - 18 page. Added rows: 100 total: 445\n",
      "GS - 34 page. Added rows: 100 total: 1940\n",
      "DIS - 55 page. Added rows: 100 total: 3226\n",
      "JNJ - 24 page. Added rows: 100 total: 1183\n",
      "MCD - 11 page. Added rows: 100 total: 253\n",
      "JPM - 29 page. Added rows: 100 total: 1052\n",
      "MMM - 5 page. Added rows: 100 total: 133\n",
      "AAPL - 73 page. Added rows: 100 total: 1776\n",
      "IBM - 32 page. Added rows: 100 total: 1494\n",
      "INTC - 31 page. Added rows: 100 total: 1335\n",
      "GS - 35 page. Added rows: 72 total: 2012\n",
      "KO - 19 page. Added rows: 100 total: 475\n",
      "DIS - 56 page. Added rows: 100 total: 3325\n",
      "JNJ - 25 page. Added rows: 100 total: 1283AAPL - 74 page. Added rows: 100 total: 1806\n",
      "\n",
      "MMM - 6 page. Added rows: 100 total: 230\n",
      "Ticker GS done\n",
      "IBM - 33 page. Added rows: 40 total: 1534\n",
      "MCD - 12 page. Added rows: 100 total: 275\n",
      "KO - 20 page. Added rows: 100 total: 522\n",
      "Ticker MNST done\n",
      "AAPL - 75 page. Added rows: 100 total: 1834\n",
      "Ticker MO done\n",
      "DIS - 57 page. Added rows: 100 total: 3425\n",
      "Ticker MOH done\n",
      "JNJ - 26 page. Added rows: 100 total: 1382\n",
      "Ticker MOS done\n",
      "MCD - 13 page. Added rows: 100 total: 297\n",
      "KO - 21 page. Added rows: 100 total: 622\n",
      "Ticker IBM done\n",
      "INTC - 32 page. Added rows: 100 total: 1435\n",
      "Ticker MPC done\n",
      "JPM - 30 page. Added rows: 100 total: 1152\n",
      "AAPL - 76 page. Added rows: 100 total: 1860\n",
      "DIS - 58 page. Added rows: 100 total: 3525\n",
      "MCD - 14 page. Added rows: 100 total: 323\n",
      "Ticker MPWR done\n",
      "JNJ - 27 page. Added rows: 100 total: 1482\n",
      "KO - 22 page. Added rows: 100 total: 722\n",
      "Ticker MRNA done\n",
      "MRK - 1 page. Added rows: 100 total: 28\n",
      "INTC - 33 page. Added rows: 100 total: 1535\n",
      "Ticker MRO done\n",
      "MCD - 15 page. Added rows: 100 total: 354\n",
      "Ticker MS done\n",
      "MMM - 7 page. Added rows: 100 total: 330\n",
      "AAPL - 77 page. Added rows: 100 total: 1885\n",
      "DIS - 59 page. Added rows: 100 total: 3623\n",
      "MRK - 2 page. Added rows: 100 total: 59\n",
      "Ticker MSCI done\n",
      "JPM - 31 page. Added rows: 100 total: 1252\n",
      "JNJ - 28 page. Added rows: 100 total: 1582\n",
      "INTC - 34 page. Added rows: 100 total: 1635\n",
      "MCD - 16 page. Added rows: 100 total: 385\n",
      "AAPL - 78 page. Added rows: 100 total: 1912\n",
      "DIS - 60 page. Added rows: 100 total: 3723\n",
      "MSFT - 1 page. Added rows: 100 total: 29\n",
      "MRK - 3 page. Added rows: 100 total: 88\n",
      "MCD - 17 page. Added rows: 100 total: 415\n",
      "JNJ - 29 page. Added rows: 100 total: 1682\n",
      "INTC - 35 page. Added rows: 100 total: 1735\n",
      "MSFT - 2 page. Added rows: 100 total: 58\n",
      "AAPL - 79 page. Added rows: 100 total: 1934\n",
      "MMM - 8 page. Added rows: 100 total: 430\n",
      "KO - 23 page. Added rows: 100 total: 822\n",
      "MCD - 18 page. Added rows: 100 total: 440\n",
      "DIS - 61 page. Added rows: 100 total: 3823\n",
      "JPM - 32 page. Added rows: 100 total: 1352\n",
      "MRK - 4 page. Added rows: 100 total: 112\n",
      "JNJ - 30 page. Added rows: 100 total: 1781\n",
      "MSFT - 3 page. Added rows: 100 total: 87\n",
      "INTC - 36 page. Added rows: 100 total: 1835\n",
      "MMM - 9 page. Added rows: 100 total: 530\n",
      "MCD - 19 page. Added rows: 100 total: 466\n",
      "AAPL - 80 page. Added rows: 100 total: 1950\n",
      "MSFT - 4 page. Added rows: 100 total: 113\n",
      "JNJ - 31 page. Added rows: 100 total: 1881\n",
      "MRK - 5 page. Added rows: 100 total: 139\n",
      "DIS - 62 page. Added rows: 100 total: 3923\n",
      "MMM - 10 page. Added rows: 44 total: 574\n",
      "KO - 24 page. Added rows: 100 total: 922\n",
      "MCD - 20 page. Added rows: 100 total: 492\n",
      "MSFT - 5 page. Added rows: 100 total: 136\n",
      "AAPL - 81 page. Added rows: 100 total: 1966\n",
      "JPM - 33 page. Added rows: 100 total: 1452\n",
      "JNJ - 32 page. Added rows: 100 total: 1981\n",
      "DIS - 63 page. Added rows: 88 total: 4011\n",
      "INTC - 37 page. Added rows: 100 total: 1935\n",
      "MRK - 6 page. Added rows: 100 total: 156\n",
      "JNJ - 33 page. Added rows: 57 total: 2038\n",
      "MSFT - 6 page. Added rows: 100 total: 159\n",
      "KO - 25 page. Added rows: 100 total: 1022\n",
      "MCD - 21 page. Added rows: 100 total: 526\n",
      "AAPL - 82 page. Added rows: 100 total: 1981\n",
      "Ticker MMM done\n",
      "JPM - 34 page. Added rows: 100 total: 1552\n",
      "INTC - 38 page. Added rows: 100 total: 2035\n",
      "Ticker MSI done\n",
      "MSFT - 7 page. Added rows: 100 total: 185\n",
      "MCD - 22 page. Added rows: 100 total: 626\n",
      "Ticker MTB done\n",
      "AAPL - 83 page. Added rows: 100 total: 2002\n",
      "Ticker JNJ done\n",
      "MRK - 7 page. Added rows: 100 total: 184\n",
      "Ticker MTCH done\n",
      "KO - 26 page. Added rows: 100 total: 1120\n",
      "Ticker DIS done\n",
      "INTC - 39 page. Added rows: 100 total: 2135\n",
      "Ticker MTD done\n",
      "JPM - 35 page. Added rows: 100 total: 1652\n",
      "Ticker MU doneMSFT - 8 page. Added rows: 100 total: 208\n",
      "\n",
      "AAPL - 84 page. Added rows: 100 total: 2025\n",
      "Ticker NCLH done\n",
      "Ticker NDAQ done\n",
      "MCD - 23 page. Added rows: 100 total: 726\n",
      "Ticker NDSN done\n",
      "MRK - 8 page. Added rows: 100 total: 206\n",
      "Ticker NFLX done\n",
      "Ticker NEE done\n",
      "Ticker NEM done\n",
      "KO - 27 page. Added rows: 100 total: 1218\n",
      "MSFT - 9 page. Added rows: 100 total: 234\n",
      "INTC - 40 page. Added rows: 100 total: 2235\n",
      "AAPL - 85 page. Added rows: 100 total: 2050\n",
      "Ticker NOC done\n",
      "Ticker NI done\n",
      "Ticker NRG done\n",
      "Ticker NOW done\n",
      "JPM - 36 page. Added rows: 100 total: 1752\n",
      "Ticker NSC done\n",
      "Ticker NTAP done\n",
      "MCD - 24 page. Added rows: 100 total: 826\n",
      "NKE - 1 page. Added rows: 100 total: 28\n",
      "MSFT - 10 page. Added rows: 100 total: 255\n",
      "INTC - 41 page. Added rows: 100 total: 2335\n",
      "KO - 28 page. Added rows: 91 total: 1307\n",
      "Ticker NTRS done\n",
      "Ticker NUE done\n",
      "AAPL - 86 page. Added rows: 100 total: 2069\n",
      "MRK - 9 page. Added rows: 100 total: 232\n",
      "NKE - 2 page. Added rows: 100 total: 53\n",
      "MSFT - 11 page. Added rows: 100 total: 279\n",
      "Ticker NVDA done\n",
      "Ticker NVR done\n",
      "MCD - 25 page. Added rows: 100 total: 926\n",
      "JPM - 37 page. Added rows: 100 total: 1852\n",
      "INTC - 42 page. Added rows: 100 total: 2435\n",
      "Ticker NWS done\n",
      "MRK - 10 page. Added rows: 100 total: 257\n",
      "Ticker KO done\n",
      "Ticker NXPI done\n",
      "Ticker NWSA done\n",
      "Ticker O done\n",
      "AAPL - 87 page. Added rows: 100 total: 2089\n",
      "MSFT - 12 page. Added rows: 100 total: 302\n",
      "Ticker ODFL done\n",
      "Ticker OKE done\n",
      "NKE - 3 page. Added rows: 100 total: 78\n",
      "Ticker OMC done\n",
      "MCD - 26 page. Added rows: 100 total: 1026\n",
      "Ticker ORCL done\n",
      "Ticker ON done\n",
      "JPM - 38 page. Added rows: 100 total: 1952\n",
      "MRK - 11 page. Added rows: 100 total: 286\n",
      "INTC - 43 page. Added rows: 43 total: 2478\n",
      "Ticker ORLY done\n",
      "Ticker OXY done\n",
      "Ticker OTIS done\n",
      "MSFT - 13 page. Added rows: 100 total: 326\n",
      "Ticker PAYC done\n",
      "Ticker PANW done\n",
      "NKE - 4 page. Added rows: 100 total: 106\n",
      "Ticker PARA done\n",
      "AAPL - 88 page. Added rows: 100 total: 2109\n",
      "MCD - 27 page. Added rows: 100 total: 1124\n",
      "JPM - 39 page. Added rows: 100 total: 2052\n",
      "Ticker PAYX done\n",
      "Ticker PCAR done\n",
      "Ticker PCG done\n",
      "MRK - 12 page. Added rows: 100 total: 322\n",
      "MSFT - 14 page. Added rows: 100 total: 352\n",
      "Ticker PEG done\n",
      "Ticker PEAK done\n",
      "Ticker PEP done\n",
      "NKE - 5 page. Added rows: 100 total: 129\n",
      "Ticker INTC done\n",
      "AAPL - 89 page. Added rows: 100 total: 2136\n",
      "MRK - 13 page. Added rows: 100 total: 356\n",
      "Ticker PFG done\n",
      "Ticker PFE done\n",
      "JPM - 40 page. Added rows: 100 total: 2152\n",
      "Ticker PGR done\n",
      "MCD - 28 page. Added rows: 100 total: 1223\n",
      "MSFT - 15 page. Added rows: 100 total: 375\n",
      "PG - 1 page. Added rows: 100 total: 30\n",
      "Ticker PKG done\n",
      "Ticker PH done\n",
      "Ticker PHM done\n",
      "NKE - 6 page. Added rows: 100 total: 151\n",
      "MRK - 14 page. Added rows: 100 total: 382\n",
      "AAPL - 90 page. Added rows: 100 total: 2161\n",
      "Ticker PNC done\n",
      "Ticker PM done\n",
      "MCD - 29 page. Added rows: 100 total: 1322\n",
      "Ticker PLD done\n",
      "MSFT - 16 page. Added rows: 100 total: 398\n",
      "PG - 2 page. Added rows: 100 total: 56\n",
      "Ticker PNW done\n",
      "Ticker PNR done\n",
      "JPM - 41 page. Added rows: 100 total: 2252\n",
      "MRK - 15 page. Added rows: 100 total: 410\n",
      "Ticker PODD done\n",
      "NKE - 7 page. Added rows: 100 total: 177\n",
      "AAPL - 91 page. Added rows: 100 total: 2191\n",
      "Ticker PPG done\n",
      "Ticker POOL done\n",
      "PG - 3 page. Added rows: 100 total: 82\n",
      "Ticker PPL done\n",
      "Ticker PRU done\n",
      "Ticker PSA done\n",
      "JPM - 42 page. Added rows: 100 total: 2352\n",
      "MCD - 30 page. Added rows: 100 total: 1421\n",
      "MSFT - 17 page. Added rows: 100 total: 422\n",
      "AAPL - 92 page. Added rows: 100 total: 2219Ticker PWR done\n",
      "\n",
      "Ticker PSX done\n",
      "NKE - 8 page. Added rows: 100 total: 201\n",
      "Ticker PTC done\n",
      "MRK - 16 page. Added rows: 100 total: 471\n",
      "Ticker PYPL done\n",
      "Ticker QCOM done\n",
      "PG - 4 page. Added rows: 100 total: 105\n",
      "Ticker PXD done\n",
      "MCD - 31 page. Added rows: 13 total: 1434\n",
      "MSFT - 18 page. Added rows: 100 total: 450\n",
      "JPM - 43 page. Added rows: 71 total: 2423\n",
      "AAPL - 93 page. Added rows: 100 total: 2249\n",
      "Ticker REG done\n",
      "Ticker QRVO done\n",
      "Ticker RCL done\n",
      "MRK - 17 page. Added rows: 100 total: 571\n",
      "NKE - 9 page. Added rows: 100 total: 226\n",
      "Ticker REGN done\n",
      "Ticker RHI done\n",
      "Ticker RF done\n",
      "PG - 5 page. Added rows: 100 total: 129\n",
      "MSFT - 19 page. Added rows: 100 total: 478\n",
      "AAPL - 94 page. Added rows: 100 total: 2282\n",
      "Ticker RJF done\n",
      "Ticker RMD done\n",
      "Ticker MCD done\n",
      "NKE - 10 page. Added rows: 100 total: 256\n",
      "Ticker RL done\n",
      "Ticker ROK done\n",
      "Ticker ROL done\n",
      "Ticker ROP done\n",
      "Ticker ROST done\n",
      "MRK - 18 page. Added rows: 100 total: 671\n",
      "Ticker JPM done\n",
      "MSFT - 20 page. Added rows: 100 total: 504\n",
      "Ticker RSG done\n",
      "Ticker SBAC done\n",
      "Ticker RTX done\n",
      "PG - 6 page. Added rows: 100 total: 150\n",
      "NKE - 11 page. Added rows: 100 total: 286\n",
      "Ticker RVTY done\n",
      "AAPL - 95 page. Added rows: 100 total: 2309\n",
      "Ticker SCHW done\n",
      "Ticker SJM done\n",
      "Ticker SBUX done\n",
      "Ticker SHW done\n",
      "MRK - 19 page. Added rows: 100 total: 771\n",
      "Ticker SLB done\n",
      "Ticker SNA done\n",
      "Ticker SPG done\n",
      "Ticker SNPS done\n",
      "Ticker SO done\n",
      "AAPL - 96 page. Added rows: 100 total: 2334\n",
      "Ticker SPGI done\n",
      "PG - 7 page. Added rows: 100 total: 166\n",
      "Ticker STLD doneMSFT - 21 page. Added rows: 100 total: 528\n",
      "\n",
      "Ticker STT done\n",
      "Ticker STE done\n",
      "Ticker SRE done\n",
      "NKE - 12 page. Added rows: 100 total: 316\n",
      "Ticker STX done\n",
      "Ticker SWK done\n",
      "Ticker SWKS done\n",
      "Ticker STZ done\n",
      "AAPL - 97 page. Added rows: 100 total: 2352\n",
      "Ticker SYK done\n",
      "Ticker SYF done\n",
      "Ticker TAP done\n",
      "NKE - 13 page. Added rows: 100 total: 344\n",
      "Ticker TDG done\n",
      "Ticker SYY done\n",
      "Ticker T done\n",
      "MSFT - 22 page. Added rows: 100 total: 550\n",
      "Ticker TDY done\n",
      "MRK - 20 page. Added rows: 100 total: 871\n",
      "Ticker TECH done\n",
      "AAPL - 98 page. Added rows: 100 total: 2377\n",
      "PG - 8 page. Added rows: 100 total: 188\n",
      "Ticker TER done\n",
      "Ticker TFC done\n",
      "Ticker TEL done\n",
      "Ticker TGT done\n",
      "Ticker TJX done\n",
      "Ticker TMO done\n",
      "Ticker TMUS done\n",
      "NKE - 14 page. Added rows: 100 total: 374\n",
      "Ticker TFX done\n",
      "Ticker TPR done\n",
      "MSFT - 23 page. Added rows: 100 total: 575\n",
      "Ticker TRGP done\n",
      "AAPL - 99 page. Added rows: 100 total: 2400\n",
      "Ticker TRMB done\n",
      "PG - 9 page. Added rows: 100 total: 210Ticker TSCO done\n",
      "\n",
      "Ticker TROW done\n",
      "Ticker TSLA done\n",
      "MRK - 21 page. Added rows: 100 total: 971\n",
      "Ticker TSN done\n",
      "NKE - 15 page. Added rows: 100 total: 402\n",
      "MSFT - 24 page. Added rows: 100 total: 600\n",
      "TRV - 1 page. Added rows: 100 total: 24\n",
      "Ticker TT done\n",
      "Ticker TXN done\n",
      "Ticker TTWO done\n",
      "AAPL - 100 page. Added rows: 100 total: 2421\n",
      "Ticker TXT done\n",
      "PG - 10 page. Added rows: 100 total: 240\n",
      "Ticker TYL done\n",
      "Ticker UAL done\n",
      "Ticker UDR done\n",
      "Ticker UBER done\n",
      "NKE - 16 page. Added rows: 100 total: 433\n",
      "AAPL - 101 page. Added rows: 100 total: 2453\n",
      "Ticker UHS done\n",
      "Ticker ULTA done\n",
      "Ticker UNP done\n",
      "MSFT - 25 page. Added rows: 100 total: 628\n",
      "TRV - 2 page. Added rows: 100 total: 48\n",
      "Ticker USB done\n",
      "Ticker UPS done\n",
      "Ticker URI done\n",
      "NKE - 17 page. Added rows: 100 total: 452\n",
      "PG - 11 page. Added rows: 100 total: 270\n",
      "MRK - 22 page. Added rows: 100 total: 1071\n",
      "UNH - 1 page. Added rows: 100 total: 30\n",
      "AAPL - 102 page. Added rows: 100 total: 2472\n",
      "Ticker VICI done\n",
      "Ticker VFC done\n",
      "TRV - 3 page. Added rows: 100 total: 78\n",
      "MSFT - 26 page. Added rows: 100 total: 653\n",
      "Ticker VLO done\n",
      "V - 1 page. Added rows: 100 total: 27\n",
      "NKE - 18 page. Added rows: 100 total: 478\n",
      "Ticker VLTO done\n",
      "PG - 12 page. Added rows: 100 total: 295\n",
      "AAPL - 103 page. Added rows: 100 total: 2502\n",
      "UNH - 2 page. Added rows: 100 total: 57\n",
      "Ticker VMC done\n",
      "Ticker VRSK done\n",
      "MRK - 23 page. Added rows: 100 total: 1171\n",
      "NKE - 19 page. Added rows: 100 total: 553\n",
      "Ticker VRSN done\n",
      "V - 2 page. Added rows: 100 total: 55\n",
      "MSFT - 27 page. Added rows: 100 total: 678\n",
      "AAPL - 104 page. Added rows: 100 total: 2529\n",
      "Ticker VRTX done\n",
      "PG - 13 page. Added rows: 100 total: 327\n",
      "Ticker VTR done\n",
      "Ticker VTRS done\n",
      "AAPL - 105 page. Added rows: 100 total: 2550\n",
      "Ticker WAB done\n",
      "NKE - 20 page. Added rows: 100 total: 653\n",
      "TRV - 4 page. Added rows: 100 total: 160\n",
      "VZ - 1 page. Added rows: 100 total: 27\n",
      "Ticker WAT done\n",
      "MSFT - 28 page. Added rows: 100 total: 700\n",
      "MRK - 24 page. Added rows: 100 total: 1271\n",
      "AAPL - 106 page. Added rows: 100 total: 2575\n",
      "V - 3 page. Added rows: 100 total: 78\n",
      "PG - 14 page. Added rows: 100 total: 417\n",
      "UNH - 3 page. Added rows: 100 total: 81\n",
      "TRV - 5 page. Added rows: 65 total: 225\n",
      "NKE - 21 page. Added rows: 100 total: 753\n",
      "VZ - 2 page. Added rows: 100 total: 51\n",
      "MSFT - 29 page. Added rows: 100 total: 726\n",
      "MRK - 25 page. Added rows: 100 total: 1371\n",
      "WBA - 1 page. Added rows: 100 total: 21\n",
      "AAPL - 107 page. Added rows: 100 total: 2604\n",
      "Ticker TRV done\n",
      "NKE - 22 page. Added rows: 100 total: 853\n",
      "UNH - 4 page. Added rows: 100 total: 109\n",
      "VZ - 3 page. Added rows: 100 total: 74\n",
      "Ticker WBD done\n",
      "V - 4 page. Added rows: 100 total: 101\n",
      "PG - 15 page. Added rows: 100 total: 517\n",
      "WBA - 2 page. Added rows: 100 total: 48\n",
      "AAPL - 108 page. Added rows: 100 total: 2637\n",
      "MSFT - 30 page. Added rows: 100 total: 742\n",
      "Ticker WDC done\n",
      "UNH - 5 page. Added rows: 100 total: 140\n",
      "NKE - 23 page. Added rows: 100 total: 953\n",
      "MRK - 26 page. Added rows: 100 total: 1471\n",
      "VZ - 4 page. Added rows: 100 total: 96\n",
      "Ticker WEC done\n",
      "WBA - 3 page. Added rows: 100 total: 75\n",
      "V - 5 page. Added rows: 100 total: 125\n",
      "AAPL - 109 page. Added rows: 100 total: 2661\n",
      "Ticker WELL done\n",
      "MSFT - 31 page. Added rows: 100 total: 766\n",
      "Ticker WFC done\n",
      "PG - 16 page. Added rows: 100 total: 617\n",
      "Ticker WHR done\n",
      "WBA - 4 page. Added rows: 100 total: 103\n",
      "MRK - 27 page. Added rows: 100 total: 1571\n",
      "UNH - 6 page. Added rows: 100 total: 167\n",
      "VZ - 5 page. Added rows: 100 total: 121\n",
      "Ticker WM done\n",
      "Ticker WMB done\n",
      "AAPL - 110 page. Added rows: 100 total: 2685\n",
      "MSFT - 32 page. Added rows: 100 total: 792\n",
      "UNH - 7 page. Added rows: 100 total: 222\n",
      "PG - 17 page. Added rows: 100 total: 717\n",
      "WBA - 5 page. Added rows: 100 total: 184\n",
      "MRK - 28 page. Added rows: 100 total: 1671\n",
      "NKE - 24 page. Added rows: 100 total: 1053\n",
      "V - 6 page. Added rows: 100 total: 144\n",
      "VZ - 6 page. Added rows: 100 total: 146\n",
      "WMT - 1 page. Added rows: 100 total: 26\n",
      "AAPL - 111 page. Added rows: 100 total: 2715\n",
      "MSFT - 33 page. Added rows: 100 total: 818\n",
      "PG - 18 page. Added rows: 100 total: 814\n",
      "UNH - 8 page. Added rows: 100 total: 322\n",
      "V - 7 page. Added rows: 100 total: 172\n",
      "MRK - 29 page. Added rows: 100 total: 1771\n",
      "AAPL - 112 page. Added rows: 100 total: 2744\n",
      "WMT - 2 page. Added rows: 100 total: 55\n",
      "VZ - 7 page. Added rows: 100 total: 168\n",
      "WBA - 6 page. Added rows: 100 total: 284\n",
      "PG - 19 page. Added rows: 91 total: 905\n",
      "MSFT - 34 page. Added rows: 100 total: 845\n",
      "V - 8 page. Added rows: 100 total: 202\n",
      "MRK - 30 page. Added rows: 66 total: 1837\n",
      "NKE - 25 page. Added rows: 100 total: 1153\n",
      "AAPL - 113 page. Added rows: 100 total: 2773\n",
      "VZ - 8 page. Added rows: 100 total: 193\n",
      "WMT - 3 page. Added rows: 100 total: 81\n",
      "WBA - 7 page. Added rows: 100 total: 384\n",
      "Ticker PG done\n",
      "V - 9 page. Added rows: 100 total: 234\n",
      "Ticker WRB done\n",
      "AAPL - 114 page. Added rows: 100 total: 2800\n",
      "UNH - 9 page. Added rows: 100 total: 422\n",
      "Ticker WRK done\n",
      "WMT - 4 page. Added rows: 100 total: 108\n",
      "NKE - 26 page. Added rows: 100 total: 1253\n",
      "MSFT - 35 page. Added rows: 100 total: 871\n",
      "V - 10 page. Added rows: 100 total: 262\n",
      "VZ - 9 page. Added rows: 100 total: 222\n",
      "Ticker WST done\n",
      "Ticker MRK done\n",
      "AAPL - 115 page. Added rows: 100 total: 2824\n",
      "WMT - 5 page. Added rows: 100 total: 136\n",
      "Ticker WTW done\n",
      "Ticker WYNN done\n",
      "Ticker WY done\n",
      "V - 11 page. Added rows: 100 total: 290\n",
      "UNH - 10 page. Added rows: 100 total: 522\n",
      "MSFT - 36 page. Added rows: 100 total: 898\n",
      "Ticker XOM done\n",
      "Ticker XEL done\n",
      "Ticker XRAY done\n",
      "AAPL - 116 page. Added rows: 100 total: 2850\n",
      "WBA - 8 page. Added rows: 100 total: 484\n",
      "V - 12 page. Added rows: 100 total: 321\n",
      "Ticker XYL done\n",
      "WMT - 6 page. Added rows: 100 total: 162\n",
      "VZ - 10 page. Added rows: 100 total: 246\n",
      "Ticker YUM done\n",
      "UNH - 11 page. Added rows: 100 total: 622\n",
      "Ticker ZBH done\n",
      "NKE - 27 page. Added rows: 100 total: 1353\n",
      "MSFT - 37 page. Added rows: 100 total: 920\n",
      "V - 13 page. Added rows: 100 total: 407\n",
      "AAPL - 117 page. Added rows: 100 total: 2876\n",
      "Ticker ZBRA done\n",
      "Ticker ZION done\n",
      "WMT - 7 page. Added rows: 100 total: 188\n",
      "WBA - 9 page. Added rows: 100 total: 584\n",
      "UNH - 12 page. Added rows: 42 total: 664\n",
      "VZ - 11 page. Added rows: 100 total: 265\n",
      "Ticker ZTS done\n",
      "NKE - 28 page. Added rows: 100 total: 1453\n",
      "AAPL - 118 page. Added rows: 100 total: 2906\n",
      "MSFT - 38 page. Added rows: 100 total: 940WMT - 8 page. Added rows: 100 total: 210\n",
      "\n",
      "WBA - 10 page. Added rows: 100 total: 684\n",
      "VZ - 12 page. Added rows: 100 total: 290\n",
      "AAPL - 119 page. Added rows: 100 total: 2937\n",
      "Ticker UNH done\n",
      "V - 14 page. Added rows: 100 total: 507\n",
      "WMT - 9 page. Added rows: 100 total: 233\n",
      "NKE - 29 page. Added rows: 100 total: 1552\n",
      "MSFT - 39 page. Added rows: 100 total: 965\n",
      "AAPL - 120 page. Added rows: 100 total: 2960\n",
      "WBA - 11 page. Added rows: 100 total: 784\n",
      "VZ - 13 page. Added rows: 100 total: 312\n",
      "NKE - 30 page. Added rows: 100 total: 1652\n",
      "WMT - 10 page. Added rows: 100 total: 259\n",
      "AAPL - 121 page. Added rows: 100 total: 2994\n",
      "MSFT - 40 page. Added rows: 100 total: 991\n",
      "WBA - 12 page. Added rows: 70 total: 854\n",
      "NKE - 31 page. Added rows: 100 total: 1751\n",
      "V - 15 page. Added rows: 100 total: 607\n",
      "AAPL - 122 page. Added rows: 100 total: 3017\n",
      "VZ - 14 page. Added rows: 100 total: 334\n",
      "WMT - 11 page. Added rows: 100 total: 283\n",
      "MSFT - 41 page. Added rows: 100 total: 1024\n",
      "NKE - 32 page. Added rows: 100 total: 1851\n",
      "Ticker WBA done\n",
      "AAPL - 123 page. Added rows: 100 total: 3041\n",
      "V - 16 page. Added rows: 100 total: 707\n",
      "VZ - 15 page. Added rows: 100 total: 349\n",
      "NKE - 33 page. Added rows: 16 total: 1867\n",
      "MSFT - 42 page. Added rows: 100 total: 1051\n",
      "WMT - 12 page. Added rows: 100 total: 307\n",
      "AAPL - 124 page. Added rows: 100 total: 3071\n",
      "Ticker NKE done\n",
      "MSFT - 43 page. Added rows: 100 total: 1078\n",
      "V - 17 page. Added rows: 100 total: 807\n",
      "AAPL - 125 page. Added rows: 100 total: 3096\n",
      "WMT - 13 page. Added rows: 100 total: 333\n",
      "VZ - 16 page. Added rows: 100 total: 373\n",
      "MSFT - 44 page. Added rows: 100 total: 1112\n",
      "V - 18 page. Added rows: 100 total: 906\n",
      "AAPL - 126 page. Added rows: 100 total: 3122\n",
      "WMT - 14 page. Added rows: 100 total: 355\n",
      "VZ - 17 page. Added rows: 100 total: 400\n",
      "V - 19 page. Added rows: 100 total: 1005\n",
      "MSFT - 45 page. Added rows: 100 total: 1135\n",
      "AAPL - 127 page. Added rows: 100 total: 3151\n",
      "VZ - 18 page. Added rows: 100 total: 432\n",
      "WMT - 15 page. Added rows: 100 total: 382\n",
      "MSFT - 46 page. Added rows: 100 total: 1166\n",
      "V - 20 page. Added rows: 65 total: 1070\n",
      "VZ - 19 page. Added rows: 100 total: 461\n",
      "AAPL - 128 page. Added rows: 100 total: 3172\n",
      "Ticker V done\n",
      "MSFT - 47 page. Added rows: 100 total: 1197\n",
      "WMT - 16 page. Added rows: 100 total: 402\n",
      "VZ - 20 page. Added rows: 100 total: 487\n",
      "AAPL - 129 page. Added rows: 100 total: 3196\n",
      "MSFT - 48 page. Added rows: 100 total: 1227\n",
      "VZ - 21 page. Added rows: 100 total: 515\n",
      "WMT - 17 page. Added rows: 100 total: 424\n",
      "AAPL - 130 page. Added rows: 100 total: 3221\n",
      "MSFT - 49 page. Added rows: 100 total: 1257\n",
      "VZ - 22 page. Added rows: 100 total: 540\n",
      "AAPL - 131 page. Added rows: 100 total: 3244\n",
      "WMT - 18 page. Added rows: 100 total: 445\n",
      "VZ - 23 page. Added rows: 100 total: 562\n",
      "MSFT - 50 page. Added rows: 100 total: 1283\n",
      "AAPL - 132 page. Added rows: 100 total: 3273\n",
      "WMT - 19 page. Added rows: 100 total: 474\n",
      "MSFT - 51 page. Added rows: 100 total: 1306\n",
      "VZ - 24 page. Added rows: 100 total: 590\n",
      "AAPL - 133 page. Added rows: 100 total: 3295\n",
      "WMT - 20 page. Added rows: 100 total: 506\n",
      "MSFT - 52 page. Added rows: 100 total: 1329\n",
      "VZ - 25 page. Added rows: 100 total: 617\n",
      "WMT - 21 page. Added rows: 100 total: 534\n",
      "AAPL - 134 page. Added rows: 100 total: 3315\n",
      "WMT - 22 page. Added rows: 100 total: 560\n",
      "AAPL - 135 page. Added rows: 100 total: 3340\n",
      "MSFT - 53 page. Added rows: 100 total: 1356\n",
      "VZ - 26 page. Added rows: 100 total: 647\n",
      "WMT - 23 page. Added rows: 100 total: 585\n",
      "AAPL - 136 page. Added rows: 100 total: 3366\n",
      "MSFT - 54 page. Added rows: 100 total: 1384\n",
      "WMT - 24 page. Added rows: 100 total: 613\n",
      "VZ - 27 page. Added rows: 100 total: 677\n",
      "AAPL - 137 page. Added rows: 100 total: 3391\n",
      "MSFT - 55 page. Added rows: 100 total: 1409\n",
      "WMT - 25 page. Added rows: 100 total: 633\n",
      "VZ - 28 page. Added rows: 100 total: 756\n",
      "AAPL - 138 page. Added rows: 100 total: 3418\n",
      "MSFT - 56 page. Added rows: 100 total: 1434\n",
      "WMT - 26 page. Added rows: 100 total: 665\n",
      "AAPL - 139 page. Added rows: 100 total: 3441\n",
      "VZ - 29 page. Added rows: 100 total: 856\n",
      "MSFT - 57 page. Added rows: 100 total: 1460\n",
      "WMT - 27 page. Added rows: 100 total: 691\n",
      "AAPL - 140 page. Added rows: 100 total: 3466\n",
      "VZ - 30 page. Added rows: 100 total: 956\n",
      "WMT - 28 page. Added rows: 100 total: 718\n",
      "MSFT - 58 page. Added rows: 100 total: 1490\n",
      "AAPL - 141 page. Added rows: 100 total: 3493\n",
      "VZ - 31 page. Added rows: 100 total: 1056\n",
      "WMT - 29 page. Added rows: 100 total: 748\n",
      "MSFT - 59 page. Added rows: 100 total: 1519\n",
      "AAPL - 142 page. Added rows: 100 total: 3525\n",
      "WMT - 30 page. Added rows: 100 total: 777\n",
      "MSFT - 60 page. Added rows: 100 total: 1540\n",
      "AAPL - 143 page. Added rows: 100 total: 3556\n",
      "AAPL - 144 page. Added rows: 100 total: 3582\n",
      "MSFT - 61 page. Added rows: 100 total: 1564\n",
      "WMT - 31 page. Added rows: 100 total: 809\n",
      "VZ - 32 page. Added rows: 100 total: 1156\n",
      "AAPL - 145 page. Added rows: 100 total: 3614\n",
      "WMT - 32 page. Added rows: 100 total: 908\n",
      "AAPL - 146 page. Added rows: 100 total: 3643\n",
      "MSFT - 62 page. Added rows: 100 total: 1651\n",
      "VZ - 33 page. Added rows: 100 total: 1256\n",
      "WMT - 33 page. Added rows: 100 total: 1008\n",
      "AAPL - 147 page. Added rows: 100 total: 3677\n",
      "MSFT - 63 page. Added rows: 100 total: 1751\n",
      "VZ - 34 page. Added rows: 100 total: 1355\n",
      "WMT - 34 page. Added rows: 100 total: 1108\n",
      "AAPL - 148 page. Added rows: 100 total: 3706\n",
      "MSFT - 64 page. Added rows: 100 total: 1851\n",
      "VZ - 35 page. Added rows: 100 total: 1455\n",
      "AAPL - 149 page. Added rows: 100 total: 3735\n",
      "WMT - 35 page. Added rows: 100 total: 1208\n",
      "MSFT - 65 page. Added rows: 100 total: 1951\n",
      "VZ - 36 page. Added rows: 100 total: 1555\n",
      "AAPL - 150 page. Added rows: 100 total: 3761\n",
      "WMT - 36 page. Added rows: 100 total: 1308\n",
      "MSFT - 66 page. Added rows: 100 total: 2051\n",
      "AAPL - 151 page. Added rows: 100 total: 3795\n",
      "VZ - 37 page. Added rows: 100 total: 1655\n",
      "WMT - 37 page. Added rows: 100 total: 1408\n",
      "MSFT - 67 page. Added rows: 100 total: 2151\n",
      "AAPL - 152 page. Added rows: 100 total: 3895\n",
      "VZ - 38 page. Added rows: 39 total: 1694\n",
      "WMT - 38 page. Added rows: 100 total: 1508\n",
      "MSFT - 68 page. Added rows: 100 total: 2251\n",
      "Ticker VZ done\n",
      "AAPL - 153 page. Added rows: 100 total: 3995\n",
      "WMT - 39 page. Added rows: 100 total: 1608\n",
      "AAPL - 154 page. Added rows: 100 total: 4095\n",
      "WMT - 40 page. Added rows: 100 total: 1708\n",
      "MSFT - 69 page. Added rows: 100 total: 2351\n",
      "AAPL - 155 page. Added rows: 100 total: 4195\n",
      "MSFT - 70 page. Added rows: 100 total: 2451\n",
      "WMT - 41 page. Added rows: 100 total: 1808\n",
      "AAPL - 156 page. Added rows: 100 total: 4295\n",
      "WMT - 42 page. Added rows: 100 total: 1908\n",
      "AAPL - 157 page. Added rows: 100 total: 4395\n",
      "MSFT - 71 page. Added rows: 100 total: 2551\n",
      "WMT - 43 page. Added rows: 100 total: 2008\n",
      "MSFT - 72 page. Added rows: 100 total: 2651\n",
      "AAPL - 158 page. Added rows: 100 total: 4495\n",
      "WMT - 44 page. Added rows: 100 total: 2108\n",
      "WMT - 45 page. Added rows: 100 total: 2208\n",
      "AAPL - 159 page. Added rows: 100 total: 4595\n",
      "MSFT - 73 page. Added rows: 100 total: 2751\n",
      "WMT - 46 page. Added rows: 100 total: 2308\n",
      "AAPL - 160 page. Added rows: 100 total: 4694\n",
      "MSFT - 74 page. Added rows: 100 total: 2851\n",
      "WMT - 47 page. Added rows: 100 total: 2408\n",
      "MSFT - 75 page. Added rows: 100 total: 2951\n",
      "AAPL - 161 page. Added rows: 100 total: 4794\n",
      "WMT - 48 page. Added rows: 100 total: 2508\n",
      "AAPL - 162 page. Added rows: 100 total: 4894\n",
      "MSFT - 76 page. Added rows: 100 total: 3051\n",
      "AAPL - 163 page. Added rows: 100 total: 4994\n",
      "WMT - 49 page. Added rows: 100 total: 2608\n",
      "MSFT - 77 page. Added rows: 100 total: 3151\n",
      "AAPL - 164 page. Added rows: 100 total: 5094\n",
      "WMT - 50 page. Added rows: 100 total: 2708\n",
      "MSFT - 78 page. Added rows: 100 total: 3251\n",
      "AAPL - 165 page. Added rows: 100 total: 5194\n",
      "MSFT - 79 page. Added rows: 100 total: 3351\n",
      "WMT - 51 page. Added rows: 100 total: 2807\n",
      "AAPL - 166 page. Added rows: 100 total: 5294\n",
      "MSFT - 80 page. Added rows: 100 total: 3451\n",
      "WMT - 52 page. Added rows: 100 total: 2907\n",
      "AAPL - 167 page. Added rows: 100 total: 5394\n",
      "MSFT - 81 page. Added rows: 100 total: 3551\n",
      "WMT - 53 page. Added rows: 100 total: 3007\n",
      "MSFT - 82 page. Added rows: 100 total: 3651\n",
      "WMT - 54 page. Added rows: 100 total: 3107\n",
      "AAPL - 168 page. Added rows: 100 total: 5493\n",
      "WMT - 55 page. Added rows: 56 total: 3163\n",
      "MSFT - 83 page. Added rows: 100 total: 3751\n",
      "AAPL - 169 page. Added rows: 100 total: 5593\n",
      "MSFT - 84 page. Added rows: 100 total: 3851\n",
      "Ticker WMT done\n",
      "AAPL - 170 page. Added rows: 100 total: 5693\n",
      "MSFT - 85 page. Added rows: 100 total: 3951\n",
      "MSFT - 86 page. Added rows: 100 total: 4051\n",
      "AAPL - 171 page. Added rows: 100 total: 5793\n",
      "MSFT - 87 page. Added rows: 100 total: 4150\n",
      "AAPL - 172 page. Added rows: 100 total: 5893\n",
      "MSFT - 88 page. Added rows: 100 total: 4245\n",
      "AAPL - 173 page. Added rows: 100 total: 5993\n",
      "MSFT - 89 page. Added rows: 100 total: 4344\n",
      "AAPL - 174 page. Added rows: 100 total: 6093\n",
      "MSFT - 90 page. Added rows: 100 total: 4440\n",
      "AAPL - 175 page. Added rows: 100 total: 6193\n",
      "MSFT - 91 page. Added rows: 100 total: 4538\n",
      "AAPL - 176 page. Added rows: 100 total: 6293\n",
      "MSFT - 92 page. Added rows: 100 total: 4637\n",
      "MSFT - 93 page. Added rows: 100 total: 4733\n",
      "AAPL - 177 page. Added rows: 100 total: 6393\n",
      "MSFT - 94 page. Added rows: 100 total: 4828\n",
      "AAPL - 178 page. Added rows: 100 total: 6493\n",
      "MSFT - 95 page. Added rows: 100 total: 4928\n",
      "AAPL - 179 page. Added rows: 100 total: 6593\n",
      "MSFT - 96 page. Added rows: 100 total: 5026\n",
      "AAPL - 180 page. Added rows: 100 total: 6693\n",
      "MSFT - 97 page. Added rows: 100 total: 5125\n",
      "AAPL - 181 page. Added rows: 100 total: 6793\n",
      "MSFT - 98 page. Added rows: 100 total: 5225\n",
      "AAPL - 182 page. Added rows: 100 total: 6893\n",
      "AAPL - 183 page. Added rows: 100 total: 6993\n",
      "MSFT - 99 page. Added rows: 100 total: 5324\n",
      "AAPL - 184 page. Added rows: 100 total: 7093\n",
      "MSFT - 100 page. Added rows: 100 total: 5423\n",
      "MSFT - 101 page. Added rows: 100 total: 5523\n",
      "AAPL - 185 page. Added rows: 100 total: 7193\n",
      "AAPL - 186 page. Added rows: 100 total: 7293\n",
      "MSFT - 102 page. Added rows: 100 total: 5621\n",
      "AAPL - 187 page. Added rows: 100 total: 7393\n",
      "MSFT - 103 page. Added rows: 100 total: 5721\n",
      "AAPL - 188 page. Added rows: 100 total: 7493\n",
      "MSFT - 104 page. Added rows: 100 total: 5821\n",
      "AAPL - 189 page. Added rows: 100 total: 7593\n",
      "MSFT - 105 page. Added rows: 100 total: 5921\n",
      "AAPL - 190 page. Added rows: 100 total: 7693\n",
      "MSFT - 106 page. Added rows: 100 total: 6021\n",
      "MSFT - 107 page. Added rows: 100 total: 6121\n",
      "AAPL - 191 page. Added rows: 100 total: 7793\n",
      "MSFT - 108 page. Added rows: 100 total: 6219\n",
      "AAPL - 192 page. Added rows: 100 total: 7893\n",
      "MSFT - 109 page. Added rows: 100 total: 6319\n",
      "AAPL - 193 page. Added rows: 100 total: 7993\n",
      "MSFT - 110 page. Added rows: 100 total: 6418\n",
      "AAPL - 194 page. Added rows: 100 total: 8093\n",
      "MSFT - 111 page. Added rows: 100 total: 6518\n",
      "AAPL - 195 page. Added rows: 100 total: 8193\n",
      "MSFT - 112 page. Added rows: 100 total: 6618\n",
      "AAPL - 196 page. Added rows: 100 total: 8293\n",
      "MSFT - 113 page. Added rows: 100 total: 6718\n",
      "AAPL - 197 page. Added rows: 100 total: 8393\n",
      "MSFT - 114 page. Added rows: 100 total: 6818\n",
      "AAPL - 198 page. Added rows: 100 total: 8493\n",
      "MSFT - 115 page. Added rows: 100 total: 6918\n",
      "AAPL - 199 page. Added rows: 100 total: 8593\n",
      "AAPL - 200 page. Added rows: 100 total: 8693\n",
      "MSFT - 116 page. Added rows: 100 total: 7018\n",
      "MSFT - 117 page. Added rows: 36 total: 7054\n",
      "AAPL - 201 page. Added rows: 100 total: 8792\n",
      "Ticker MSFT done\n",
      "AAPL - 202 page. Added rows: 100 total: 8892\n",
      "AAPL - 203 page. Added rows: 100 total: 8986\n",
      "AAPL - 204 page. Added rows: 100 total: 9085\n",
      "AAPL - 205 page. Added rows: 100 total: 9185\n",
      "AAPL - 206 page. Added rows: 100 total: 9284\n",
      "AAPL - 207 page. Added rows: 100 total: 9382\n",
      "AAPL - 208 page. Added rows: 100 total: 9481\n",
      "AAPL - 209 page. Added rows: 100 total: 9581\n",
      "AAPL - 210 page. Added rows: 100 total: 9680\n",
      "AAPL - 211 page. Added rows: 100 total: 9780\n",
      "AAPL - 212 page. Added rows: 100 total: 9880\n",
      "AAPL - 213 page. Added rows: 100 total: 9980\n",
      "AAPL - 214 page. Added rows: 100 total: 10078\n",
      "AAPL - 215 page. Added rows: 100 total: 10176\n",
      "AAPL - 216 page. Added rows: 100 total: 10276\n",
      "AAPL - 217 page. Added rows: 100 total: 10376\n",
      "AAPL - 218 page. Added rows: 100 total: 10475\n",
      "AAPL - 219 page. Added rows: 100 total: 10575\n",
      "AAPL - 220 page. Added rows: 100 total: 10674\n",
      "AAPL - 221 page. Added rows: 100 total: 10774\n",
      "AAPL - 222 page. Added rows: 100 total: 10874\n",
      "AAPL - 223 page. Added rows: 100 total: 10974\n",
      "AAPL - 224 page. Added rows: 100 total: 11074\n",
      "AAPL - 225 page. Added rows: 100 total: 11174\n",
      "AAPL - 226 page. Added rows: 100 total: 11274\n",
      "AAPL - 227 page. Added rows: 100 total: 11373\n",
      "AAPL - 228 page. Added rows: 100 total: 11472\n",
      "AAPL - 229 page. Added rows: 100 total: 11571\n",
      "AAPL - 230 page. Added rows: 100 total: 11671\n",
      "AAPL - 231 page. Added rows: 100 total: 11771\n",
      "AAPL - 232 page. Added rows: 100 total: 11870\n",
      "AAPL - 233 page. Added rows: 100 total: 11968\n",
      "AAPL - 234 page. Added rows: 100 total: 12068\n",
      "AAPL - 235 page. Added rows: 100 total: 12168\n",
      "AAPL - 236 page. Added rows: 100 total: 12268\n",
      "AAPL - 237 page. Added rows: 100 total: 12368\n",
      "AAPL - 238 page. Added rows: 100 total: 12468\n",
      "AAPL - 239 page. Added rows: 100 total: 12568\n",
      "AAPL - 240 page. Added rows: 100 total: 12667\n",
      "AAPL - 241 page. Added rows: 100 total: 12767\n",
      "AAPL - 242 page. Added rows: 100 total: 12866\n",
      "AAPL - 243 page. Added rows: 100 total: 12966\n",
      "AAPL - 244 page. Added rows: 100 total: 13066\n",
      "AAPL - 245 page. Added rows: 100 total: 13166\n",
      "AAPL - 246 page. Added rows: 12 total: 13178\n",
      "Ticker AAPL done\n"
     ]
    }
   ],
   "source": [
    "create_datasets_folder()\n",
    "run_concurent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83fc70a9-5ae6-476d-b40b-ecceaa1d9ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in total 45407\n"
     ]
    }
   ],
   "source": [
    "merge_all_in_one_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "706d25f3-0809-461d-8d51-314485516138",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T11:21:47.363603Z",
     "start_time": "2024-02-05T11:21:45.773864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updated</th>\n",
       "      <th>stocks</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>BROAD</td>\n",
       "      <td>Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>BZSUM</td>\n",
       "      <td>Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>CAR</td>\n",
       "      <td>Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>EARLY</td>\n",
       "      <td>Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     updated stocks                                               body\n",
       "1 2013-01-02   AAPL  Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...\n",
       "1 2013-01-02  BROAD  Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...\n",
       "1 2013-01-02  BZSUM  Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...\n",
       "1 2013-01-02    CAR  Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...\n",
       "1 2013-01-02  EARLY  Futures Up Strong on Fiscal Cliff Deal\\nU.S. e..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news = pd.read_csv('datasets/news_sp_500.csv').iloc[:,2:][['updated', 'stocks', 'body']].dropna()\n",
    "\n",
    "df_news['stocks'] = df_news['stocks'].apply(eval).apply(lambda x: [entry['name'] for entry in x])\n",
    "\n",
    "df_news = df_news.explode('stocks')\n",
    "\n",
    "df_news['updated'] = pd.to_datetime(df_news['updated']).dt.tz_localize(None)\n",
    "\n",
    "df_news['updated'] = df_news['updated'].dt.date\n",
    "df_news['updated'] = pd.to_datetime(df_news['updated'])\n",
    "\n",
    "df_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41b47bf2-febd-4aa5-aab5-24aac8edfcaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T11:22:22.738017Z",
     "start_time": "2024-02-05T11:22:22.583165Z"
    }
   },
   "outputs": [],
   "source": [
    "df_stocks = stocks[['Symbol', 'Adj Close']]\n",
    "df_stocks['pct_diff'] = df_stocks.groupby('Symbol')['Adj Close'].pct_change() * 100\n",
    "df_stocks = df_stocks.dropna().reset_index()\n",
    "df_stocks['Date'] = pd.to_datetime(df_stocks['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd2fb002-f2b3-49e3-88e9-2793d3b2e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_news.merge(df_stocks,\n",
    "                          how='inner',\n",
    "                          left_on=['updated', 'stocks'],\n",
    "                          right_on=['Date', 'Symbol'])[['Symbol', 'body', 'pct_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fc54f65-b23b-45df-93f7-8f431a671ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datasets/merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e092b6e1-7123-418d-8772-0500878b5c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.read_csv('datasets/merged.csv')[['Symbol', 'body', 'pct_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21c4e0e2-e0cc-47e3-bf2c-96c72a41486f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>body</th>\n",
       "      <th>pct_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Microsoft (NASDAQ: MSFT) has purchased technol...</td>\n",
       "      <td>-1.262273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple (NASDAQ: AAPL) is reportedly interested ...</td>\n",
       "      <td>-1.262273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>The year has opened with a bit of good news fo...</td>\n",
       "      <td>-1.262273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>On Thursday, the NASDAQ stock market is appare...</td>\n",
       "      <td>-1.262273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Sony (NYSE: SNE) is getting a lot of attention...</td>\n",
       "      <td>-1.262273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143526</th>\n",
       "      <td>EBAY</td>\n",
       "      <td>After Ford Motor (NYSE:F) decided to cut the o...</td>\n",
       "      <td>-1.572028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143527</th>\n",
       "      <td>F</td>\n",
       "      <td>After Ford Motor (NYSE:F) decided to cut the o...</td>\n",
       "      <td>1.991338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143528</th>\n",
       "      <td>WMT</td>\n",
       "      <td>After Ford Motor (NYSE:F) decided to cut the o...</td>\n",
       "      <td>0.333254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143529</th>\n",
       "      <td>WMT</td>\n",
       "      <td>Walmart Inc. (NYSE:WMT) announced on Tuesday e...</td>\n",
       "      <td>0.333254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143530</th>\n",
       "      <td>WMT</td>\n",
       "      <td>Walmart Inc.(NYSE:WMT) is planning to build o...</td>\n",
       "      <td>-0.205324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143531 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Symbol                                               body  pct_diff\n",
       "0        AAPL  Microsoft (NASDAQ: MSFT) has purchased technol... -1.262273\n",
       "1        AAPL  Apple (NASDAQ: AAPL) is reportedly interested ... -1.262273\n",
       "2        AAPL  The year has opened with a bit of good news fo... -1.262273\n",
       "3        AAPL  On Thursday, the NASDAQ stock market is appare... -1.262273\n",
       "4        AAPL  Sony (NYSE: SNE) is getting a lot of attention... -1.262273\n",
       "...       ...                                                ...       ...\n",
       "143526   EBAY  After Ford Motor (NYSE:F) decided to cut the o... -1.572028\n",
       "143527      F  After Ford Motor (NYSE:F) decided to cut the o...  1.991338\n",
       "143528    WMT  After Ford Motor (NYSE:F) decided to cut the o...  0.333254\n",
       "143529    WMT  Walmart Inc. (NYSE:WMT) announced on Tuesday e...  0.333254\n",
       "143530    WMT  Walmart Inc.(NYSE:WMT) is planning to build o... -0.205324\n",
       "\n",
       "[143531 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "32873556-8a33-48e0-ac02-b7e2276f6478",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T09:56:55.906456Z",
     "start_time": "2024-02-05T09:56:54.297535Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/teal/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /Users/teal/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b409687-a7b3-47a3-ae45-621aadcd372e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T09:56:56.037241Z",
     "start_time": "2024-02-05T09:56:56.023818Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_to_wordlist(text, remove_stop_words=True, stem_words=False): \n",
    "    text = text.replace('\\n', '')\n",
    "    text = text.replace('\\r\\r', '')\n",
    "    text = re.sub(r\"[^A-Za-z0-9]\", \" \", text).lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation from text\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "    if remove_stop_words:\n",
    "        stop_words = set(stopwords.words(\"english\")) \n",
    "        word_tokens = word_tokenize(text) \n",
    "        text = [word for word in word_tokens if word not in stop_words] \n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "    if stem_words:\n",
    "        # text = text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        text = [stemmer.stem(word) for word in text]\n",
    "    \n",
    "    # Return a list of words\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dd0e6fb-f9a2-444d-93c8-697a4b5e19b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T09:56:59.928672Z",
     "start_time": "2024-02-05T09:56:59.765906Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_merged[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody_preprocessed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_merged\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbody\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_to_wordlist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstem_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PythonProjects/HSE/Portfolio_Optimisation/env/lib/python3.11/site-packages/pandas/core/series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4640\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4762\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4764\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PythonProjects/HSE/Portfolio_Optimisation/env/lib/python3.11/site-packages/pandas/core/apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PythonProjects/HSE/Portfolio_Optimisation/env/lib/python3.11/site-packages/pandas/core/apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/PythonProjects/HSE/Portfolio_Optimisation/env/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PythonProjects/HSE/Portfolio_Optimisation/env/lib/python3.11/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1818\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_merged[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody_preprocessed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_merged[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mtext_to_wordlist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstem_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[18], line 20\u001b[0m, in \u001b[0;36mtext_to_wordlist\u001b[0;34m(text, remove_stop_words, stem_words)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stem_words:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# text = text.split()\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     stemmer \u001b[38;5;241m=\u001b[39m SnowballStemmer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mstemmer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Return a list of words\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "Cell \u001b[0;32mIn[18], line 20\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stem_words:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# text = text.split()\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     stemmer \u001b[38;5;241m=\u001b[39m SnowballStemmer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     text \u001b[38;5;241m=\u001b[39m [\u001b[43mstemmer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m text]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Return a list of words\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[0;32m~/PythonProjects/HSE/Portfolio_Optimisation/env/lib/python3.11/site-packages/nltk/stem/snowball.py:1578\u001b[0m, in \u001b[0;36mEnglishStemmer.stem\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;66;03m# STEP 2\u001b[39;00m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step2_suffixes:\n\u001b[0;32m-> 1578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mword\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendswith\u001b[49m\u001b[43m(\u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1579\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m r1\u001b[38;5;241m.\u001b[39mendswith(suffix):\n\u001b[1;32m   1580\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtional\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_merged['body_preprocessed'] = df_merged['body'].apply(lambda x: text_to_wordlist(x, stem_words=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "98ad11a1-5ef7-4fa2-94ab-b8236171df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    input=\"content\",\n",
    "    tokenizer=text_to_wordlist,\n",
    "    token_pattern=None,\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_merged, df_merged[\"pct_diff\"], test_size=0.3)\n",
    "\n",
    "\n",
    "X_train_body_vectorized = vectorizer.fit_transform(X_train[\"body\"])\n",
    "X_test_body_vectorized = vectorizer.transform(X_test[\"body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9d48feca-bc1c-4dba-82a6-fcd106497927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "encoder = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "\n",
    "X_train_encoded = encoder.fit_transform(np.array(X_train['Symbol']).reshape(-1, 1))\n",
    "X_train_proccesed = hstack([X_train_body_vectorized, X_train_encoded])\n",
    "\n",
    "X_test_encoded = encoder.transform(np.array(X_test['Symbol']).reshape(-1, 1))\n",
    "X_test_proccesed = hstack([X_test_body_vectorized, X_test_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6775feec-17a4-4862-8e87-fdfca55a34a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.084821\n",
      "0:\tlearn: 3.5141730\ttotal: 1.04s\tremaining: 17m 20s\n",
      "1:\tlearn: 3.4933734\ttotal: 1.81s\tremaining: 15m 3s\n",
      "2:\tlearn: 3.4747799\ttotal: 2.56s\tremaining: 14m 10s\n",
      "3:\tlearn: 3.4595400\ttotal: 3.41s\tremaining: 14m 9s\n",
      "4:\tlearn: 3.4453526\ttotal: 4.22s\tremaining: 14m\n",
      "5:\tlearn: 3.4327733\ttotal: 5.1s\tremaining: 14m 4s\n",
      "6:\tlearn: 3.4229517\ttotal: 5.99s\tremaining: 14m 10s\n",
      "7:\tlearn: 3.4136131\ttotal: 6.86s\tremaining: 14m 10s\n",
      "8:\tlearn: 3.4062459\ttotal: 7.7s\tremaining: 14m 8s\n",
      "9:\tlearn: 3.3993854\ttotal: 8.55s\tremaining: 14m 6s\n",
      "10:\tlearn: 3.3927377\ttotal: 9.45s\tremaining: 14m 9s\n",
      "11:\tlearn: 3.3863389\ttotal: 10.4s\tremaining: 14m 14s\n",
      "12:\tlearn: 3.3814835\ttotal: 11.3s\tremaining: 14m 18s\n",
      "13:\tlearn: 3.3767415\ttotal: 12.2s\tremaining: 14m 17s\n",
      "14:\tlearn: 3.3728779\ttotal: 13.1s\tremaining: 14m 19s\n",
      "15:\tlearn: 3.3687898\ttotal: 13.9s\tremaining: 14m 15s\n",
      "16:\tlearn: 3.3645428\ttotal: 14.8s\tremaining: 14m 13s\n",
      "17:\tlearn: 3.3603848\ttotal: 15.6s\tremaining: 14m 9s\n",
      "18:\tlearn: 3.3569955\ttotal: 16.4s\tremaining: 14m 5s\n",
      "19:\tlearn: 3.3526755\ttotal: 17.2s\tremaining: 14m 4s\n",
      "20:\tlearn: 3.3496213\ttotal: 18.1s\tremaining: 14m 4s\n",
      "21:\tlearn: 3.3471218\ttotal: 19s\tremaining: 14m 6s\n",
      "22:\tlearn: 3.3443480\ttotal: 20s\tremaining: 14m 9s\n",
      "23:\tlearn: 3.3417189\ttotal: 20.9s\tremaining: 14m 11s\n",
      "24:\tlearn: 3.3367453\ttotal: 21.9s\tremaining: 14m 13s\n",
      "25:\tlearn: 3.3353397\ttotal: 22.8s\tremaining: 14m 13s\n",
      "26:\tlearn: 3.3334736\ttotal: 23.7s\tremaining: 14m 14s\n",
      "27:\tlearn: 3.3315496\ttotal: 24.5s\tremaining: 14m 11s\n",
      "28:\tlearn: 3.3300664\ttotal: 25.4s\tremaining: 14m 10s\n",
      "29:\tlearn: 3.3277107\ttotal: 26.3s\tremaining: 14m 11s\n",
      "30:\tlearn: 3.3259043\ttotal: 27.2s\tremaining: 14m 8s\n",
      "31:\tlearn: 3.3232604\ttotal: 28.1s\tremaining: 14m 9s\n",
      "32:\tlearn: 3.3220909\ttotal: 29s\tremaining: 14m 8s\n",
      "33:\tlearn: 3.3188054\ttotal: 29.9s\tremaining: 14m 8s\n",
      "34:\tlearn: 3.3172598\ttotal: 30.7s\tremaining: 14m 6s\n",
      "35:\tlearn: 3.3158741\ttotal: 31.6s\tremaining: 14m 6s\n",
      "36:\tlearn: 3.3134922\ttotal: 32.5s\tremaining: 14m 4s\n",
      "37:\tlearn: 3.3127162\ttotal: 33.3s\tremaining: 14m 2s\n",
      "38:\tlearn: 3.3117526\ttotal: 34.1s\tremaining: 14m 1s\n",
      "39:\tlearn: 3.3103217\ttotal: 35.1s\tremaining: 14m 1s\n",
      "40:\tlearn: 3.3083980\ttotal: 36s\tremaining: 14m 2s\n",
      "41:\tlearn: 3.3073333\ttotal: 36.9s\tremaining: 14m 2s\n",
      "42:\tlearn: 3.3061385\ttotal: 37.9s\tremaining: 14m 2s\n",
      "43:\tlearn: 3.3054238\ttotal: 38.7s\tremaining: 14m 1s\n",
      "44:\tlearn: 3.3031965\ttotal: 39.7s\tremaining: 14m 2s\n",
      "45:\tlearn: 3.3015332\ttotal: 40.5s\tremaining: 14m\n",
      "46:\tlearn: 3.3008178\ttotal: 41.4s\tremaining: 13m 59s\n",
      "47:\tlearn: 3.2997069\ttotal: 42.3s\tremaining: 13m 58s\n",
      "48:\tlearn: 3.2991725\ttotal: 43.1s\tremaining: 13m 57s\n",
      "49:\tlearn: 3.2969268\ttotal: 44.1s\tremaining: 13m 57s\n",
      "50:\tlearn: 3.2963241\ttotal: 44.9s\tremaining: 13m 56s\n",
      "51:\tlearn: 3.2950665\ttotal: 45.8s\tremaining: 13m 55s\n",
      "52:\tlearn: 3.2940492\ttotal: 46.6s\tremaining: 13m 53s\n",
      "53:\tlearn: 3.2938526\ttotal: 47.5s\tremaining: 13m 51s\n",
      "54:\tlearn: 3.2932733\ttotal: 48.4s\tremaining: 13m 51s\n",
      "55:\tlearn: 3.2926607\ttotal: 49.2s\tremaining: 13m 49s\n",
      "56:\tlearn: 3.2914231\ttotal: 50.1s\tremaining: 13m 48s\n",
      "57:\tlearn: 3.2903265\ttotal: 51s\tremaining: 13m 49s\n",
      "58:\tlearn: 3.2901289\ttotal: 51.8s\tremaining: 13m 46s\n",
      "59:\tlearn: 3.2894387\ttotal: 52.6s\tremaining: 13m 43s\n",
      "60:\tlearn: 3.2878479\ttotal: 53.5s\tremaining: 13m 44s\n",
      "61:\tlearn: 3.2873410\ttotal: 54.4s\tremaining: 13m 42s\n",
      "62:\tlearn: 3.2866694\ttotal: 55.4s\tremaining: 13m 44s\n",
      "63:\tlearn: 3.2856669\ttotal: 56.3s\tremaining: 13m 43s\n",
      "64:\tlearn: 3.2849478\ttotal: 57.3s\tremaining: 13m 43s\n",
      "65:\tlearn: 3.2840509\ttotal: 58.6s\tremaining: 13m 49s\n",
      "66:\tlearn: 3.2834614\ttotal: 59.5s\tremaining: 13m 49s\n",
      "67:\tlearn: 3.2824301\ttotal: 1m\tremaining: 13m 47s\n",
      "68:\tlearn: 3.2806028\ttotal: 1m 1s\tremaining: 13m 45s\n",
      "69:\tlearn: 3.2803386\ttotal: 1m 1s\tremaining: 13m 39s\n",
      "70:\tlearn: 3.2798195\ttotal: 1m 2s\tremaining: 13m 35s\n",
      "71:\tlearn: 3.2790272\ttotal: 1m 2s\tremaining: 13m 30s\n",
      "72:\tlearn: 3.2782924\ttotal: 1m 3s\tremaining: 13m 25s\n",
      "73:\tlearn: 3.2778094\ttotal: 1m 4s\tremaining: 13m 21s\n",
      "74:\tlearn: 3.2769913\ttotal: 1m 4s\tremaining: 13m 17s\n",
      "75:\tlearn: 3.2757131\ttotal: 1m 5s\tremaining: 13m 14s\n",
      "76:\tlearn: 3.2744808\ttotal: 1m 5s\tremaining: 13m 9s\n",
      "77:\tlearn: 3.2735242\ttotal: 1m 6s\tremaining: 13m 6s\n",
      "78:\tlearn: 3.2732903\ttotal: 1m 6s\tremaining: 13m\n",
      "79:\tlearn: 3.2729694\ttotal: 1m 7s\tremaining: 12m 56s\n",
      "80:\tlearn: 3.2722142\ttotal: 1m 8s\tremaining: 12m 51s\n",
      "81:\tlearn: 3.2713386\ttotal: 1m 8s\tremaining: 12m 48s\n",
      "82:\tlearn: 3.2706098\ttotal: 1m 9s\tremaining: 12m 43s\n",
      "83:\tlearn: 3.2702244\ttotal: 1m 9s\tremaining: 12m 39s\n",
      "84:\tlearn: 3.2691864\ttotal: 1m 10s\tremaining: 12m 35s\n",
      "85:\tlearn: 3.2690119\ttotal: 1m 10s\tremaining: 12m 31s\n",
      "86:\tlearn: 3.2687247\ttotal: 1m 11s\tremaining: 12m 26s\n",
      "87:\tlearn: 3.2685425\ttotal: 1m 11s\tremaining: 12m 22s\n",
      "88:\tlearn: 3.2675583\ttotal: 1m 12s\tremaining: 12m 19s\n",
      "89:\tlearn: 3.2673992\ttotal: 1m 12s\tremaining: 12m 16s\n",
      "90:\tlearn: 3.2669033\ttotal: 1m 13s\tremaining: 12m 12s\n",
      "91:\tlearn: 3.2663078\ttotal: 1m 13s\tremaining: 12m 7s\n",
      "92:\tlearn: 3.2661507\ttotal: 1m 14s\tremaining: 12m 4s\n",
      "93:\tlearn: 3.2648379\ttotal: 1m 14s\tremaining: 12m 1s\n",
      "94:\tlearn: 3.2642984\ttotal: 1m 15s\tremaining: 11m 57s\n",
      "95:\tlearn: 3.2632289\ttotal: 1m 15s\tremaining: 11m 53s\n",
      "96:\tlearn: 3.2619502\ttotal: 1m 16s\tremaining: 11m 50s\n",
      "97:\tlearn: 3.2607738\ttotal: 1m 16s\tremaining: 11m 47s\n",
      "98:\tlearn: 3.2605459\ttotal: 1m 17s\tremaining: 11m 43s\n",
      "99:\tlearn: 3.2599912\ttotal: 1m 17s\tremaining: 11m 40s\n",
      "100:\tlearn: 3.2589982\ttotal: 1m 18s\tremaining: 11m 37s\n",
      "101:\tlearn: 3.2578642\ttotal: 1m 19s\tremaining: 11m 35s\n",
      "102:\tlearn: 3.2575634\ttotal: 1m 19s\tremaining: 11m 32s\n",
      "103:\tlearn: 3.2566311\ttotal: 1m 20s\tremaining: 11m 30s\n",
      "104:\tlearn: 3.2558146\ttotal: 1m 20s\tremaining: 11m 27s\n",
      "105:\tlearn: 3.2542495\ttotal: 1m 21s\tremaining: 11m 25s\n",
      "106:\tlearn: 3.2530630\ttotal: 1m 21s\tremaining: 11m 23s\n",
      "107:\tlearn: 3.2522870\ttotal: 1m 22s\tremaining: 11m 21s\n",
      "108:\tlearn: 3.2520230\ttotal: 1m 23s\tremaining: 11m 18s\n",
      "109:\tlearn: 3.2512856\ttotal: 1m 23s\tremaining: 11m 17s\n",
      "110:\tlearn: 3.2511288\ttotal: 1m 24s\tremaining: 11m 14s\n",
      "111:\tlearn: 3.2506355\ttotal: 1m 24s\tremaining: 11m 13s\n",
      "112:\tlearn: 3.2496352\ttotal: 1m 25s\tremaining: 11m 10s\n",
      "113:\tlearn: 3.2488219\ttotal: 1m 26s\tremaining: 11m 9s\n",
      "114:\tlearn: 3.2480197\ttotal: 1m 26s\tremaining: 11m 6s\n",
      "115:\tlearn: 3.2476190\ttotal: 1m 27s\tremaining: 11m 4s\n",
      "116:\tlearn: 3.2465218\ttotal: 1m 27s\tremaining: 11m 1s\n",
      "117:\tlearn: 3.2461227\ttotal: 1m 28s\tremaining: 10m 59s\n",
      "118:\tlearn: 3.2454443\ttotal: 1m 28s\tremaining: 10m 56s\n",
      "119:\tlearn: 3.2448941\ttotal: 1m 29s\tremaining: 10m 54s\n",
      "120:\tlearn: 3.2443391\ttotal: 1m 29s\tremaining: 10m 51s\n",
      "121:\tlearn: 3.2435704\ttotal: 1m 30s\tremaining: 10m 49s\n",
      "122:\tlearn: 3.2425415\ttotal: 1m 30s\tremaining: 10m 47s\n",
      "123:\tlearn: 3.2423489\ttotal: 1m 31s\tremaining: 10m 45s\n",
      "124:\tlearn: 3.2406647\ttotal: 1m 31s\tremaining: 10m 43s\n",
      "125:\tlearn: 3.2398183\ttotal: 1m 32s\tremaining: 10m 42s\n",
      "126:\tlearn: 3.2391199\ttotal: 1m 33s\tremaining: 10m 40s\n",
      "127:\tlearn: 3.2386222\ttotal: 1m 33s\tremaining: 10m 38s\n",
      "128:\tlearn: 3.2373157\ttotal: 1m 34s\tremaining: 10m 36s\n",
      "129:\tlearn: 3.2370506\ttotal: 1m 34s\tremaining: 10m 34s\n",
      "130:\tlearn: 3.2362946\ttotal: 1m 35s\tremaining: 10m 32s\n",
      "131:\tlearn: 3.2354118\ttotal: 1m 35s\tremaining: 10m 31s\n",
      "132:\tlearn: 3.2350202\ttotal: 1m 36s\tremaining: 10m 29s\n",
      "133:\tlearn: 3.2344420\ttotal: 1m 37s\tremaining: 10m 27s\n",
      "134:\tlearn: 3.2342040\ttotal: 1m 37s\tremaining: 10m 25s\n",
      "135:\tlearn: 3.2339779\ttotal: 1m 38s\tremaining: 10m 24s\n",
      "136:\tlearn: 3.2332478\ttotal: 1m 38s\tremaining: 10m 22s\n",
      "137:\tlearn: 3.2329128\ttotal: 1m 39s\tremaining: 10m 20s\n",
      "138:\tlearn: 3.2327184\ttotal: 1m 40s\tremaining: 10m 19s\n",
      "139:\tlearn: 3.2314226\ttotal: 1m 40s\tremaining: 10m 20s\n",
      "140:\tlearn: 3.2311889\ttotal: 1m 41s\tremaining: 10m 18s\n",
      "141:\tlearn: 3.2306973\ttotal: 1m 42s\tremaining: 10m 17s\n",
      "142:\tlearn: 3.2290912\ttotal: 1m 42s\tremaining: 10m 16s\n",
      "143:\tlearn: 3.2288859\ttotal: 1m 43s\tremaining: 10m 15s\n",
      "144:\tlearn: 3.2286937\ttotal: 1m 44s\tremaining: 10m 13s\n",
      "145:\tlearn: 3.2276196\ttotal: 1m 44s\tremaining: 10m 12s\n",
      "146:\tlearn: 3.2274078\ttotal: 1m 45s\tremaining: 10m 10s\n",
      "147:\tlearn: 3.2262387\ttotal: 1m 45s\tremaining: 10m 8s\n",
      "148:\tlearn: 3.2260466\ttotal: 1m 46s\tremaining: 10m 7s\n",
      "149:\tlearn: 3.2258590\ttotal: 1m 47s\tremaining: 10m 6s\n",
      "150:\tlearn: 3.2251135\ttotal: 1m 47s\tremaining: 10m 5s\n",
      "151:\tlearn: 3.2237681\ttotal: 1m 48s\tremaining: 10m 4s\n",
      "152:\tlearn: 3.2234318\ttotal: 1m 48s\tremaining: 10m 2s\n",
      "153:\tlearn: 3.2223095\ttotal: 1m 49s\tremaining: 10m 1s\n",
      "154:\tlearn: 3.2207790\ttotal: 1m 50s\tremaining: 10m\n",
      "155:\tlearn: 3.2198017\ttotal: 1m 50s\tremaining: 9m 59s\n",
      "156:\tlearn: 3.2196232\ttotal: 1m 51s\tremaining: 9m 58s\n",
      "157:\tlearn: 3.2180973\ttotal: 1m 52s\tremaining: 9m 57s\n",
      "158:\tlearn: 3.2179131\ttotal: 1m 52s\tremaining: 9m 56s\n",
      "159:\tlearn: 3.2177306\ttotal: 1m 53s\tremaining: 9m 54s\n",
      "160:\tlearn: 3.2163137\ttotal: 1m 53s\tremaining: 9m 53s\n",
      "161:\tlearn: 3.2154751\ttotal: 1m 54s\tremaining: 9m 52s\n",
      "162:\tlearn: 3.2148929\ttotal: 1m 55s\tremaining: 9m 51s\n",
      "163:\tlearn: 3.2141708\ttotal: 1m 55s\tremaining: 9m 49s\n",
      "164:\tlearn: 3.2136457\ttotal: 1m 56s\tremaining: 9m 48s\n",
      "165:\tlearn: 3.2134368\ttotal: 1m 56s\tremaining: 9m 47s\n",
      "166:\tlearn: 3.2126869\ttotal: 1m 57s\tremaining: 9m 46s\n",
      "167:\tlearn: 3.2124919\ttotal: 1m 58s\tremaining: 9m 44s\n",
      "168:\tlearn: 3.2123270\ttotal: 1m 58s\tremaining: 9m 43s\n",
      "169:\tlearn: 3.2120524\ttotal: 1m 59s\tremaining: 9m 42s\n",
      "170:\tlearn: 3.2116268\ttotal: 1m 59s\tremaining: 9m 40s\n",
      "171:\tlearn: 3.2106437\ttotal: 2m\tremaining: 9m 40s\n",
      "172:\tlearn: 3.2097971\ttotal: 2m 1s\tremaining: 9m 38s\n",
      "173:\tlearn: 3.2089272\ttotal: 2m 1s\tremaining: 9m 37s\n",
      "174:\tlearn: 3.2079373\ttotal: 2m 2s\tremaining: 9m 36s\n",
      "175:\tlearn: 3.2069838\ttotal: 2m 2s\tremaining: 9m 35s\n",
      "176:\tlearn: 3.2059296\ttotal: 2m 3s\tremaining: 9m 34s\n",
      "177:\tlearn: 3.2053893\ttotal: 2m 4s\tremaining: 9m 33s\n",
      "178:\tlearn: 3.2049742\ttotal: 2m 4s\tremaining: 9m 31s\n",
      "179:\tlearn: 3.2040920\ttotal: 2m 5s\tremaining: 9m 30s\n",
      "180:\tlearn: 3.2028636\ttotal: 2m 5s\tremaining: 9m 29s\n",
      "181:\tlearn: 3.2009970\ttotal: 2m 6s\tremaining: 9m 28s\n",
      "182:\tlearn: 3.2000422\ttotal: 2m 7s\tremaining: 9m 27s\n",
      "183:\tlearn: 3.1991203\ttotal: 2m 7s\tremaining: 9m 26s\n",
      "184:\tlearn: 3.1975849\ttotal: 2m 8s\tremaining: 9m 25s\n",
      "185:\tlearn: 3.1972389\ttotal: 2m 9s\tremaining: 9m 24s\n",
      "186:\tlearn: 3.1964613\ttotal: 2m 9s\tremaining: 9m 23s\n",
      "187:\tlearn: 3.1962906\ttotal: 2m 10s\tremaining: 9m 21s\n",
      "188:\tlearn: 3.1958702\ttotal: 2m 10s\tremaining: 9m 20s\n",
      "189:\tlearn: 3.1951476\ttotal: 2m 11s\tremaining: 9m 19s\n",
      "190:\tlearn: 3.1949812\ttotal: 2m 11s\tremaining: 9m 18s\n",
      "191:\tlearn: 3.1942512\ttotal: 2m 12s\tremaining: 9m 17s\n",
      "192:\tlearn: 3.1939998\ttotal: 2m 12s\tremaining: 9m 16s\n",
      "193:\tlearn: 3.1938390\ttotal: 2m 13s\tremaining: 9m 14s\n",
      "194:\tlearn: 3.1936782\ttotal: 2m 14s\tremaining: 9m 13s\n",
      "195:\tlearn: 3.1935362\ttotal: 2m 14s\tremaining: 9m 12s\n",
      "196:\tlearn: 3.1933895\ttotal: 2m 15s\tremaining: 9m 11s\n",
      "197:\tlearn: 3.1926628\ttotal: 2m 15s\tremaining: 9m 10s\n",
      "198:\tlearn: 3.1917879\ttotal: 2m 16s\tremaining: 9m 9s\n",
      "199:\tlearn: 3.1903174\ttotal: 2m 17s\tremaining: 9m 8s\n",
      "200:\tlearn: 3.1897414\ttotal: 2m 17s\tremaining: 9m 7s\n",
      "201:\tlearn: 3.1888188\ttotal: 2m 18s\tremaining: 9m 5s\n",
      "202:\tlearn: 3.1877945\ttotal: 2m 18s\tremaining: 9m 5s\n",
      "203:\tlearn: 3.1871584\ttotal: 2m 19s\tremaining: 9m 4s\n",
      "204:\tlearn: 3.1868849\ttotal: 2m 19s\tremaining: 9m 2s\n",
      "205:\tlearn: 3.1867291\ttotal: 2m 20s\tremaining: 9m 1s\n",
      "206:\tlearn: 3.1865695\ttotal: 2m 21s\tremaining: 9m\n",
      "207:\tlearn: 3.1860758\ttotal: 2m 21s\tremaining: 8m 59s\n",
      "208:\tlearn: 3.1852076\ttotal: 2m 22s\tremaining: 8m 58s\n",
      "209:\tlearn: 3.1848086\ttotal: 2m 22s\tremaining: 8m 57s\n",
      "210:\tlearn: 3.1840267\ttotal: 2m 23s\tremaining: 8m 56s\n",
      "211:\tlearn: 3.1831441\ttotal: 2m 24s\tremaining: 8m 55s\n",
      "212:\tlearn: 3.1822675\ttotal: 2m 24s\tremaining: 8m 54s\n",
      "213:\tlearn: 3.1818303\ttotal: 2m 25s\tremaining: 8m 53s\n",
      "214:\tlearn: 3.1808956\ttotal: 2m 25s\tremaining: 8m 53s\n",
      "215:\tlearn: 3.1804893\ttotal: 2m 26s\tremaining: 8m 51s\n",
      "216:\tlearn: 3.1798494\ttotal: 2m 27s\tremaining: 8m 51s\n",
      "217:\tlearn: 3.1796925\ttotal: 2m 27s\tremaining: 8m 49s\n",
      "218:\tlearn: 3.1795557\ttotal: 2m 28s\tremaining: 8m 49s\n",
      "219:\tlearn: 3.1786094\ttotal: 2m 28s\tremaining: 8m 48s\n",
      "220:\tlearn: 3.1782452\ttotal: 2m 29s\tremaining: 8m 47s\n",
      "221:\tlearn: 3.1780636\ttotal: 2m 30s\tremaining: 8m 46s\n",
      "222:\tlearn: 3.1776654\ttotal: 2m 30s\tremaining: 8m 45s\n",
      "223:\tlearn: 3.1775374\ttotal: 2m 31s\tremaining: 8m 44s\n",
      "224:\tlearn: 3.1772405\ttotal: 2m 32s\tremaining: 8m 43s\n",
      "225:\tlearn: 3.1761040\ttotal: 2m 32s\tremaining: 8m 43s\n",
      "226:\tlearn: 3.1758892\ttotal: 2m 33s\tremaining: 8m 42s\n",
      "227:\tlearn: 3.1755858\ttotal: 2m 33s\tremaining: 8m 41s\n",
      "228:\tlearn: 3.1748848\ttotal: 2m 34s\tremaining: 8m 40s\n",
      "229:\tlearn: 3.1743611\ttotal: 2m 35s\tremaining: 8m 39s\n",
      "230:\tlearn: 3.1735331\ttotal: 2m 35s\tremaining: 8m 38s\n",
      "231:\tlearn: 3.1730201\ttotal: 2m 36s\tremaining: 8m 37s\n",
      "232:\tlearn: 3.1721210\ttotal: 2m 37s\tremaining: 8m 36s\n",
      "233:\tlearn: 3.1716336\ttotal: 2m 37s\tremaining: 8m 35s\n",
      "234:\tlearn: 3.1712944\ttotal: 2m 38s\tremaining: 8m 34s\n",
      "235:\tlearn: 3.1705556\ttotal: 2m 38s\tremaining: 8m 34s\n",
      "236:\tlearn: 3.1699135\ttotal: 2m 39s\tremaining: 8m 33s\n",
      "237:\tlearn: 3.1693146\ttotal: 2m 40s\tremaining: 8m 32s\n",
      "238:\tlearn: 3.1685846\ttotal: 2m 40s\tremaining: 8m 31s\n",
      "239:\tlearn: 3.1681397\ttotal: 2m 41s\tremaining: 8m 30s\n",
      "240:\tlearn: 3.1676439\ttotal: 2m 41s\tremaining: 8m 29s\n",
      "241:\tlearn: 3.1673236\ttotal: 2m 42s\tremaining: 8m 28s\n",
      "242:\tlearn: 3.1671233\ttotal: 2m 42s\tremaining: 8m 27s\n",
      "243:\tlearn: 3.1661161\ttotal: 2m 43s\tremaining: 8m 26s\n",
      "244:\tlearn: 3.1653795\ttotal: 2m 44s\tremaining: 8m 25s\n",
      "245:\tlearn: 3.1650812\ttotal: 2m 44s\tremaining: 8m 24s\n",
      "246:\tlearn: 3.1645829\ttotal: 2m 45s\tremaining: 8m 23s\n",
      "247:\tlearn: 3.1642764\ttotal: 2m 45s\tremaining: 8m 23s\n",
      "248:\tlearn: 3.1635672\ttotal: 2m 46s\tremaining: 8m 22s\n",
      "249:\tlearn: 3.1630017\ttotal: 2m 47s\tremaining: 8m 21s\n",
      "250:\tlearn: 3.1620897\ttotal: 2m 47s\tremaining: 8m 20s\n",
      "251:\tlearn: 3.1611019\ttotal: 2m 48s\tremaining: 8m 19s\n",
      "252:\tlearn: 3.1606251\ttotal: 2m 49s\tremaining: 8m 19s\n",
      "253:\tlearn: 3.1600270\ttotal: 2m 49s\tremaining: 8m 18s\n",
      "254:\tlearn: 3.1593869\ttotal: 2m 50s\tremaining: 8m 17s\n",
      "255:\tlearn: 3.1588219\ttotal: 2m 51s\tremaining: 8m 17s\n",
      "256:\tlearn: 3.1582926\ttotal: 2m 51s\tremaining: 8m 16s\n",
      "257:\tlearn: 3.1579303\ttotal: 2m 52s\tremaining: 8m 15s\n",
      "258:\tlearn: 3.1565167\ttotal: 2m 53s\tremaining: 8m 14s\n",
      "259:\tlearn: 3.1556953\ttotal: 2m 53s\tremaining: 8m 14s\n",
      "260:\tlearn: 3.1555572\ttotal: 2m 54s\tremaining: 8m 13s\n",
      "261:\tlearn: 3.1549982\ttotal: 2m 54s\tremaining: 8m 12s\n",
      "262:\tlearn: 3.1545730\ttotal: 2m 55s\tremaining: 8m 12s\n",
      "263:\tlearn: 3.1541002\ttotal: 2m 56s\tremaining: 8m 11s\n",
      "264:\tlearn: 3.1533370\ttotal: 2m 57s\tremaining: 8m 11s\n",
      "265:\tlearn: 3.1524475\ttotal: 2m 57s\tremaining: 8m 10s\n",
      "266:\tlearn: 3.1520543\ttotal: 2m 58s\tremaining: 8m 10s\n",
      "267:\tlearn: 3.1513905\ttotal: 2m 59s\tremaining: 8m 9s\n",
      "268:\tlearn: 3.1504248\ttotal: 2m 59s\tremaining: 8m 8s\n",
      "269:\tlearn: 3.1495461\ttotal: 3m\tremaining: 8m 7s\n",
      "270:\tlearn: 3.1492136\ttotal: 3m 1s\tremaining: 8m 6s\n",
      "271:\tlearn: 3.1484594\ttotal: 3m 1s\tremaining: 8m 6s\n",
      "272:\tlearn: 3.1476131\ttotal: 3m 2s\tremaining: 8m 5s\n",
      "273:\tlearn: 3.1472838\ttotal: 3m 2s\tremaining: 8m 4s\n",
      "274:\tlearn: 3.1462668\ttotal: 3m 3s\tremaining: 8m 3s\n",
      "275:\tlearn: 3.1449549\ttotal: 3m 4s\tremaining: 8m 3s\n",
      "276:\tlearn: 3.1444733\ttotal: 3m 4s\tremaining: 8m 2s\n",
      "277:\tlearn: 3.1436144\ttotal: 3m 5s\tremaining: 8m 1s\n",
      "278:\tlearn: 3.1430762\ttotal: 3m 6s\tremaining: 8m\n",
      "279:\tlearn: 3.1427682\ttotal: 3m 6s\tremaining: 7m 59s\n",
      "280:\tlearn: 3.1422052\ttotal: 3m 7s\tremaining: 7m 58s\n",
      "281:\tlearn: 3.1416151\ttotal: 3m 7s\tremaining: 7m 57s\n",
      "282:\tlearn: 3.1413849\ttotal: 3m 8s\tremaining: 7m 57s\n",
      "283:\tlearn: 3.1406568\ttotal: 3m 8s\tremaining: 7m 56s\n",
      "284:\tlearn: 3.1405239\ttotal: 3m 9s\tremaining: 7m 55s\n",
      "285:\tlearn: 3.1401503\ttotal: 3m 10s\tremaining: 7m 54s\n",
      "286:\tlearn: 3.1400268\ttotal: 3m 10s\tremaining: 7m 53s\n",
      "287:\tlearn: 3.1398047\ttotal: 3m 11s\tremaining: 7m 52s\n",
      "288:\tlearn: 3.1396821\ttotal: 3m 11s\tremaining: 7m 51s\n",
      "289:\tlearn: 3.1395669\ttotal: 3m 12s\tremaining: 7m 51s\n",
      "290:\tlearn: 3.1392006\ttotal: 3m 12s\tremaining: 7m 50s\n",
      "291:\tlearn: 3.1386136\ttotal: 3m 13s\tremaining: 7m 49s\n",
      "292:\tlearn: 3.1381061\ttotal: 3m 14s\tremaining: 7m 48s\n",
      "293:\tlearn: 3.1377313\ttotal: 3m 14s\tremaining: 7m 47s\n",
      "294:\tlearn: 3.1369009\ttotal: 3m 15s\tremaining: 7m 46s\n",
      "295:\tlearn: 3.1365170\ttotal: 3m 16s\tremaining: 7m 46s\n",
      "296:\tlearn: 3.1362526\ttotal: 3m 16s\tremaining: 7m 45s\n",
      "297:\tlearn: 3.1358509\ttotal: 3m 17s\tremaining: 7m 44s\n",
      "298:\tlearn: 3.1351570\ttotal: 3m 17s\tremaining: 7m 43s\n",
      "299:\tlearn: 3.1348976\ttotal: 3m 18s\tremaining: 7m 42s\n",
      "300:\tlearn: 3.1342424\ttotal: 3m 18s\tremaining: 7m 42s\n",
      "301:\tlearn: 3.1337236\ttotal: 3m 19s\tremaining: 7m 41s\n",
      "302:\tlearn: 3.1334560\ttotal: 3m 20s\tremaining: 7m 40s\n",
      "303:\tlearn: 3.1326250\ttotal: 3m 20s\tremaining: 7m 39s\n",
      "304:\tlearn: 3.1321455\ttotal: 3m 21s\tremaining: 7m 38s\n",
      "305:\tlearn: 3.1314677\ttotal: 3m 21s\tremaining: 7m 37s\n",
      "306:\tlearn: 3.1311020\ttotal: 3m 22s\tremaining: 7m 36s\n",
      "307:\tlearn: 3.1302609\ttotal: 3m 22s\tremaining: 7m 36s\n",
      "308:\tlearn: 3.1300574\ttotal: 3m 23s\tremaining: 7m 35s\n",
      "309:\tlearn: 3.1296036\ttotal: 3m 24s\tremaining: 7m 34s\n",
      "310:\tlearn: 3.1285168\ttotal: 3m 24s\tremaining: 7m 33s\n",
      "311:\tlearn: 3.1283276\ttotal: 3m 25s\tremaining: 7m 32s\n",
      "312:\tlearn: 3.1273364\ttotal: 3m 25s\tremaining: 7m 32s\n",
      "313:\tlearn: 3.1268257\ttotal: 3m 26s\tremaining: 7m 31s\n",
      "314:\tlearn: 3.1265958\ttotal: 3m 27s\tremaining: 7m 30s\n",
      "315:\tlearn: 3.1256311\ttotal: 3m 27s\tremaining: 7m 29s\n",
      "316:\tlearn: 3.1255068\ttotal: 3m 28s\tremaining: 7m 28s\n",
      "317:\tlearn: 3.1248979\ttotal: 3m 28s\tremaining: 7m 27s\n",
      "318:\tlearn: 3.1247875\ttotal: 3m 29s\tremaining: 7m 27s\n",
      "319:\tlearn: 3.1243994\ttotal: 3m 30s\tremaining: 7m 26s\n",
      "320:\tlearn: 3.1233835\ttotal: 3m 30s\tremaining: 7m 25s\n",
      "321:\tlearn: 3.1231456\ttotal: 3m 31s\tremaining: 7m 24s\n",
      "322:\tlearn: 3.1224172\ttotal: 3m 31s\tremaining: 7m 24s\n",
      "323:\tlearn: 3.1221136\ttotal: 3m 32s\tremaining: 7m 23s\n",
      "324:\tlearn: 3.1212404\ttotal: 3m 33s\tremaining: 7m 22s\n",
      "325:\tlearn: 3.1206219\ttotal: 3m 33s\tremaining: 7m 22s\n",
      "326:\tlearn: 3.1201757\ttotal: 3m 34s\tremaining: 7m 21s\n",
      "327:\tlearn: 3.1196096\ttotal: 3m 35s\tremaining: 7m 20s\n",
      "328:\tlearn: 3.1190185\ttotal: 3m 35s\tremaining: 7m 19s\n",
      "329:\tlearn: 3.1187050\ttotal: 3m 36s\tremaining: 7m 19s\n",
      "330:\tlearn: 3.1183807\ttotal: 3m 36s\tremaining: 7m 18s\n",
      "331:\tlearn: 3.1178790\ttotal: 3m 37s\tremaining: 7m 17s\n",
      "332:\tlearn: 3.1171818\ttotal: 3m 37s\tremaining: 7m 16s\n",
      "333:\tlearn: 3.1165928\ttotal: 3m 38s\tremaining: 7m 15s\n",
      "334:\tlearn: 3.1158772\ttotal: 3m 39s\tremaining: 7m 15s\n",
      "335:\tlearn: 3.1151898\ttotal: 3m 39s\tremaining: 7m 14s\n",
      "336:\tlearn: 3.1141283\ttotal: 3m 40s\tremaining: 7m 13s\n",
      "337:\tlearn: 3.1135957\ttotal: 3m 40s\tremaining: 7m 12s\n",
      "338:\tlearn: 3.1134802\ttotal: 3m 41s\tremaining: 7m 11s\n",
      "339:\tlearn: 3.1126649\ttotal: 3m 42s\tremaining: 7m 11s\n",
      "340:\tlearn: 3.1121936\ttotal: 3m 42s\tremaining: 7m 10s\n",
      "341:\tlearn: 3.1118022\ttotal: 3m 43s\tremaining: 7m 9s\n",
      "342:\tlearn: 3.1111402\ttotal: 3m 43s\tremaining: 7m 8s\n",
      "343:\tlearn: 3.1105639\ttotal: 3m 44s\tremaining: 7m 8s\n",
      "344:\tlearn: 3.1101238\ttotal: 3m 45s\tremaining: 7m 7s\n",
      "345:\tlearn: 3.1094462\ttotal: 3m 45s\tremaining: 7m 6s\n",
      "346:\tlearn: 3.1091048\ttotal: 3m 46s\tremaining: 7m 5s\n",
      "347:\tlearn: 3.1087812\ttotal: 3m 46s\tremaining: 7m 5s\n",
      "348:\tlearn: 3.1079946\ttotal: 3m 47s\tremaining: 7m 4s\n",
      "349:\tlearn: 3.1070690\ttotal: 3m 48s\tremaining: 7m 3s\n",
      "350:\tlearn: 3.1065703\ttotal: 3m 48s\tremaining: 7m 2s\n",
      "351:\tlearn: 3.1062377\ttotal: 3m 49s\tremaining: 7m 2s\n",
      "352:\tlearn: 3.1059314\ttotal: 3m 49s\tremaining: 7m 1s\n",
      "353:\tlearn: 3.1056628\ttotal: 3m 50s\tremaining: 7m\n",
      "354:\tlearn: 3.1051667\ttotal: 3m 51s\tremaining: 6m 59s\n",
      "355:\tlearn: 3.1049156\ttotal: 3m 51s\tremaining: 6m 59s\n",
      "356:\tlearn: 3.1042338\ttotal: 3m 52s\tremaining: 6m 58s\n",
      "357:\tlearn: 3.1039560\ttotal: 3m 52s\tremaining: 6m 57s\n",
      "358:\tlearn: 3.1035493\ttotal: 3m 53s\tremaining: 6m 56s\n",
      "359:\tlearn: 3.1024438\ttotal: 3m 54s\tremaining: 6m 56s\n",
      "360:\tlearn: 3.1019214\ttotal: 3m 54s\tremaining: 6m 55s\n",
      "361:\tlearn: 3.1016438\ttotal: 3m 55s\tremaining: 6m 54s\n",
      "362:\tlearn: 3.1011413\ttotal: 3m 55s\tremaining: 6m 53s\n",
      "363:\tlearn: 3.1007466\ttotal: 3m 56s\tremaining: 6m 53s\n",
      "364:\tlearn: 3.1005042\ttotal: 3m 57s\tremaining: 6m 52s\n",
      "365:\tlearn: 3.1001240\ttotal: 3m 57s\tremaining: 6m 51s\n",
      "366:\tlearn: 3.0997261\ttotal: 3m 58s\tremaining: 6m 50s\n",
      "367:\tlearn: 3.0989503\ttotal: 3m 58s\tremaining: 6m 50s\n",
      "368:\tlearn: 3.0982290\ttotal: 3m 59s\tremaining: 6m 49s\n",
      "369:\tlearn: 3.0974335\ttotal: 4m\tremaining: 6m 48s\n",
      "370:\tlearn: 3.0969546\ttotal: 4m\tremaining: 6m 48s\n",
      "371:\tlearn: 3.0965565\ttotal: 4m 1s\tremaining: 6m 47s\n",
      "372:\tlearn: 3.0963691\ttotal: 4m 1s\tremaining: 6m 46s\n",
      "373:\tlearn: 3.0959224\ttotal: 4m 2s\tremaining: 6m 45s\n",
      "374:\tlearn: 3.0957109\ttotal: 4m 2s\tremaining: 6m 44s\n",
      "375:\tlearn: 3.0952935\ttotal: 4m 3s\tremaining: 6m 44s\n",
      "376:\tlearn: 3.0947558\ttotal: 4m 4s\tremaining: 6m 43s\n",
      "377:\tlearn: 3.0944286\ttotal: 4m 4s\tremaining: 6m 42s\n",
      "378:\tlearn: 3.0939184\ttotal: 4m 5s\tremaining: 6m 42s\n",
      "379:\tlearn: 3.0931982\ttotal: 4m 6s\tremaining: 6m 41s\n",
      "380:\tlearn: 3.0927157\ttotal: 4m 6s\tremaining: 6m 40s\n",
      "381:\tlearn: 3.0919616\ttotal: 4m 7s\tremaining: 6m 39s\n",
      "382:\tlearn: 3.0914804\ttotal: 4m 7s\tremaining: 6m 39s\n",
      "383:\tlearn: 3.0908461\ttotal: 4m 8s\tremaining: 6m 39s\n",
      "384:\tlearn: 3.0905881\ttotal: 4m 9s\tremaining: 6m 38s\n",
      "385:\tlearn: 3.0901245\ttotal: 4m 9s\tremaining: 6m 37s\n",
      "386:\tlearn: 3.0898967\ttotal: 4m 10s\tremaining: 6m 36s\n",
      "387:\tlearn: 3.0893581\ttotal: 4m 11s\tremaining: 6m 35s\n",
      "388:\tlearn: 3.0889272\ttotal: 4m 11s\tremaining: 6m 35s\n",
      "389:\tlearn: 3.0886783\ttotal: 4m 12s\tremaining: 6m 34s\n",
      "390:\tlearn: 3.0883249\ttotal: 4m 12s\tremaining: 6m 33s\n",
      "391:\tlearn: 3.0876011\ttotal: 4m 13s\tremaining: 6m 32s\n",
      "392:\tlearn: 3.0869417\ttotal: 4m 13s\tremaining: 6m 32s\n",
      "393:\tlearn: 3.0867394\ttotal: 4m 14s\tremaining: 6m 31s\n",
      "394:\tlearn: 3.0862473\ttotal: 4m 14s\tremaining: 6m 30s\n",
      "395:\tlearn: 3.0857829\ttotal: 4m 15s\tremaining: 6m 29s\n",
      "396:\tlearn: 3.0856304\ttotal: 4m 16s\tremaining: 6m 28s\n",
      "397:\tlearn: 3.0850701\ttotal: 4m 16s\tremaining: 6m 28s\n",
      "398:\tlearn: 3.0844207\ttotal: 4m 17s\tremaining: 6m 27s\n",
      "399:\tlearn: 3.0835845\ttotal: 4m 17s\tremaining: 6m 26s\n",
      "400:\tlearn: 3.0834283\ttotal: 4m 18s\tremaining: 6m 25s\n",
      "401:\tlearn: 3.0828695\ttotal: 4m 18s\tremaining: 6m 24s\n",
      "402:\tlearn: 3.0825780\ttotal: 4m 19s\tremaining: 6m 24s\n",
      "403:\tlearn: 3.0820996\ttotal: 4m 19s\tremaining: 6m 23s\n",
      "404:\tlearn: 3.0815064\ttotal: 4m 20s\tremaining: 6m 22s\n",
      "405:\tlearn: 3.0808764\ttotal: 4m 20s\tremaining: 6m 21s\n",
      "406:\tlearn: 3.0802459\ttotal: 4m 21s\tremaining: 6m 20s\n",
      "407:\tlearn: 3.0797720\ttotal: 4m 21s\tremaining: 6m 20s\n",
      "408:\tlearn: 3.0791802\ttotal: 4m 22s\tremaining: 6m 19s\n",
      "409:\tlearn: 3.0788390\ttotal: 4m 22s\tremaining: 6m 18s\n",
      "410:\tlearn: 3.0785750\ttotal: 4m 23s\tremaining: 6m 17s\n",
      "411:\tlearn: 3.0782407\ttotal: 4m 24s\tremaining: 6m 16s\n",
      "412:\tlearn: 3.0778847\ttotal: 4m 24s\tremaining: 6m 16s\n",
      "413:\tlearn: 3.0773606\ttotal: 4m 25s\tremaining: 6m 15s\n",
      "414:\tlearn: 3.0767839\ttotal: 4m 25s\tremaining: 6m 14s\n",
      "415:\tlearn: 3.0765748\ttotal: 4m 26s\tremaining: 6m 13s\n",
      "416:\tlearn: 3.0764231\ttotal: 4m 26s\tremaining: 6m 13s\n",
      "417:\tlearn: 3.0759834\ttotal: 4m 27s\tremaining: 6m 12s\n",
      "418:\tlearn: 3.0756324\ttotal: 4m 27s\tremaining: 6m 11s\n",
      "419:\tlearn: 3.0753299\ttotal: 4m 28s\tremaining: 6m 10s\n",
      "420:\tlearn: 3.0752204\ttotal: 4m 29s\tremaining: 6m 9s\n",
      "421:\tlearn: 3.0742474\ttotal: 4m 29s\tremaining: 6m 9s\n",
      "422:\tlearn: 3.0741063\ttotal: 4m 30s\tremaining: 6m 8s\n",
      "423:\tlearn: 3.0738814\ttotal: 4m 30s\tremaining: 6m 7s\n",
      "424:\tlearn: 3.0734084\ttotal: 4m 31s\tremaining: 6m 7s\n",
      "425:\tlearn: 3.0731417\ttotal: 4m 31s\tremaining: 6m 6s\n",
      "426:\tlearn: 3.0725591\ttotal: 4m 32s\tremaining: 6m 5s\n",
      "427:\tlearn: 3.0719834\ttotal: 4m 33s\tremaining: 6m 4s\n",
      "428:\tlearn: 3.0714639\ttotal: 4m 33s\tremaining: 6m 4s\n",
      "429:\tlearn: 3.0711077\ttotal: 4m 34s\tremaining: 6m 3s\n",
      "430:\tlearn: 3.0709072\ttotal: 4m 34s\tremaining: 6m 2s\n",
      "431:\tlearn: 3.0708096\ttotal: 4m 35s\tremaining: 6m 1s\n",
      "432:\tlearn: 3.0702976\ttotal: 4m 35s\tremaining: 6m 1s\n",
      "433:\tlearn: 3.0695975\ttotal: 4m 36s\tremaining: 6m\n",
      "434:\tlearn: 3.0694940\ttotal: 4m 36s\tremaining: 5m 59s\n",
      "435:\tlearn: 3.0689048\ttotal: 4m 37s\tremaining: 5m 58s\n",
      "436:\tlearn: 3.0687991\ttotal: 4m 38s\tremaining: 5m 58s\n",
      "437:\tlearn: 3.0686907\ttotal: 4m 38s\tremaining: 5m 57s\n",
      "438:\tlearn: 3.0685963\ttotal: 4m 39s\tremaining: 5m 56s\n",
      "439:\tlearn: 3.0678802\ttotal: 4m 39s\tremaining: 5m 55s\n",
      "440:\tlearn: 3.0673520\ttotal: 4m 40s\tremaining: 5m 55s\n",
      "441:\tlearn: 3.0669237\ttotal: 4m 40s\tremaining: 5m 54s\n",
      "442:\tlearn: 3.0664861\ttotal: 4m 41s\tremaining: 5m 53s\n",
      "443:\tlearn: 3.0663829\ttotal: 4m 41s\tremaining: 5m 53s\n",
      "444:\tlearn: 3.0660389\ttotal: 4m 42s\tremaining: 5m 52s\n",
      "445:\tlearn: 3.0655905\ttotal: 4m 43s\tremaining: 5m 51s\n",
      "446:\tlearn: 3.0650603\ttotal: 4m 43s\tremaining: 5m 50s\n",
      "447:\tlearn: 3.0644903\ttotal: 4m 44s\tremaining: 5m 50s\n",
      "448:\tlearn: 3.0640650\ttotal: 4m 44s\tremaining: 5m 49s\n",
      "449:\tlearn: 3.0638650\ttotal: 4m 45s\tremaining: 5m 48s\n",
      "450:\tlearn: 3.0632885\ttotal: 4m 45s\tremaining: 5m 47s\n",
      "451:\tlearn: 3.0623843\ttotal: 4m 46s\tremaining: 5m 47s\n",
      "452:\tlearn: 3.0619308\ttotal: 4m 46s\tremaining: 5m 46s\n",
      "453:\tlearn: 3.0616299\ttotal: 4m 47s\tremaining: 5m 45s\n",
      "454:\tlearn: 3.0613401\ttotal: 4m 48s\tremaining: 5m 45s\n",
      "455:\tlearn: 3.0606688\ttotal: 4m 48s\tremaining: 5m 44s\n",
      "456:\tlearn: 3.0605863\ttotal: 4m 49s\tremaining: 5m 43s\n",
      "457:\tlearn: 3.0601607\ttotal: 4m 49s\tremaining: 5m 42s\n",
      "458:\tlearn: 3.0600139\ttotal: 4m 50s\tremaining: 5m 41s\n",
      "459:\tlearn: 3.0592747\ttotal: 4m 50s\tremaining: 5m 41s\n",
      "460:\tlearn: 3.0585676\ttotal: 4m 51s\tremaining: 5m 40s\n",
      "461:\tlearn: 3.0578602\ttotal: 4m 51s\tremaining: 5m 40s\n",
      "462:\tlearn: 3.0574266\ttotal: 4m 52s\tremaining: 5m 39s\n",
      "463:\tlearn: 3.0568740\ttotal: 4m 53s\tremaining: 5m 38s\n",
      "464:\tlearn: 3.0565486\ttotal: 4m 53s\tremaining: 5m 37s\n",
      "465:\tlearn: 3.0563240\ttotal: 4m 54s\tremaining: 5m 37s\n",
      "466:\tlearn: 3.0557596\ttotal: 4m 54s\tremaining: 5m 36s\n",
      "467:\tlearn: 3.0550408\ttotal: 4m 55s\tremaining: 5m 35s\n",
      "468:\tlearn: 3.0547061\ttotal: 4m 55s\tremaining: 5m 35s\n",
      "469:\tlearn: 3.0539665\ttotal: 4m 56s\tremaining: 5m 34s\n",
      "470:\tlearn: 3.0536385\ttotal: 4m 57s\tremaining: 5m 33s\n",
      "471:\tlearn: 3.0532004\ttotal: 4m 57s\tremaining: 5m 33s\n",
      "472:\tlearn: 3.0528545\ttotal: 4m 58s\tremaining: 5m 32s\n",
      "473:\tlearn: 3.0523583\ttotal: 4m 58s\tremaining: 5m 31s\n",
      "474:\tlearn: 3.0518284\ttotal: 4m 59s\tremaining: 5m 30s\n",
      "475:\tlearn: 3.0514269\ttotal: 4m 59s\tremaining: 5m 30s\n",
      "476:\tlearn: 3.0509385\ttotal: 5m\tremaining: 5m 29s\n",
      "477:\tlearn: 3.0506961\ttotal: 5m\tremaining: 5m 28s\n",
      "478:\tlearn: 3.0502592\ttotal: 5m 1s\tremaining: 5m 27s\n",
      "479:\tlearn: 3.0497444\ttotal: 5m 1s\tremaining: 5m 26s\n",
      "480:\tlearn: 3.0489432\ttotal: 5m 2s\tremaining: 5m 26s\n",
      "481:\tlearn: 3.0484556\ttotal: 5m 2s\tremaining: 5m 25s\n",
      "482:\tlearn: 3.0476943\ttotal: 5m 3s\tremaining: 5m 24s\n",
      "483:\tlearn: 3.0474217\ttotal: 5m 3s\tremaining: 5m 23s\n",
      "484:\tlearn: 3.0469420\ttotal: 5m 4s\tremaining: 5m 23s\n",
      "485:\tlearn: 3.0465549\ttotal: 5m 5s\tremaining: 5m 22s\n",
      "486:\tlearn: 3.0462362\ttotal: 5m 5s\tremaining: 5m 21s\n",
      "487:\tlearn: 3.0457794\ttotal: 5m 6s\tremaining: 5m 21s\n",
      "488:\tlearn: 3.0455284\ttotal: 5m 6s\tremaining: 5m 20s\n",
      "489:\tlearn: 3.0453389\ttotal: 5m 7s\tremaining: 5m 19s\n",
      "490:\tlearn: 3.0448521\ttotal: 5m 7s\tremaining: 5m 18s\n",
      "491:\tlearn: 3.0444347\ttotal: 5m 8s\tremaining: 5m 18s\n",
      "492:\tlearn: 3.0442398\ttotal: 5m 8s\tremaining: 5m 17s\n",
      "493:\tlearn: 3.0438324\ttotal: 5m 9s\tremaining: 5m 16s\n",
      "494:\tlearn: 3.0435566\ttotal: 5m 9s\tremaining: 5m 16s\n",
      "495:\tlearn: 3.0433998\ttotal: 5m 10s\tremaining: 5m 15s\n",
      "496:\tlearn: 3.0433171\ttotal: 5m 10s\tremaining: 5m 14s\n",
      "497:\tlearn: 3.0424653\ttotal: 5m 11s\tremaining: 5m 13s\n",
      "498:\tlearn: 3.0417930\ttotal: 5m 12s\tremaining: 5m 13s\n",
      "499:\tlearn: 3.0415082\ttotal: 5m 12s\tremaining: 5m 12s\n",
      "500:\tlearn: 3.0412276\ttotal: 5m 13s\tremaining: 5m 11s\n",
      "501:\tlearn: 3.0408762\ttotal: 5m 13s\tremaining: 5m 11s\n",
      "502:\tlearn: 3.0407844\ttotal: 5m 14s\tremaining: 5m 10s\n",
      "503:\tlearn: 3.0402855\ttotal: 5m 14s\tremaining: 5m 9s\n",
      "504:\tlearn: 3.0396949\ttotal: 5m 15s\tremaining: 5m 9s\n",
      "505:\tlearn: 3.0393393\ttotal: 5m 15s\tremaining: 5m 8s\n",
      "506:\tlearn: 3.0392545\ttotal: 5m 16s\tremaining: 5m 7s\n",
      "507:\tlearn: 3.0388101\ttotal: 5m 16s\tremaining: 5m 6s\n",
      "508:\tlearn: 3.0382672\ttotal: 5m 17s\tremaining: 5m 6s\n",
      "509:\tlearn: 3.0379273\ttotal: 5m 17s\tremaining: 5m 5s\n",
      "510:\tlearn: 3.0374723\ttotal: 5m 18s\tremaining: 5m 4s\n",
      "511:\tlearn: 3.0370057\ttotal: 5m 19s\tremaining: 5m 4s\n",
      "512:\tlearn: 3.0364668\ttotal: 5m 19s\tremaining: 5m 3s\n",
      "513:\tlearn: 3.0362855\ttotal: 5m 20s\tremaining: 5m 2s\n",
      "514:\tlearn: 3.0358390\ttotal: 5m 20s\tremaining: 5m 2s\n",
      "515:\tlearn: 3.0351648\ttotal: 5m 21s\tremaining: 5m 1s\n",
      "516:\tlearn: 3.0349093\ttotal: 5m 21s\tremaining: 5m\n",
      "517:\tlearn: 3.0345975\ttotal: 5m 22s\tremaining: 4m 59s\n",
      "518:\tlearn: 3.0340885\ttotal: 5m 22s\tremaining: 4m 59s\n",
      "519:\tlearn: 3.0339939\ttotal: 5m 23s\tremaining: 4m 58s\n",
      "520:\tlearn: 3.0336852\ttotal: 5m 23s\tremaining: 4m 57s\n",
      "521:\tlearn: 3.0332505\ttotal: 5m 24s\tremaining: 4m 56s\n",
      "522:\tlearn: 3.0331528\ttotal: 5m 24s\tremaining: 4m 56s\n",
      "523:\tlearn: 3.0330632\ttotal: 5m 25s\tremaining: 4m 55s\n",
      "524:\tlearn: 3.0329804\ttotal: 5m 25s\tremaining: 4m 54s\n",
      "525:\tlearn: 3.0328905\ttotal: 5m 26s\tremaining: 4m 54s\n",
      "526:\tlearn: 3.0325581\ttotal: 5m 27s\tremaining: 4m 53s\n",
      "527:\tlearn: 3.0323563\ttotal: 5m 27s\tremaining: 4m 52s\n",
      "528:\tlearn: 3.0322813\ttotal: 5m 28s\tremaining: 4m 52s\n",
      "529:\tlearn: 3.0321228\ttotal: 5m 28s\tremaining: 4m 51s\n",
      "530:\tlearn: 3.0315428\ttotal: 5m 29s\tremaining: 4m 50s\n",
      "531:\tlearn: 3.0310857\ttotal: 5m 29s\tremaining: 4m 50s\n",
      "532:\tlearn: 3.0310022\ttotal: 5m 30s\tremaining: 4m 49s\n",
      "533:\tlearn: 3.0302646\ttotal: 5m 30s\tremaining: 4m 48s\n",
      "534:\tlearn: 3.0299115\ttotal: 5m 31s\tremaining: 4m 48s\n",
      "535:\tlearn: 3.0295148\ttotal: 5m 32s\tremaining: 4m 47s\n",
      "536:\tlearn: 3.0290688\ttotal: 5m 32s\tremaining: 4m 46s\n",
      "537:\tlearn: 3.0286664\ttotal: 5m 33s\tremaining: 4m 46s\n",
      "538:\tlearn: 3.0283253\ttotal: 5m 33s\tremaining: 4m 45s\n",
      "539:\tlearn: 3.0275787\ttotal: 5m 34s\tremaining: 4m 44s\n",
      "540:\tlearn: 3.0272230\ttotal: 5m 34s\tremaining: 4m 44s\n",
      "541:\tlearn: 3.0267554\ttotal: 5m 35s\tremaining: 4m 43s\n",
      "542:\tlearn: 3.0264982\ttotal: 5m 35s\tremaining: 4m 42s\n",
      "543:\tlearn: 3.0259816\ttotal: 5m 36s\tremaining: 4m 42s\n",
      "544:\tlearn: 3.0256370\ttotal: 5m 37s\tremaining: 4m 41s\n",
      "545:\tlearn: 3.0255018\ttotal: 5m 37s\tremaining: 4m 40s\n",
      "546:\tlearn: 3.0251629\ttotal: 5m 38s\tremaining: 4m 40s\n",
      "547:\tlearn: 3.0249718\ttotal: 5m 38s\tremaining: 4m 39s\n",
      "548:\tlearn: 3.0245827\ttotal: 5m 39s\tremaining: 4m 38s\n",
      "549:\tlearn: 3.0243779\ttotal: 5m 39s\tremaining: 4m 38s\n",
      "550:\tlearn: 3.0241994\ttotal: 5m 40s\tremaining: 4m 37s\n",
      "551:\tlearn: 3.0239649\ttotal: 5m 41s\tremaining: 4m 36s\n",
      "552:\tlearn: 3.0237983\ttotal: 5m 41s\tremaining: 4m 36s\n",
      "553:\tlearn: 3.0233008\ttotal: 5m 42s\tremaining: 4m 35s\n",
      "554:\tlearn: 3.0227097\ttotal: 5m 42s\tremaining: 4m 34s\n",
      "555:\tlearn: 3.0222918\ttotal: 5m 43s\tremaining: 4m 33s\n",
      "556:\tlearn: 3.0220641\ttotal: 5m 43s\tremaining: 4m 33s\n",
      "557:\tlearn: 3.0214823\ttotal: 5m 44s\tremaining: 4m 32s\n",
      "558:\tlearn: 3.0211102\ttotal: 5m 44s\tremaining: 4m 31s\n",
      "559:\tlearn: 3.0208223\ttotal: 5m 45s\tremaining: 4m 31s\n",
      "560:\tlearn: 3.0204216\ttotal: 5m 45s\tremaining: 4m 30s\n",
      "561:\tlearn: 3.0200238\ttotal: 5m 46s\tremaining: 4m 29s\n",
      "562:\tlearn: 3.0199404\ttotal: 5m 46s\tremaining: 4m 29s\n",
      "563:\tlearn: 3.0198466\ttotal: 5m 47s\tremaining: 4m 28s\n",
      "564:\tlearn: 3.0194592\ttotal: 5m 47s\tremaining: 4m 27s\n",
      "565:\tlearn: 3.0190765\ttotal: 5m 48s\tremaining: 4m 27s\n",
      "566:\tlearn: 3.0189920\ttotal: 5m 48s\tremaining: 4m 26s\n",
      "567:\tlearn: 3.0187768\ttotal: 5m 49s\tremaining: 4m 25s\n",
      "568:\tlearn: 3.0183379\ttotal: 5m 49s\tremaining: 4m 25s\n",
      "569:\tlearn: 3.0182495\ttotal: 5m 50s\tremaining: 4m 24s\n",
      "570:\tlearn: 3.0178340\ttotal: 5m 51s\tremaining: 4m 23s\n",
      "571:\tlearn: 3.0176237\ttotal: 5m 51s\tremaining: 4m 23s\n",
      "572:\tlearn: 3.0174812\ttotal: 5m 52s\tremaining: 4m 22s\n",
      "573:\tlearn: 3.0172062\ttotal: 5m 52s\tremaining: 4m 21s\n",
      "574:\tlearn: 3.0170562\ttotal: 5m 53s\tremaining: 4m 21s\n",
      "575:\tlearn: 3.0167799\ttotal: 5m 53s\tremaining: 4m 20s\n",
      "576:\tlearn: 3.0165149\ttotal: 5m 54s\tremaining: 4m 19s\n",
      "577:\tlearn: 3.0159221\ttotal: 5m 54s\tremaining: 4m 18s\n",
      "578:\tlearn: 3.0155004\ttotal: 5m 55s\tremaining: 4m 18s\n",
      "579:\tlearn: 3.0150179\ttotal: 5m 55s\tremaining: 4m 17s\n",
      "580:\tlearn: 3.0149427\ttotal: 5m 56s\tremaining: 4m 16s\n",
      "581:\tlearn: 3.0146890\ttotal: 5m 56s\tremaining: 4m 16s\n",
      "582:\tlearn: 3.0142732\ttotal: 5m 57s\tremaining: 4m 15s\n",
      "583:\tlearn: 3.0142021\ttotal: 5m 57s\tremaining: 4m 14s\n",
      "584:\tlearn: 3.0136356\ttotal: 5m 58s\tremaining: 4m 14s\n",
      "585:\tlearn: 3.0132777\ttotal: 5m 58s\tremaining: 4m 13s\n",
      "586:\tlearn: 3.0130064\ttotal: 5m 59s\tremaining: 4m 12s\n",
      "587:\tlearn: 3.0124169\ttotal: 6m\tremaining: 4m 12s\n",
      "588:\tlearn: 3.0117426\ttotal: 6m\tremaining: 4m 11s\n",
      "589:\tlearn: 3.0115130\ttotal: 6m 1s\tremaining: 4m 11s\n",
      "590:\tlearn: 3.0110881\ttotal: 6m 1s\tremaining: 4m 10s\n",
      "591:\tlearn: 3.0108888\ttotal: 6m 2s\tremaining: 4m 9s\n",
      "592:\tlearn: 3.0106546\ttotal: 6m 2s\tremaining: 4m 9s\n",
      "593:\tlearn: 3.0100724\ttotal: 6m 3s\tremaining: 4m 8s\n",
      "594:\tlearn: 3.0098687\ttotal: 6m 4s\tremaining: 4m 7s\n",
      "595:\tlearn: 3.0096668\ttotal: 6m 4s\tremaining: 4m 7s\n",
      "596:\tlearn: 3.0095827\ttotal: 6m 5s\tremaining: 4m 6s\n",
      "597:\tlearn: 3.0095017\ttotal: 6m 5s\tremaining: 4m 5s\n",
      "598:\tlearn: 3.0094270\ttotal: 6m 6s\tremaining: 4m 5s\n",
      "599:\tlearn: 3.0093513\ttotal: 6m 6s\tremaining: 4m 4s\n",
      "600:\tlearn: 3.0092724\ttotal: 6m 7s\tremaining: 4m 3s\n",
      "601:\tlearn: 3.0088080\ttotal: 6m 8s\tremaining: 4m 3s\n",
      "602:\tlearn: 3.0080871\ttotal: 6m 8s\tremaining: 4m 2s\n",
      "603:\tlearn: 3.0075612\ttotal: 6m 9s\tremaining: 4m 2s\n",
      "604:\tlearn: 3.0071941\ttotal: 6m 9s\tremaining: 4m 1s\n",
      "605:\tlearn: 3.0070602\ttotal: 6m 10s\tremaining: 4m\n",
      "606:\tlearn: 3.0065970\ttotal: 6m 10s\tremaining: 4m\n",
      "607:\tlearn: 3.0063186\ttotal: 6m 11s\tremaining: 3m 59s\n",
      "608:\tlearn: 3.0060511\ttotal: 6m 11s\tremaining: 3m 58s\n",
      "609:\tlearn: 3.0057861\ttotal: 6m 12s\tremaining: 3m 58s\n",
      "610:\tlearn: 3.0055478\ttotal: 6m 13s\tremaining: 3m 57s\n",
      "611:\tlearn: 3.0053019\ttotal: 6m 13s\tremaining: 3m 56s\n",
      "612:\tlearn: 3.0047175\ttotal: 6m 14s\tremaining: 3m 56s\n",
      "613:\tlearn: 3.0043485\ttotal: 6m 14s\tremaining: 3m 55s\n",
      "614:\tlearn: 3.0040714\ttotal: 6m 15s\tremaining: 3m 54s\n",
      "615:\tlearn: 3.0037805\ttotal: 6m 15s\tremaining: 3m 54s\n",
      "616:\tlearn: 3.0033812\ttotal: 6m 16s\tremaining: 3m 53s\n",
      "617:\tlearn: 3.0029301\ttotal: 6m 16s\tremaining: 3m 53s\n",
      "618:\tlearn: 3.0027091\ttotal: 6m 17s\tremaining: 3m 52s\n",
      "619:\tlearn: 3.0022362\ttotal: 6m 18s\tremaining: 3m 51s\n",
      "620:\tlearn: 3.0017414\ttotal: 6m 18s\tremaining: 3m 51s\n",
      "621:\tlearn: 3.0014080\ttotal: 6m 19s\tremaining: 3m 50s\n",
      "622:\tlearn: 3.0011808\ttotal: 6m 19s\tremaining: 3m 49s\n",
      "623:\tlearn: 3.0005840\ttotal: 6m 19s\tremaining: 3m 48s\n",
      "624:\tlearn: 3.0001270\ttotal: 6m 20s\tremaining: 3m 48s\n",
      "625:\tlearn: 2.9996618\ttotal: 6m 21s\tremaining: 3m 47s\n",
      "626:\tlearn: 2.9992442\ttotal: 6m 21s\tremaining: 3m 47s\n",
      "627:\tlearn: 2.9990718\ttotal: 6m 22s\tremaining: 3m 46s\n",
      "628:\tlearn: 2.9985959\ttotal: 6m 22s\tremaining: 3m 45s\n",
      "629:\tlearn: 2.9982355\ttotal: 6m 23s\tremaining: 3m 45s\n",
      "630:\tlearn: 2.9976565\ttotal: 6m 23s\tremaining: 3m 44s\n",
      "631:\tlearn: 2.9973153\ttotal: 6m 24s\tremaining: 3m 43s\n",
      "632:\tlearn: 2.9972416\ttotal: 6m 24s\tremaining: 3m 43s\n",
      "633:\tlearn: 2.9966548\ttotal: 6m 25s\tremaining: 3m 42s\n",
      "634:\tlearn: 2.9959564\ttotal: 6m 25s\tremaining: 3m 41s\n",
      "635:\tlearn: 2.9957748\ttotal: 6m 26s\tremaining: 3m 41s\n",
      "636:\tlearn: 2.9957004\ttotal: 6m 26s\tremaining: 3m 40s\n",
      "637:\tlearn: 2.9953104\ttotal: 6m 27s\tremaining: 3m 39s\n",
      "638:\tlearn: 2.9949369\ttotal: 6m 28s\tremaining: 3m 39s\n",
      "639:\tlearn: 2.9948650\ttotal: 6m 28s\tremaining: 3m 38s\n",
      "640:\tlearn: 2.9947529\ttotal: 6m 29s\tremaining: 3m 37s\n",
      "641:\tlearn: 2.9944665\ttotal: 6m 29s\tremaining: 3m 37s\n",
      "642:\tlearn: 2.9941604\ttotal: 6m 30s\tremaining: 3m 36s\n",
      "643:\tlearn: 2.9939147\ttotal: 6m 30s\tremaining: 3m 36s\n",
      "644:\tlearn: 2.9934663\ttotal: 6m 31s\tremaining: 3m 35s\n",
      "645:\tlearn: 2.9931097\ttotal: 6m 32s\tremaining: 3m 34s\n",
      "646:\tlearn: 2.9929575\ttotal: 6m 32s\tremaining: 3m 34s\n",
      "647:\tlearn: 2.9927405\ttotal: 6m 33s\tremaining: 3m 33s\n",
      "648:\tlearn: 2.9925312\ttotal: 6m 33s\tremaining: 3m 32s\n",
      "649:\tlearn: 2.9920764\ttotal: 6m 34s\tremaining: 3m 32s\n",
      "650:\tlearn: 2.9913557\ttotal: 6m 34s\tremaining: 3m 31s\n",
      "651:\tlearn: 2.9912053\ttotal: 6m 35s\tremaining: 3m 31s\n",
      "652:\tlearn: 2.9910025\ttotal: 6m 35s\tremaining: 3m 30s\n",
      "653:\tlearn: 2.9904291\ttotal: 6m 36s\tremaining: 3m 29s\n",
      "654:\tlearn: 2.9902299\ttotal: 6m 37s\tremaining: 3m 29s\n",
      "655:\tlearn: 2.9896938\ttotal: 6m 37s\tremaining: 3m 28s\n",
      "656:\tlearn: 2.9891973\ttotal: 6m 38s\tremaining: 3m 27s\n",
      "657:\tlearn: 2.9890724\ttotal: 6m 38s\tremaining: 3m 27s\n",
      "658:\tlearn: 2.9889915\ttotal: 6m 39s\tremaining: 3m 26s\n",
      "659:\tlearn: 2.9889106\ttotal: 6m 39s\tremaining: 3m 26s\n",
      "660:\tlearn: 2.9888362\ttotal: 6m 40s\tremaining: 3m 25s\n",
      "661:\tlearn: 2.9886966\ttotal: 6m 41s\tremaining: 3m 24s\n",
      "662:\tlearn: 2.9885996\ttotal: 6m 41s\tremaining: 3m 24s\n",
      "663:\tlearn: 2.9885297\ttotal: 6m 42s\tremaining: 3m 23s\n",
      "664:\tlearn: 2.9884620\ttotal: 6m 42s\tremaining: 3m 22s\n",
      "665:\tlearn: 2.9883856\ttotal: 6m 43s\tremaining: 3m 22s\n",
      "666:\tlearn: 2.9880793\ttotal: 6m 43s\tremaining: 3m 21s\n",
      "667:\tlearn: 2.9879439\ttotal: 6m 44s\tremaining: 3m 20s\n",
      "668:\tlearn: 2.9874365\ttotal: 6m 44s\tremaining: 3m 20s\n",
      "669:\tlearn: 2.9869902\ttotal: 6m 45s\tremaining: 3m 19s\n",
      "670:\tlearn: 2.9867437\ttotal: 6m 46s\tremaining: 3m 19s\n",
      "671:\tlearn: 2.9864549\ttotal: 6m 46s\tremaining: 3m 18s\n",
      "672:\tlearn: 2.9860367\ttotal: 6m 47s\tremaining: 3m 17s\n",
      "673:\tlearn: 2.9859640\ttotal: 6m 47s\tremaining: 3m 17s\n",
      "674:\tlearn: 2.9858985\ttotal: 6m 48s\tremaining: 3m 16s\n",
      "675:\tlearn: 2.9857107\ttotal: 6m 48s\tremaining: 3m 15s\n",
      "676:\tlearn: 2.9855758\ttotal: 6m 49s\tremaining: 3m 15s\n",
      "677:\tlearn: 2.9854474\ttotal: 6m 49s\tremaining: 3m 14s\n",
      "678:\tlearn: 2.9852709\ttotal: 6m 50s\tremaining: 3m 14s\n",
      "679:\tlearn: 2.9848857\ttotal: 6m 51s\tremaining: 3m 13s\n",
      "680:\tlearn: 2.9844373\ttotal: 6m 51s\tremaining: 3m 12s\n",
      "681:\tlearn: 2.9842406\ttotal: 6m 52s\tremaining: 3m 12s\n",
      "682:\tlearn: 2.9840860\ttotal: 6m 52s\tremaining: 3m 11s\n",
      "683:\tlearn: 2.9839119\ttotal: 6m 53s\tremaining: 3m 10s\n",
      "684:\tlearn: 2.9836304\ttotal: 6m 53s\tremaining: 3m 10s\n",
      "685:\tlearn: 2.9833926\ttotal: 6m 54s\tremaining: 3m 9s\n",
      "686:\tlearn: 2.9830770\ttotal: 6m 54s\tremaining: 3m 8s\n",
      "687:\tlearn: 2.9828811\ttotal: 6m 55s\tremaining: 3m 8s\n",
      "688:\tlearn: 2.9825309\ttotal: 6m 55s\tremaining: 3m 7s\n",
      "689:\tlearn: 2.9824258\ttotal: 6m 56s\tremaining: 3m 7s\n",
      "690:\tlearn: 2.9822409\ttotal: 6m 56s\tremaining: 3m 6s\n",
      "691:\tlearn: 2.9816716\ttotal: 6m 57s\tremaining: 3m 5s\n",
      "692:\tlearn: 2.9815491\ttotal: 6m 57s\tremaining: 3m 5s\n",
      "693:\tlearn: 2.9812140\ttotal: 6m 58s\tremaining: 3m 4s\n",
      "694:\tlearn: 2.9810142\ttotal: 6m 59s\tremaining: 3m 3s\n",
      "695:\tlearn: 2.9807100\ttotal: 6m 59s\tremaining: 3m 3s\n",
      "696:\tlearn: 2.9805318\ttotal: 7m\tremaining: 3m 2s\n",
      "697:\tlearn: 2.9803764\ttotal: 7m\tremaining: 3m 2s\n",
      "698:\tlearn: 2.9798214\ttotal: 7m 1s\tremaining: 3m 1s\n",
      "699:\tlearn: 2.9793850\ttotal: 7m 1s\tremaining: 3m\n",
      "700:\tlearn: 2.9790819\ttotal: 7m 2s\tremaining: 3m\n",
      "701:\tlearn: 2.9785808\ttotal: 7m 2s\tremaining: 2m 59s\n",
      "702:\tlearn: 2.9782044\ttotal: 7m 3s\tremaining: 2m 58s\n",
      "703:\tlearn: 2.9779932\ttotal: 7m 3s\tremaining: 2m 58s\n",
      "704:\tlearn: 2.9776491\ttotal: 7m 4s\tremaining: 2m 57s\n",
      "705:\tlearn: 2.9774010\ttotal: 7m 4s\tremaining: 2m 56s\n",
      "706:\tlearn: 2.9770819\ttotal: 7m 5s\tremaining: 2m 56s\n",
      "707:\tlearn: 2.9768922\ttotal: 7m 5s\tremaining: 2m 55s\n",
      "708:\tlearn: 2.9765546\ttotal: 7m 6s\tremaining: 2m 55s\n",
      "709:\tlearn: 2.9763925\ttotal: 7m 6s\tremaining: 2m 54s\n",
      "710:\tlearn: 2.9759062\ttotal: 7m 7s\tremaining: 2m 53s\n",
      "711:\tlearn: 2.9752349\ttotal: 7m 7s\tremaining: 2m 53s\n",
      "712:\tlearn: 2.9748219\ttotal: 7m 8s\tremaining: 2m 52s\n",
      "713:\tlearn: 2.9746836\ttotal: 7m 8s\tremaining: 2m 51s\n",
      "714:\tlearn: 2.9743743\ttotal: 7m 9s\tremaining: 2m 51s\n",
      "715:\tlearn: 2.9740052\ttotal: 7m 10s\tremaining: 2m 50s\n",
      "716:\tlearn: 2.9737461\ttotal: 7m 10s\tremaining: 2m 49s\n",
      "717:\tlearn: 2.9732047\ttotal: 7m 11s\tremaining: 2m 49s\n",
      "718:\tlearn: 2.9727673\ttotal: 7m 11s\tremaining: 2m 48s\n",
      "719:\tlearn: 2.9725483\ttotal: 7m 12s\tremaining: 2m 48s\n",
      "720:\tlearn: 2.9721895\ttotal: 7m 12s\tremaining: 2m 47s\n",
      "721:\tlearn: 2.9720383\ttotal: 7m 12s\tremaining: 2m 46s\n",
      "722:\tlearn: 2.9716368\ttotal: 7m 13s\tremaining: 2m 46s\n",
      "723:\tlearn: 2.9710909\ttotal: 7m 13s\tremaining: 2m 45s\n",
      "724:\tlearn: 2.9708987\ttotal: 7m 14s\tremaining: 2m 44s\n",
      "725:\tlearn: 2.9704814\ttotal: 7m 14s\tremaining: 2m 44s\n",
      "726:\tlearn: 2.9701568\ttotal: 7m 15s\tremaining: 2m 43s\n",
      "727:\tlearn: 2.9697333\ttotal: 7m 15s\tremaining: 2m 42s\n",
      "728:\tlearn: 2.9694194\ttotal: 7m 16s\tremaining: 2m 42s\n",
      "729:\tlearn: 2.9688495\ttotal: 7m 16s\tremaining: 2m 41s\n",
      "730:\tlearn: 2.9685594\ttotal: 7m 17s\tremaining: 2m 40s\n",
      "731:\tlearn: 2.9680574\ttotal: 7m 17s\tremaining: 2m 40s\n",
      "732:\tlearn: 2.9678240\ttotal: 7m 18s\tremaining: 2m 39s\n",
      "733:\tlearn: 2.9674171\ttotal: 7m 18s\tremaining: 2m 39s\n",
      "734:\tlearn: 2.9671261\ttotal: 7m 19s\tremaining: 2m 38s\n",
      "735:\tlearn: 2.9669887\ttotal: 7m 19s\tremaining: 2m 37s\n",
      "736:\tlearn: 2.9665924\ttotal: 7m 20s\tremaining: 2m 37s\n",
      "737:\tlearn: 2.9664095\ttotal: 7m 20s\tremaining: 2m 36s\n",
      "738:\tlearn: 2.9659547\ttotal: 7m 21s\tremaining: 2m 35s\n",
      "739:\tlearn: 2.9655574\ttotal: 7m 21s\tremaining: 2m 35s\n",
      "740:\tlearn: 2.9649546\ttotal: 7m 22s\tremaining: 2m 34s\n",
      "741:\tlearn: 2.9644301\ttotal: 7m 22s\tremaining: 2m 33s\n",
      "742:\tlearn: 2.9639821\ttotal: 7m 23s\tremaining: 2m 33s\n",
      "743:\tlearn: 2.9636466\ttotal: 7m 23s\tremaining: 2m 32s\n",
      "744:\tlearn: 2.9633594\ttotal: 7m 24s\tremaining: 2m 32s\n",
      "745:\tlearn: 2.9631961\ttotal: 7m 24s\tremaining: 2m 31s\n",
      "746:\tlearn: 2.9629072\ttotal: 7m 25s\tremaining: 2m 30s\n",
      "747:\tlearn: 2.9627224\ttotal: 7m 25s\tremaining: 2m 30s\n",
      "748:\tlearn: 2.9622902\ttotal: 7m 26s\tremaining: 2m 29s\n",
      "749:\tlearn: 2.9619181\ttotal: 7m 26s\tremaining: 2m 28s\n",
      "750:\tlearn: 2.9616155\ttotal: 7m 27s\tremaining: 2m 28s\n",
      "751:\tlearn: 2.9615538\ttotal: 7m 27s\tremaining: 2m 27s\n",
      "752:\tlearn: 2.9612222\ttotal: 7m 28s\tremaining: 2m 27s\n",
      "753:\tlearn: 2.9609869\ttotal: 7m 28s\tremaining: 2m 26s\n",
      "754:\tlearn: 2.9608549\ttotal: 7m 29s\tremaining: 2m 25s\n",
      "755:\tlearn: 2.9604920\ttotal: 7m 29s\tremaining: 2m 25s\n",
      "756:\tlearn: 2.9603418\ttotal: 7m 30s\tremaining: 2m 24s\n",
      "757:\tlearn: 2.9599446\ttotal: 7m 30s\tremaining: 2m 23s\n",
      "758:\tlearn: 2.9593605\ttotal: 7m 31s\tremaining: 2m 23s\n",
      "759:\tlearn: 2.9592303\ttotal: 7m 31s\tremaining: 2m 22s\n",
      "760:\tlearn: 2.9590736\ttotal: 7m 32s\tremaining: 2m 22s\n",
      "761:\tlearn: 2.9586169\ttotal: 7m 32s\tremaining: 2m 21s\n",
      "762:\tlearn: 2.9581326\ttotal: 7m 33s\tremaining: 2m 20s\n",
      "763:\tlearn: 2.9577185\ttotal: 7m 33s\tremaining: 2m 20s\n",
      "764:\tlearn: 2.9571595\ttotal: 7m 34s\tremaining: 2m 19s\n",
      "765:\tlearn: 2.9567402\ttotal: 7m 34s\tremaining: 2m 18s\n",
      "766:\tlearn: 2.9566373\ttotal: 7m 35s\tremaining: 2m 18s\n",
      "767:\tlearn: 2.9563955\ttotal: 7m 35s\tremaining: 2m 17s\n",
      "768:\tlearn: 2.9560967\ttotal: 7m 36s\tremaining: 2m 17s\n",
      "769:\tlearn: 2.9557518\ttotal: 7m 36s\tremaining: 2m 16s\n",
      "770:\tlearn: 2.9554891\ttotal: 7m 37s\tremaining: 2m 15s\n",
      "771:\tlearn: 2.9551244\ttotal: 7m 37s\tremaining: 2m 15s\n",
      "772:\tlearn: 2.9548633\ttotal: 7m 38s\tremaining: 2m 14s\n",
      "773:\tlearn: 2.9543711\ttotal: 7m 38s\tremaining: 2m 14s\n",
      "774:\tlearn: 2.9539699\ttotal: 7m 39s\tremaining: 2m 13s\n",
      "775:\tlearn: 2.9536793\ttotal: 7m 40s\tremaining: 2m 12s\n",
      "776:\tlearn: 2.9533163\ttotal: 7m 40s\tremaining: 2m 12s\n",
      "777:\tlearn: 2.9526824\ttotal: 7m 41s\tremaining: 2m 11s\n",
      "778:\tlearn: 2.9522967\ttotal: 7m 41s\tremaining: 2m 10s\n",
      "779:\tlearn: 2.9520213\ttotal: 7m 42s\tremaining: 2m 10s\n",
      "780:\tlearn: 2.9516753\ttotal: 7m 42s\tremaining: 2m 9s\n",
      "781:\tlearn: 2.9512981\ttotal: 7m 43s\tremaining: 2m 9s\n",
      "782:\tlearn: 2.9508950\ttotal: 7m 43s\tremaining: 2m 8s\n",
      "783:\tlearn: 2.9506297\ttotal: 7m 44s\tremaining: 2m 7s\n",
      "784:\tlearn: 2.9504333\ttotal: 7m 44s\tremaining: 2m 7s\n",
      "785:\tlearn: 2.9502492\ttotal: 7m 44s\tremaining: 2m 6s\n",
      "786:\tlearn: 2.9501989\ttotal: 7m 45s\tremaining: 2m 5s\n",
      "787:\tlearn: 2.9497640\ttotal: 7m 46s\tremaining: 2m 5s\n",
      "788:\tlearn: 2.9494932\ttotal: 7m 46s\tremaining: 2m 4s\n",
      "789:\tlearn: 2.9490849\ttotal: 7m 47s\tremaining: 2m 4s\n",
      "790:\tlearn: 2.9487511\ttotal: 7m 47s\tremaining: 2m 3s\n",
      "791:\tlearn: 2.9483672\ttotal: 7m 48s\tremaining: 2m 3s\n",
      "792:\tlearn: 2.9479942\ttotal: 7m 48s\tremaining: 2m 2s\n",
      "793:\tlearn: 2.9479301\ttotal: 7m 49s\tremaining: 2m 1s\n",
      "794:\tlearn: 2.9477392\ttotal: 7m 49s\tremaining: 2m 1s\n",
      "795:\tlearn: 2.9475285\ttotal: 7m 50s\tremaining: 2m\n",
      "796:\tlearn: 2.9470662\ttotal: 7m 51s\tremaining: 2m\n",
      "797:\tlearn: 2.9466416\ttotal: 7m 51s\tremaining: 1m 59s\n",
      "798:\tlearn: 2.9462632\ttotal: 7m 52s\tremaining: 1m 58s\n",
      "799:\tlearn: 2.9458838\ttotal: 7m 52s\tremaining: 1m 58s\n",
      "800:\tlearn: 2.9456431\ttotal: 7m 53s\tremaining: 1m 57s\n",
      "801:\tlearn: 2.9452020\ttotal: 7m 53s\tremaining: 1m 57s\n",
      "802:\tlearn: 2.9451414\ttotal: 7m 54s\tremaining: 1m 56s\n",
      "803:\tlearn: 2.9450851\ttotal: 7m 55s\tremaining: 1m 55s\n",
      "804:\tlearn: 2.9447258\ttotal: 7m 55s\tremaining: 1m 55s\n",
      "805:\tlearn: 2.9443900\ttotal: 7m 56s\tremaining: 1m 54s\n",
      "806:\tlearn: 2.9438773\ttotal: 7m 56s\tremaining: 1m 54s\n",
      "807:\tlearn: 2.9436401\ttotal: 7m 57s\tremaining: 1m 53s\n",
      "808:\tlearn: 2.9433023\ttotal: 7m 57s\tremaining: 1m 52s\n",
      "809:\tlearn: 2.9432454\ttotal: 7m 58s\tremaining: 1m 52s\n",
      "810:\tlearn: 2.9430409\ttotal: 7m 59s\tremaining: 1m 51s\n",
      "811:\tlearn: 2.9428753\ttotal: 7m 59s\tremaining: 1m 51s\n",
      "812:\tlearn: 2.9426404\ttotal: 8m\tremaining: 1m 50s\n",
      "813:\tlearn: 2.9425343\ttotal: 8m\tremaining: 1m 49s\n",
      "814:\tlearn: 2.9423452\ttotal: 8m 1s\tremaining: 1m 49s\n",
      "815:\tlearn: 2.9419352\ttotal: 8m 1s\tremaining: 1m 48s\n",
      "816:\tlearn: 2.9414745\ttotal: 8m 2s\tremaining: 1m 48s\n",
      "817:\tlearn: 2.9413474\ttotal: 8m 2s\tremaining: 1m 47s\n",
      "818:\tlearn: 2.9409864\ttotal: 8m 3s\tremaining: 1m 46s\n",
      "819:\tlearn: 2.9407466\ttotal: 8m 4s\tremaining: 1m 46s\n",
      "820:\tlearn: 2.9404982\ttotal: 8m 4s\tremaining: 1m 45s\n",
      "821:\tlearn: 2.9403078\ttotal: 8m 5s\tremaining: 1m 45s\n",
      "822:\tlearn: 2.9401681\ttotal: 8m 5s\tremaining: 1m 44s\n",
      "823:\tlearn: 2.9400693\ttotal: 8m 6s\tremaining: 1m 43s\n",
      "824:\tlearn: 2.9396406\ttotal: 8m 6s\tremaining: 1m 43s\n",
      "825:\tlearn: 2.9395201\ttotal: 8m 7s\tremaining: 1m 42s\n",
      "826:\tlearn: 2.9391497\ttotal: 8m 7s\tremaining: 1m 42s\n",
      "827:\tlearn: 2.9389814\ttotal: 8m 8s\tremaining: 1m 41s\n",
      "828:\tlearn: 2.9386694\ttotal: 8m 9s\tremaining: 1m 40s\n",
      "829:\tlearn: 2.9383950\ttotal: 8m 9s\tremaining: 1m 40s\n",
      "830:\tlearn: 2.9382971\ttotal: 8m 10s\tremaining: 1m 39s\n",
      "831:\tlearn: 2.9381467\ttotal: 8m 10s\tremaining: 1m 39s\n",
      "832:\tlearn: 2.9380111\ttotal: 8m 11s\tremaining: 1m 38s\n",
      "833:\tlearn: 2.9375223\ttotal: 8m 11s\tremaining: 1m 37s\n",
      "834:\tlearn: 2.9369698\ttotal: 8m 12s\tremaining: 1m 37s\n",
      "835:\tlearn: 2.9369146\ttotal: 8m 13s\tremaining: 1m 36s\n",
      "836:\tlearn: 2.9364125\ttotal: 8m 13s\tremaining: 1m 36s\n",
      "837:\tlearn: 2.9361345\ttotal: 8m 14s\tremaining: 1m 35s\n",
      "838:\tlearn: 2.9360819\ttotal: 8m 14s\tremaining: 1m 34s\n",
      "839:\tlearn: 2.9358950\ttotal: 8m 15s\tremaining: 1m 34s\n",
      "840:\tlearn: 2.9356503\ttotal: 8m 15s\tremaining: 1m 33s\n",
      "841:\tlearn: 2.9354565\ttotal: 8m 16s\tremaining: 1m 33s\n",
      "842:\tlearn: 2.9349866\ttotal: 8m 17s\tremaining: 1m 32s\n",
      "843:\tlearn: 2.9346818\ttotal: 8m 17s\tremaining: 1m 31s\n",
      "844:\tlearn: 2.9344422\ttotal: 8m 18s\tremaining: 1m 31s\n",
      "845:\tlearn: 2.9343225\ttotal: 8m 18s\tremaining: 1m 30s\n",
      "846:\tlearn: 2.9339927\ttotal: 8m 19s\tremaining: 1m 30s\n",
      "847:\tlearn: 2.9336781\ttotal: 8m 19s\tremaining: 1m 29s\n",
      "848:\tlearn: 2.9334780\ttotal: 8m 20s\tremaining: 1m 28s\n",
      "849:\tlearn: 2.9329330\ttotal: 8m 21s\tremaining: 1m 28s\n",
      "850:\tlearn: 2.9327331\ttotal: 8m 21s\tremaining: 1m 27s\n",
      "851:\tlearn: 2.9324964\ttotal: 8m 22s\tremaining: 1m 27s\n",
      "852:\tlearn: 2.9323671\ttotal: 8m 22s\tremaining: 1m 26s\n",
      "853:\tlearn: 2.9322687\ttotal: 8m 23s\tremaining: 1m 26s\n",
      "854:\tlearn: 2.9322020\ttotal: 8m 23s\tremaining: 1m 25s\n",
      "855:\tlearn: 2.9318934\ttotal: 8m 24s\tremaining: 1m 24s\n",
      "856:\tlearn: 2.9318083\ttotal: 8m 24s\tremaining: 1m 24s\n",
      "857:\tlearn: 2.9313164\ttotal: 8m 25s\tremaining: 1m 23s\n",
      "858:\tlearn: 2.9309377\ttotal: 8m 26s\tremaining: 1m 23s\n",
      "859:\tlearn: 2.9308698\ttotal: 8m 26s\tremaining: 1m 22s\n",
      "860:\tlearn: 2.9308168\ttotal: 8m 27s\tremaining: 1m 21s\n",
      "861:\tlearn: 2.9307601\ttotal: 8m 27s\tremaining: 1m 21s\n",
      "862:\tlearn: 2.9303483\ttotal: 8m 28s\tremaining: 1m 20s\n",
      "863:\tlearn: 2.9302880\ttotal: 8m 28s\tremaining: 1m 20s\n",
      "864:\tlearn: 2.9298692\ttotal: 8m 29s\tremaining: 1m 19s\n",
      "865:\tlearn: 2.9294261\ttotal: 8m 30s\tremaining: 1m 18s\n",
      "866:\tlearn: 2.9293603\ttotal: 8m 30s\tremaining: 1m 18s\n",
      "867:\tlearn: 2.9291080\ttotal: 8m 31s\tremaining: 1m 17s\n",
      "868:\tlearn: 2.9286965\ttotal: 8m 31s\tremaining: 1m 17s\n",
      "869:\tlearn: 2.9283913\ttotal: 8m 32s\tremaining: 1m 16s\n",
      "870:\tlearn: 2.9282718\ttotal: 8m 32s\tremaining: 1m 15s\n",
      "871:\tlearn: 2.9281222\ttotal: 8m 33s\tremaining: 1m 15s\n",
      "872:\tlearn: 2.9279992\ttotal: 8m 34s\tremaining: 1m 14s\n",
      "873:\tlearn: 2.9275146\ttotal: 8m 34s\tremaining: 1m 14s\n",
      "874:\tlearn: 2.9272630\ttotal: 8m 35s\tremaining: 1m 13s\n",
      "875:\tlearn: 2.9270072\ttotal: 8m 36s\tremaining: 1m 13s\n",
      "876:\tlearn: 2.9264685\ttotal: 8m 37s\tremaining: 1m 12s\n",
      "877:\tlearn: 2.9261780\ttotal: 8m 38s\tremaining: 1m 11s\n",
      "878:\tlearn: 2.9261170\ttotal: 8m 38s\tremaining: 1m 11s\n",
      "879:\tlearn: 2.9259476\ttotal: 8m 39s\tremaining: 1m 10s\n",
      "880:\tlearn: 2.9258595\ttotal: 8m 40s\tremaining: 1m 10s\n",
      "881:\tlearn: 2.9257975\ttotal: 8m 40s\tremaining: 1m 9s\n",
      "882:\tlearn: 2.9257437\ttotal: 8m 41s\tremaining: 1m 9s\n",
      "883:\tlearn: 2.9256810\ttotal: 8m 42s\tremaining: 1m 8s\n",
      "884:\tlearn: 2.9255720\ttotal: 8m 42s\tremaining: 1m 7s\n",
      "885:\tlearn: 2.9255103\ttotal: 8m 43s\tremaining: 1m 7s\n",
      "886:\tlearn: 2.9254259\ttotal: 8m 43s\tremaining: 1m 6s\n",
      "887:\tlearn: 2.9250095\ttotal: 8m 44s\tremaining: 1m 6s\n",
      "888:\tlearn: 2.9248048\ttotal: 8m 44s\tremaining: 1m 5s\n",
      "889:\tlearn: 2.9246783\ttotal: 8m 45s\tremaining: 1m 4s\n",
      "890:\tlearn: 2.9243618\ttotal: 8m 45s\tremaining: 1m 4s\n",
      "891:\tlearn: 2.9240466\ttotal: 8m 46s\tremaining: 1m 3s\n",
      "892:\tlearn: 2.9237389\ttotal: 8m 46s\tremaining: 1m 3s\n",
      "893:\tlearn: 2.9233614\ttotal: 8m 47s\tremaining: 1m 2s\n",
      "894:\tlearn: 2.9230467\ttotal: 8m 48s\tremaining: 1m 1s\n",
      "895:\tlearn: 2.9228712\ttotal: 8m 48s\tremaining: 1m 1s\n",
      "896:\tlearn: 2.9226385\ttotal: 8m 49s\tremaining: 1m\n",
      "897:\tlearn: 2.9223314\ttotal: 8m 49s\tremaining: 1m\n",
      "898:\tlearn: 2.9220367\ttotal: 8m 50s\tremaining: 59.6s\n",
      "899:\tlearn: 2.9216761\ttotal: 8m 51s\tremaining: 59s\n",
      "900:\tlearn: 2.9214660\ttotal: 8m 51s\tremaining: 58.4s\n",
      "901:\tlearn: 2.9213312\ttotal: 8m 51s\tremaining: 57.8s\n",
      "902:\tlearn: 2.9210833\ttotal: 8m 52s\tremaining: 57.2s\n",
      "903:\tlearn: 2.9207919\ttotal: 8m 53s\tremaining: 56.6s\n",
      "904:\tlearn: 2.9206591\ttotal: 8m 53s\tremaining: 56s\n",
      "905:\tlearn: 2.9205382\ttotal: 8m 54s\tremaining: 55.4s\n",
      "906:\tlearn: 2.9202394\ttotal: 8m 54s\tremaining: 54.8s\n",
      "907:\tlearn: 2.9199966\ttotal: 8m 55s\tremaining: 54.2s\n",
      "908:\tlearn: 2.9194711\ttotal: 8m 55s\tremaining: 53.6s\n",
      "909:\tlearn: 2.9189510\ttotal: 8m 56s\tremaining: 53s\n",
      "910:\tlearn: 2.9185888\ttotal: 8m 56s\tremaining: 52.4s\n",
      "911:\tlearn: 2.9182715\ttotal: 8m 57s\tremaining: 51.8s\n",
      "912:\tlearn: 2.9179677\ttotal: 8m 57s\tremaining: 51.2s\n",
      "913:\tlearn: 2.9177924\ttotal: 8m 58s\tremaining: 50.6s\n",
      "914:\tlearn: 2.9175813\ttotal: 8m 58s\tremaining: 50.1s\n",
      "915:\tlearn: 2.9174059\ttotal: 8m 59s\tremaining: 49.5s\n",
      "916:\tlearn: 2.9172517\ttotal: 8m 59s\tremaining: 48.9s\n",
      "917:\tlearn: 2.9168401\ttotal: 9m\tremaining: 48.3s\n",
      "918:\tlearn: 2.9164307\ttotal: 9m 1s\tremaining: 47.7s\n",
      "919:\tlearn: 2.9160389\ttotal: 9m 1s\tremaining: 47.1s\n",
      "920:\tlearn: 2.9158705\ttotal: 9m 2s\tremaining: 46.5s\n",
      "921:\tlearn: 2.9156603\ttotal: 9m 2s\tremaining: 45.9s\n",
      "922:\tlearn: 2.9152276\ttotal: 9m 3s\tremaining: 45.3s\n",
      "923:\tlearn: 2.9149185\ttotal: 9m 4s\tremaining: 44.8s\n",
      "924:\tlearn: 2.9145647\ttotal: 9m 4s\tremaining: 44.2s\n",
      "925:\tlearn: 2.9143206\ttotal: 9m 5s\tremaining: 43.6s\n",
      "926:\tlearn: 2.9138033\ttotal: 9m 6s\tremaining: 43s\n",
      "927:\tlearn: 2.9135017\ttotal: 9m 6s\tremaining: 42.4s\n",
      "928:\tlearn: 2.9133113\ttotal: 9m 7s\tremaining: 41.8s\n",
      "929:\tlearn: 2.9130485\ttotal: 9m 7s\tremaining: 41.2s\n",
      "930:\tlearn: 2.9129330\ttotal: 9m 8s\tremaining: 40.6s\n",
      "931:\tlearn: 2.9127765\ttotal: 9m 8s\tremaining: 40s\n",
      "932:\tlearn: 2.9125253\ttotal: 9m 9s\tremaining: 39.5s\n",
      "933:\tlearn: 2.9123142\ttotal: 9m 9s\tremaining: 38.9s\n",
      "934:\tlearn: 2.9119307\ttotal: 9m 10s\tremaining: 38.3s\n",
      "935:\tlearn: 2.9116104\ttotal: 9m 11s\tremaining: 37.7s\n",
      "936:\tlearn: 2.9113979\ttotal: 9m 11s\tremaining: 37.1s\n",
      "937:\tlearn: 2.9108880\ttotal: 9m 12s\tremaining: 36.5s\n",
      "938:\tlearn: 2.9105050\ttotal: 9m 12s\tremaining: 35.9s\n",
      "939:\tlearn: 2.9099928\ttotal: 9m 13s\tremaining: 35.3s\n",
      "940:\tlearn: 2.9097363\ttotal: 9m 13s\tremaining: 34.7s\n",
      "941:\tlearn: 2.9094332\ttotal: 9m 14s\tremaining: 34.1s\n",
      "942:\tlearn: 2.9092538\ttotal: 9m 15s\tremaining: 33.6s\n",
      "943:\tlearn: 2.9091238\ttotal: 9m 15s\tremaining: 33s\n",
      "944:\tlearn: 2.9087082\ttotal: 9m 16s\tremaining: 32.4s\n",
      "945:\tlearn: 2.9084520\ttotal: 9m 16s\tremaining: 31.8s\n",
      "946:\tlearn: 2.9082091\ttotal: 9m 17s\tremaining: 31.2s\n",
      "947:\tlearn: 2.9079776\ttotal: 9m 17s\tremaining: 30.6s\n",
      "948:\tlearn: 2.9076096\ttotal: 9m 18s\tremaining: 30s\n",
      "949:\tlearn: 2.9073338\ttotal: 9m 18s\tremaining: 29.4s\n",
      "950:\tlearn: 2.9070125\ttotal: 9m 19s\tremaining: 28.8s\n",
      "951:\tlearn: 2.9067607\ttotal: 9m 20s\tremaining: 28.2s\n",
      "952:\tlearn: 2.9063894\ttotal: 9m 20s\tremaining: 27.7s\n",
      "953:\tlearn: 2.9061211\ttotal: 9m 21s\tremaining: 27.1s\n",
      "954:\tlearn: 2.9057551\ttotal: 9m 21s\tremaining: 26.5s\n",
      "955:\tlearn: 2.9054111\ttotal: 9m 22s\tremaining: 25.9s\n",
      "956:\tlearn: 2.9050627\ttotal: 9m 22s\tremaining: 25.3s\n",
      "957:\tlearn: 2.9047216\ttotal: 9m 23s\tremaining: 24.7s\n",
      "958:\tlearn: 2.9044797\ttotal: 9m 24s\tremaining: 24.1s\n",
      "959:\tlearn: 2.9039044\ttotal: 9m 24s\tremaining: 23.5s\n",
      "960:\tlearn: 2.9038039\ttotal: 9m 25s\tremaining: 22.9s\n",
      "961:\tlearn: 2.9034903\ttotal: 9m 26s\tremaining: 22.4s\n",
      "962:\tlearn: 2.9031857\ttotal: 9m 26s\tremaining: 21.8s\n",
      "963:\tlearn: 2.9029121\ttotal: 9m 27s\tremaining: 21.2s\n",
      "964:\tlearn: 2.9024950\ttotal: 9m 27s\tremaining: 20.6s\n",
      "965:\tlearn: 2.9023530\ttotal: 9m 28s\tremaining: 20s\n",
      "966:\tlearn: 2.9022611\ttotal: 9m 28s\tremaining: 19.4s\n",
      "967:\tlearn: 2.9021774\ttotal: 9m 29s\tremaining: 18.8s\n",
      "968:\tlearn: 2.9013900\ttotal: 9m 30s\tremaining: 18.2s\n",
      "969:\tlearn: 2.9009439\ttotal: 9m 30s\tremaining: 17.7s\n",
      "970:\tlearn: 2.9006996\ttotal: 9m 31s\tremaining: 17.1s\n",
      "971:\tlearn: 2.9002927\ttotal: 9m 32s\tremaining: 16.5s\n",
      "972:\tlearn: 2.8999935\ttotal: 9m 32s\tremaining: 15.9s\n",
      "973:\tlearn: 2.8998168\ttotal: 9m 33s\tremaining: 15.3s\n",
      "974:\tlearn: 2.8995030\ttotal: 9m 33s\tremaining: 14.7s\n",
      "975:\tlearn: 2.8993743\ttotal: 9m 34s\tremaining: 14.1s\n",
      "976:\tlearn: 2.8989989\ttotal: 9m 34s\tremaining: 13.5s\n",
      "977:\tlearn: 2.8985945\ttotal: 9m 35s\tremaining: 12.9s\n",
      "978:\tlearn: 2.8984912\ttotal: 9m 36s\tremaining: 12.4s\n",
      "979:\tlearn: 2.8983375\ttotal: 9m 36s\tremaining: 11.8s\n",
      "980:\tlearn: 2.8981969\ttotal: 9m 37s\tremaining: 11.2s\n",
      "981:\tlearn: 2.8981064\ttotal: 9m 37s\tremaining: 10.6s\n",
      "982:\tlearn: 2.8979900\ttotal: 9m 38s\tremaining: 10s\n",
      "983:\tlearn: 2.8975453\ttotal: 9m 39s\tremaining: 9.42s\n",
      "984:\tlearn: 2.8972415\ttotal: 9m 39s\tremaining: 8.83s\n",
      "985:\tlearn: 2.8969451\ttotal: 9m 40s\tremaining: 8.24s\n",
      "986:\tlearn: 2.8966701\ttotal: 9m 40s\tremaining: 7.65s\n",
      "987:\tlearn: 2.8963140\ttotal: 9m 41s\tremaining: 7.06s\n",
      "988:\tlearn: 2.8959698\ttotal: 9m 42s\tremaining: 6.47s\n",
      "989:\tlearn: 2.8959172\ttotal: 9m 42s\tremaining: 5.88s\n",
      "990:\tlearn: 2.8956168\ttotal: 9m 43s\tremaining: 5.3s\n",
      "991:\tlearn: 2.8952828\ttotal: 9m 43s\tremaining: 4.71s\n",
      "992:\tlearn: 2.8952380\ttotal: 9m 44s\tremaining: 4.12s\n",
      "993:\tlearn: 2.8950814\ttotal: 9m 45s\tremaining: 3.53s\n",
      "994:\tlearn: 2.8949327\ttotal: 9m 45s\tremaining: 2.94s\n",
      "995:\tlearn: 2.8948050\ttotal: 9m 46s\tremaining: 2.35s\n",
      "996:\tlearn: 2.8944698\ttotal: 9m 46s\tremaining: 1.76s\n",
      "997:\tlearn: 2.8939768\ttotal: 9m 47s\tremaining: 1.18s\n",
      "998:\tlearn: 2.8939184\ttotal: 9m 48s\tremaining: 589ms\n",
      "999:\tlearn: 2.8937377\ttotal: 9m 48s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_squared_error': 10.48606994087936,\n",
       " 'mean_absolute_percentage_error': 6558457133422.015,\n",
       " 'r2': 0.15355473743178216}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "model = CatBoostRegressor()\n",
    "\n",
    "model.fit(X_train_proccesed, y_train)\n",
    "\n",
    "scores = {\n",
    "    'mean_squared_error': mean_squared_error(y_test, model.predict(X_test_proccesed)),\n",
    "    'mean_squared_error': mean_squared_error(y_test, model.predict(X_test_proccesed)),\n",
    "    'mean_absolute_percentage_error': mean_absolute_percentage_error(y_test, model.predict(X_test_proccesed)),\n",
    "    'r2': r2_score(y_test, model.predict(X_test_proccesed)),\n",
    "}\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c191380a-9882-4539-bf31-01b86309475e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_squared_error': 10.668367248496512,\n",
       " 'mean_absolute_percentage_error': 6499537059397.321,\n",
       " 'r2': 0.13883953018240736}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor()\n",
    "\n",
    "model.fit(X_train_proccesed, y_train)\n",
    "\n",
    "scores = {\n",
    "    'mean_squared_error': mean_squared_error(y_test, model.predict(X_test_proccesed)),\n",
    "    'mean_absolute_percentage_error': mean_absolute_percentage_error(y_test, model.predict(X_test_proccesed)),\n",
    "    'r2': r2_score(y_test, model.predict(X_test_proccesed)),\n",
    "}\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bcb27e2f-ac13-4eaf-a869-1be2298746cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 5.592813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1902983\n",
      "[LightGBM] [Info] Number of data points in the train set: 100471, number of used features: 40428\n",
      "[LightGBM] [Info] Start training from score 0.107487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_squared_error': 10.633911638477876,\n",
       " 'mean_absolute_percentage_error': 6149678652337.21,\n",
       " 'r2': 0.14162081888576372}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    " \n",
    "model = LGBMRegressor(metric='mse')\n",
    "\n",
    "model.fit(X_train_proccesed, y_train)\n",
    "\n",
    "scores = {\n",
    "    'mean_squared_error': mean_squared_error(y_test, model.predict(X_test_proccesed)),\n",
    "    'mean_absolute_percentage_error': mean_absolute_percentage_error(y_test, model.predict(X_test_proccesed)),\n",
    "    'r2': r2_score(y_test, model.predict(X_test_proccesed)),\n",
    "}\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f104bb6-3e4b-4481-9271-bf7230ae702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[df_merged['Symbol'] == 'AAPL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce582f8d-83ab-4e74-8834-24e16bc11a2c",
   "metadata": {},
   "source": [
    "# Only AAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "515fa2cc-1393-46d7-8437-8286cb64561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aapl = df_merged[df_merged['Symbol'] == 'AAPL'][['body', 'pct_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0891e01-0a27-4911-9974-ffed7cf12143",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T09:56:59.928672Z",
     "start_time": "2024-02-05T09:56:59.765906Z"
    }
   },
   "outputs": [],
   "source": [
    "df_aapl['body_preprocessed'] = df_aapl['body'].apply(lambda x: text_to_wordlist(x, stem_words=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6450cfb7-a11b-46a0-98fc-3f13f767c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    input=\"content\",\n",
    "    tokenizer=text_to_wordlist,\n",
    "    token_pattern=None,\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_aapl, df_aapl[\"pct_diff\"], test_size=0.3)\n",
    "\n",
    "\n",
    "X_train_body_vectorized = vectorizer.fit_transform(X_train[\"body\"])\n",
    "X_test_body_vectorized = vectorizer.transform(X_test[\"body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0eb1a517-d75b-4f98-8d2f-ed8846da65fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.057529\n",
      "0:\tlearn: 2.0949785\ttotal: 295ms\tremaining: 4m 54s\n",
      "1:\tlearn: 2.0930747\ttotal: 445ms\tremaining: 3m 42s\n",
      "2:\tlearn: 2.0916982\ttotal: 558ms\tremaining: 3m 5s\n",
      "3:\tlearn: 2.0890859\ttotal: 669ms\tremaining: 2m 46s\n",
      "4:\tlearn: 2.0873476\ttotal: 774ms\tremaining: 2m 34s\n",
      "5:\tlearn: 2.0856431\ttotal: 887ms\tremaining: 2m 26s\n",
      "6:\tlearn: 2.0846084\ttotal: 996ms\tremaining: 2m 21s\n",
      "7:\tlearn: 2.0831892\ttotal: 1.11s\tremaining: 2m 17s\n",
      "8:\tlearn: 2.0820847\ttotal: 1.23s\tremaining: 2m 15s\n",
      "9:\tlearn: 2.0809140\ttotal: 1.34s\tremaining: 2m 13s\n",
      "10:\tlearn: 2.0787592\ttotal: 1.47s\tremaining: 2m 12s\n",
      "11:\tlearn: 2.0783463\ttotal: 1.58s\tremaining: 2m 10s\n",
      "12:\tlearn: 2.0773026\ttotal: 1.69s\tremaining: 2m 8s\n",
      "13:\tlearn: 2.0765409\ttotal: 1.81s\tremaining: 2m 7s\n",
      "14:\tlearn: 2.0752359\ttotal: 1.92s\tremaining: 2m 5s\n",
      "15:\tlearn: 2.0740933\ttotal: 2.03s\tremaining: 2m 4s\n",
      "16:\tlearn: 2.0734786\ttotal: 2.14s\tremaining: 2m 3s\n",
      "17:\tlearn: 2.0724447\ttotal: 2.25s\tremaining: 2m 2s\n",
      "18:\tlearn: 2.0702818\ttotal: 2.36s\tremaining: 2m 1s\n",
      "19:\tlearn: 2.0696732\ttotal: 2.47s\tremaining: 2m\n",
      "20:\tlearn: 2.0674229\ttotal: 2.57s\tremaining: 2m\n",
      "21:\tlearn: 2.0669694\ttotal: 2.69s\tremaining: 1m 59s\n",
      "22:\tlearn: 2.0657420\ttotal: 2.8s\tremaining: 1m 58s\n",
      "23:\tlearn: 2.0649311\ttotal: 2.92s\tremaining: 1m 58s\n",
      "24:\tlearn: 2.0635355\ttotal: 3.05s\tremaining: 1m 59s\n",
      "25:\tlearn: 2.0623753\ttotal: 3.16s\tremaining: 1m 58s\n",
      "26:\tlearn: 2.0609050\ttotal: 3.28s\tremaining: 1m 58s\n",
      "27:\tlearn: 2.0598802\ttotal: 3.39s\tremaining: 1m 57s\n",
      "28:\tlearn: 2.0593746\ttotal: 3.5s\tremaining: 1m 57s\n",
      "29:\tlearn: 2.0587709\ttotal: 3.61s\tremaining: 1m 56s\n",
      "30:\tlearn: 2.0582691\ttotal: 3.72s\tremaining: 1m 56s\n",
      "31:\tlearn: 2.0573949\ttotal: 3.85s\tremaining: 1m 56s\n",
      "32:\tlearn: 2.0568530\ttotal: 3.97s\tremaining: 1m 56s\n",
      "33:\tlearn: 2.0559799\ttotal: 4.08s\tremaining: 1m 55s\n",
      "34:\tlearn: 2.0554479\ttotal: 4.19s\tremaining: 1m 55s\n",
      "35:\tlearn: 2.0551194\ttotal: 4.3s\tremaining: 1m 55s\n",
      "36:\tlearn: 2.0547695\ttotal: 4.41s\tremaining: 1m 54s\n",
      "37:\tlearn: 2.0543575\ttotal: 4.52s\tremaining: 1m 54s\n",
      "38:\tlearn: 2.0530780\ttotal: 4.63s\tremaining: 1m 53s\n",
      "39:\tlearn: 2.0523516\ttotal: 4.74s\tremaining: 1m 53s\n",
      "40:\tlearn: 2.0515238\ttotal: 4.85s\tremaining: 1m 53s\n",
      "41:\tlearn: 2.0498665\ttotal: 4.96s\tremaining: 1m 53s\n",
      "42:\tlearn: 2.0493947\ttotal: 5.08s\tremaining: 1m 52s\n",
      "43:\tlearn: 2.0488943\ttotal: 5.19s\tremaining: 1m 52s\n",
      "44:\tlearn: 2.0480826\ttotal: 5.31s\tremaining: 1m 52s\n",
      "45:\tlearn: 2.0476008\ttotal: 5.42s\tremaining: 1m 52s\n",
      "46:\tlearn: 2.0471993\ttotal: 5.53s\tremaining: 1m 52s\n",
      "47:\tlearn: 2.0459871\ttotal: 5.64s\tremaining: 1m 51s\n",
      "48:\tlearn: 2.0448617\ttotal: 5.75s\tremaining: 1m 51s\n",
      "49:\tlearn: 2.0437705\ttotal: 5.86s\tremaining: 1m 51s\n",
      "50:\tlearn: 2.0428331\ttotal: 5.97s\tremaining: 1m 51s\n",
      "51:\tlearn: 2.0405990\ttotal: 6.08s\tremaining: 1m 50s\n",
      "52:\tlearn: 2.0401666\ttotal: 6.18s\tremaining: 1m 50s\n",
      "53:\tlearn: 2.0396083\ttotal: 6.29s\tremaining: 1m 50s\n",
      "54:\tlearn: 2.0391358\ttotal: 6.4s\tremaining: 1m 50s\n",
      "55:\tlearn: 2.0378425\ttotal: 6.51s\tremaining: 1m 49s\n",
      "56:\tlearn: 2.0369827\ttotal: 6.62s\tremaining: 1m 49s\n",
      "57:\tlearn: 2.0361205\ttotal: 6.74s\tremaining: 1m 49s\n",
      "58:\tlearn: 2.0354318\ttotal: 6.86s\tremaining: 1m 49s\n",
      "59:\tlearn: 2.0331106\ttotal: 6.96s\tremaining: 1m 49s\n",
      "60:\tlearn: 2.0322739\ttotal: 7.07s\tremaining: 1m 48s\n",
      "61:\tlearn: 2.0318145\ttotal: 7.18s\tremaining: 1m 48s\n",
      "62:\tlearn: 2.0308221\ttotal: 7.29s\tremaining: 1m 48s\n",
      "63:\tlearn: 2.0302540\ttotal: 7.39s\tremaining: 1m 48s\n",
      "64:\tlearn: 2.0290937\ttotal: 7.5s\tremaining: 1m 47s\n",
      "65:\tlearn: 2.0286831\ttotal: 7.61s\tremaining: 1m 47s\n",
      "66:\tlearn: 2.0280499\ttotal: 7.71s\tremaining: 1m 47s\n",
      "67:\tlearn: 2.0274461\ttotal: 7.82s\tremaining: 1m 47s\n",
      "68:\tlearn: 2.0270097\ttotal: 7.93s\tremaining: 1m 47s\n",
      "69:\tlearn: 2.0259181\ttotal: 8.04s\tremaining: 1m 46s\n",
      "70:\tlearn: 2.0255583\ttotal: 8.15s\tremaining: 1m 46s\n",
      "71:\tlearn: 2.0241728\ttotal: 8.27s\tremaining: 1m 46s\n",
      "72:\tlearn: 2.0238425\ttotal: 8.38s\tremaining: 1m 46s\n",
      "73:\tlearn: 2.0234785\ttotal: 8.49s\tremaining: 1m 46s\n",
      "74:\tlearn: 2.0230140\ttotal: 8.6s\tremaining: 1m 46s\n",
      "75:\tlearn: 2.0221486\ttotal: 8.7s\tremaining: 1m 45s\n",
      "76:\tlearn: 2.0217059\ttotal: 8.81s\tremaining: 1m 45s\n",
      "77:\tlearn: 2.0207616\ttotal: 8.92s\tremaining: 1m 45s\n",
      "78:\tlearn: 2.0192171\ttotal: 9.03s\tremaining: 1m 45s\n",
      "79:\tlearn: 2.0188102\ttotal: 9.14s\tremaining: 1m 45s\n",
      "80:\tlearn: 2.0173356\ttotal: 9.25s\tremaining: 1m 44s\n",
      "81:\tlearn: 2.0168407\ttotal: 9.36s\tremaining: 1m 44s\n",
      "82:\tlearn: 2.0161653\ttotal: 9.47s\tremaining: 1m 44s\n",
      "83:\tlearn: 2.0157727\ttotal: 9.59s\tremaining: 1m 44s\n",
      "84:\tlearn: 2.0147597\ttotal: 9.7s\tremaining: 1m 44s\n",
      "85:\tlearn: 2.0143732\ttotal: 9.81s\tremaining: 1m 44s\n",
      "86:\tlearn: 2.0134987\ttotal: 9.92s\tremaining: 1m 44s\n",
      "87:\tlearn: 2.0129170\ttotal: 10s\tremaining: 1m 43s\n",
      "88:\tlearn: 2.0126513\ttotal: 10.2s\tremaining: 1m 43s\n",
      "89:\tlearn: 2.0122589\ttotal: 10.3s\tremaining: 1m 44s\n",
      "90:\tlearn: 2.0109301\ttotal: 10.4s\tremaining: 1m 44s\n",
      "91:\tlearn: 2.0105004\ttotal: 10.6s\tremaining: 1m 44s\n",
      "92:\tlearn: 2.0100192\ttotal: 10.7s\tremaining: 1m 44s\n",
      "93:\tlearn: 2.0082302\ttotal: 10.8s\tremaining: 1m 43s\n",
      "94:\tlearn: 2.0073385\ttotal: 10.9s\tremaining: 1m 43s\n",
      "95:\tlearn: 2.0067512\ttotal: 11s\tremaining: 1m 43s\n",
      "96:\tlearn: 2.0064146\ttotal: 11.1s\tremaining: 1m 43s\n",
      "97:\tlearn: 2.0060122\ttotal: 11.2s\tremaining: 1m 43s\n",
      "98:\tlearn: 2.0052643\ttotal: 11.3s\tremaining: 1m 42s\n",
      "99:\tlearn: 2.0049401\ttotal: 11.4s\tremaining: 1m 42s\n",
      "100:\tlearn: 2.0045048\ttotal: 11.5s\tremaining: 1m 42s\n",
      "101:\tlearn: 2.0039613\ttotal: 11.6s\tremaining: 1m 42s\n",
      "102:\tlearn: 2.0036655\ttotal: 11.7s\tremaining: 1m 42s\n",
      "103:\tlearn: 2.0032914\ttotal: 11.8s\tremaining: 1m 42s\n",
      "104:\tlearn: 2.0029680\ttotal: 12s\tremaining: 1m 41s\n",
      "105:\tlearn: 2.0005916\ttotal: 12.1s\tremaining: 1m 41s\n",
      "106:\tlearn: 2.0002403\ttotal: 12.2s\tremaining: 1m 41s\n",
      "107:\tlearn: 1.9996863\ttotal: 12.3s\tremaining: 1m 41s\n",
      "108:\tlearn: 1.9990968\ttotal: 12.4s\tremaining: 1m 41s\n",
      "109:\tlearn: 1.9986067\ttotal: 12.5s\tremaining: 1m 41s\n",
      "110:\tlearn: 1.9982534\ttotal: 12.6s\tremaining: 1m 41s\n",
      "111:\tlearn: 1.9979266\ttotal: 12.7s\tremaining: 1m 40s\n",
      "112:\tlearn: 1.9971684\ttotal: 12.8s\tremaining: 1m 40s\n",
      "113:\tlearn: 1.9968246\ttotal: 12.9s\tremaining: 1m 40s\n",
      "114:\tlearn: 1.9965888\ttotal: 13.1s\tremaining: 1m 40s\n",
      "115:\tlearn: 1.9962586\ttotal: 13.2s\tremaining: 1m 40s\n",
      "116:\tlearn: 1.9959156\ttotal: 13.3s\tremaining: 1m 40s\n",
      "117:\tlearn: 1.9943873\ttotal: 13.4s\tremaining: 1m 39s\n",
      "118:\tlearn: 1.9939299\ttotal: 13.5s\tremaining: 1m 39s\n",
      "119:\tlearn: 1.9935545\ttotal: 13.6s\tremaining: 1m 39s\n",
      "120:\tlearn: 1.9921061\ttotal: 13.7s\tremaining: 1m 39s\n",
      "121:\tlearn: 1.9914159\ttotal: 13.8s\tremaining: 1m 39s\n",
      "122:\tlearn: 1.9906768\ttotal: 13.9s\tremaining: 1m 39s\n",
      "123:\tlearn: 1.9904142\ttotal: 14s\tremaining: 1m 39s\n",
      "124:\tlearn: 1.9899037\ttotal: 14.1s\tremaining: 1m 38s\n",
      "125:\tlearn: 1.9895905\ttotal: 14.3s\tremaining: 1m 38s\n",
      "126:\tlearn: 1.9889394\ttotal: 14.4s\tremaining: 1m 38s\n",
      "127:\tlearn: 1.9885365\ttotal: 14.5s\tremaining: 1m 38s\n",
      "128:\tlearn: 1.9881434\ttotal: 14.6s\tremaining: 1m 38s\n",
      "129:\tlearn: 1.9874674\ttotal: 14.7s\tremaining: 1m 38s\n",
      "130:\tlearn: 1.9870831\ttotal: 14.8s\tremaining: 1m 38s\n",
      "131:\tlearn: 1.9867202\ttotal: 14.9s\tremaining: 1m 38s\n",
      "132:\tlearn: 1.9851976\ttotal: 15s\tremaining: 1m 38s\n",
      "133:\tlearn: 1.9843748\ttotal: 15.2s\tremaining: 1m 37s\n",
      "134:\tlearn: 1.9830991\ttotal: 15.3s\tremaining: 1m 37s\n",
      "135:\tlearn: 1.9824369\ttotal: 15.4s\tremaining: 1m 37s\n",
      "136:\tlearn: 1.9820505\ttotal: 15.5s\tremaining: 1m 37s\n",
      "137:\tlearn: 1.9816790\ttotal: 15.6s\tremaining: 1m 37s\n",
      "138:\tlearn: 1.9812417\ttotal: 15.8s\tremaining: 1m 37s\n",
      "139:\tlearn: 1.9806649\ttotal: 15.9s\tremaining: 1m 37s\n",
      "140:\tlearn: 1.9794834\ttotal: 16s\tremaining: 1m 37s\n",
      "141:\tlearn: 1.9789149\ttotal: 16.2s\tremaining: 1m 37s\n",
      "142:\tlearn: 1.9781620\ttotal: 16.3s\tremaining: 1m 37s\n",
      "143:\tlearn: 1.9776751\ttotal: 16.5s\tremaining: 1m 37s\n",
      "144:\tlearn: 1.9772637\ttotal: 16.6s\tremaining: 1m 38s\n",
      "145:\tlearn: 1.9769153\ttotal: 16.8s\tremaining: 1m 38s\n",
      "146:\tlearn: 1.9762141\ttotal: 16.9s\tremaining: 1m 38s\n",
      "147:\tlearn: 1.9758785\ttotal: 17s\tremaining: 1m 38s\n",
      "148:\tlearn: 1.9750905\ttotal: 17.2s\tremaining: 1m 37s\n",
      "149:\tlearn: 1.9744458\ttotal: 17.3s\tremaining: 1m 38s\n",
      "150:\tlearn: 1.9739092\ttotal: 17.5s\tremaining: 1m 38s\n",
      "151:\tlearn: 1.9731091\ttotal: 17.6s\tremaining: 1m 38s\n",
      "152:\tlearn: 1.9727344\ttotal: 17.7s\tremaining: 1m 37s\n",
      "153:\tlearn: 1.9721585\ttotal: 17.8s\tremaining: 1m 37s\n",
      "154:\tlearn: 1.9715675\ttotal: 18s\tremaining: 1m 38s\n",
      "155:\tlearn: 1.9708627\ttotal: 18.1s\tremaining: 1m 38s\n",
      "156:\tlearn: 1.9701075\ttotal: 18.3s\tremaining: 1m 38s\n",
      "157:\tlearn: 1.9697201\ttotal: 18.4s\tremaining: 1m 37s\n",
      "158:\tlearn: 1.9687783\ttotal: 18.5s\tremaining: 1m 37s\n",
      "159:\tlearn: 1.9678565\ttotal: 18.7s\tremaining: 1m 38s\n",
      "160:\tlearn: 1.9674857\ttotal: 18.8s\tremaining: 1m 38s\n",
      "161:\tlearn: 1.9665470\ttotal: 19s\tremaining: 1m 38s\n",
      "162:\tlearn: 1.9648552\ttotal: 19.1s\tremaining: 1m 38s\n",
      "163:\tlearn: 1.9643720\ttotal: 19.2s\tremaining: 1m 37s\n",
      "164:\tlearn: 1.9635427\ttotal: 19.4s\tremaining: 1m 38s\n",
      "165:\tlearn: 1.9631277\ttotal: 19.5s\tremaining: 1m 38s\n",
      "166:\tlearn: 1.9621183\ttotal: 19.6s\tremaining: 1m 37s\n",
      "167:\tlearn: 1.9598231\ttotal: 19.8s\tremaining: 1m 37s\n",
      "168:\tlearn: 1.9594081\ttotal: 19.9s\tremaining: 1m 37s\n",
      "169:\tlearn: 1.9588715\ttotal: 20s\tremaining: 1m 37s\n",
      "170:\tlearn: 1.9580568\ttotal: 20.2s\tremaining: 1m 37s\n",
      "171:\tlearn: 1.9572897\ttotal: 20.3s\tremaining: 1m 37s\n",
      "172:\tlearn: 1.9547227\ttotal: 20.4s\tremaining: 1m 37s\n",
      "173:\tlearn: 1.9539256\ttotal: 20.5s\tremaining: 1m 37s\n",
      "174:\tlearn: 1.9530782\ttotal: 20.7s\tremaining: 1m 37s\n",
      "175:\tlearn: 1.9523544\ttotal: 20.8s\tremaining: 1m 37s\n",
      "176:\tlearn: 1.9512888\ttotal: 20.9s\tremaining: 1m 37s\n",
      "177:\tlearn: 1.9508338\ttotal: 21s\tremaining: 1m 37s\n",
      "178:\tlearn: 1.9489893\ttotal: 21.2s\tremaining: 1m 37s\n",
      "179:\tlearn: 1.9481174\ttotal: 21.3s\tremaining: 1m 36s\n",
      "180:\tlearn: 1.9474231\ttotal: 21.4s\tremaining: 1m 36s\n",
      "181:\tlearn: 1.9455097\ttotal: 21.5s\tremaining: 1m 36s\n",
      "182:\tlearn: 1.9447602\ttotal: 21.6s\tremaining: 1m 36s\n",
      "183:\tlearn: 1.9443760\ttotal: 21.8s\tremaining: 1m 36s\n",
      "184:\tlearn: 1.9436321\ttotal: 21.9s\tremaining: 1m 36s\n",
      "185:\tlearn: 1.9431989\ttotal: 22s\tremaining: 1m 36s\n",
      "186:\tlearn: 1.9424244\ttotal: 22.1s\tremaining: 1m 35s\n",
      "187:\tlearn: 1.9409860\ttotal: 22.2s\tremaining: 1m 35s\n",
      "188:\tlearn: 1.9388424\ttotal: 22.3s\tremaining: 1m 35s\n",
      "189:\tlearn: 1.9380264\ttotal: 22.4s\tremaining: 1m 35s\n",
      "190:\tlearn: 1.9372757\ttotal: 22.5s\tremaining: 1m 35s\n",
      "191:\tlearn: 1.9342996\ttotal: 22.6s\tremaining: 1m 35s\n",
      "192:\tlearn: 1.9339225\ttotal: 22.7s\tremaining: 1m 35s\n",
      "193:\tlearn: 1.9326664\ttotal: 22.8s\tremaining: 1m 34s\n",
      "194:\tlearn: 1.9318570\ttotal: 23s\tremaining: 1m 34s\n",
      "195:\tlearn: 1.9310847\ttotal: 23.1s\tremaining: 1m 34s\n",
      "196:\tlearn: 1.9296649\ttotal: 23.2s\tremaining: 1m 34s\n",
      "197:\tlearn: 1.9281537\ttotal: 23.3s\tremaining: 1m 34s\n",
      "198:\tlearn: 1.9274782\ttotal: 23.4s\tremaining: 1m 34s\n",
      "199:\tlearn: 1.9268411\ttotal: 23.5s\tremaining: 1m 34s\n",
      "200:\tlearn: 1.9251754\ttotal: 23.7s\tremaining: 1m 34s\n",
      "201:\tlearn: 1.9240384\ttotal: 23.8s\tremaining: 1m 33s\n",
      "202:\tlearn: 1.9220292\ttotal: 23.9s\tremaining: 1m 33s\n",
      "203:\tlearn: 1.9199086\ttotal: 24s\tremaining: 1m 33s\n",
      "204:\tlearn: 1.9192417\ttotal: 24.1s\tremaining: 1m 33s\n",
      "205:\tlearn: 1.9185606\ttotal: 24.2s\tremaining: 1m 33s\n",
      "206:\tlearn: 1.9168101\ttotal: 24.3s\tremaining: 1m 33s\n",
      "207:\tlearn: 1.9164085\ttotal: 24.4s\tremaining: 1m 32s\n",
      "208:\tlearn: 1.9139380\ttotal: 24.5s\tremaining: 1m 32s\n",
      "209:\tlearn: 1.9128667\ttotal: 24.6s\tremaining: 1m 32s\n",
      "210:\tlearn: 1.9124835\ttotal: 24.8s\tremaining: 1m 32s\n",
      "211:\tlearn: 1.9118567\ttotal: 24.9s\tremaining: 1m 32s\n",
      "212:\tlearn: 1.9113524\ttotal: 25s\tremaining: 1m 32s\n",
      "213:\tlearn: 1.9093007\ttotal: 25.1s\tremaining: 1m 32s\n",
      "214:\tlearn: 1.9078827\ttotal: 25.2s\tremaining: 1m 31s\n",
      "215:\tlearn: 1.9061587\ttotal: 25.3s\tremaining: 1m 31s\n",
      "216:\tlearn: 1.9051328\ttotal: 25.4s\tremaining: 1m 31s\n",
      "217:\tlearn: 1.9043964\ttotal: 25.5s\tremaining: 1m 31s\n",
      "218:\tlearn: 1.9040117\ttotal: 25.6s\tremaining: 1m 31s\n",
      "219:\tlearn: 1.9022853\ttotal: 25.7s\tremaining: 1m 31s\n",
      "220:\tlearn: 1.9005931\ttotal: 25.8s\tremaining: 1m 31s\n",
      "221:\tlearn: 1.8989175\ttotal: 26s\tremaining: 1m 30s\n",
      "222:\tlearn: 1.8984173\ttotal: 26.1s\tremaining: 1m 30s\n",
      "223:\tlearn: 1.8971566\ttotal: 26.2s\tremaining: 1m 30s\n",
      "224:\tlearn: 1.8966027\ttotal: 26.3s\tremaining: 1m 30s\n",
      "225:\tlearn: 1.8950839\ttotal: 26.4s\tremaining: 1m 30s\n",
      "226:\tlearn: 1.8945484\ttotal: 26.5s\tremaining: 1m 30s\n",
      "227:\tlearn: 1.8929824\ttotal: 26.6s\tremaining: 1m 30s\n",
      "228:\tlearn: 1.8922050\ttotal: 26.7s\tremaining: 1m 30s\n",
      "229:\tlearn: 1.8901781\ttotal: 26.9s\tremaining: 1m 29s\n",
      "230:\tlearn: 1.8892833\ttotal: 27s\tremaining: 1m 29s\n",
      "231:\tlearn: 1.8885467\ttotal: 27.1s\tremaining: 1m 29s\n",
      "232:\tlearn: 1.8865436\ttotal: 27.2s\tremaining: 1m 29s\n",
      "233:\tlearn: 1.8860075\ttotal: 27.3s\tremaining: 1m 29s\n",
      "234:\tlearn: 1.8853139\ttotal: 27.4s\tremaining: 1m 29s\n",
      "235:\tlearn: 1.8849405\ttotal: 27.5s\tremaining: 1m 29s\n",
      "236:\tlearn: 1.8835770\ttotal: 27.6s\tremaining: 1m 28s\n",
      "237:\tlearn: 1.8832330\ttotal: 27.7s\tremaining: 1m 28s\n",
      "238:\tlearn: 1.8820550\ttotal: 27.8s\tremaining: 1m 28s\n",
      "239:\tlearn: 1.8807953\ttotal: 28s\tremaining: 1m 28s\n",
      "240:\tlearn: 1.8792168\ttotal: 28.1s\tremaining: 1m 28s\n",
      "241:\tlearn: 1.8785469\ttotal: 28.2s\tremaining: 1m 28s\n",
      "242:\tlearn: 1.8770614\ttotal: 28.3s\tremaining: 1m 28s\n",
      "243:\tlearn: 1.8757562\ttotal: 28.4s\tremaining: 1m 28s\n",
      "244:\tlearn: 1.8744479\ttotal: 28.5s\tremaining: 1m 27s\n",
      "245:\tlearn: 1.8732724\ttotal: 28.6s\tremaining: 1m 27s\n",
      "246:\tlearn: 1.8721494\ttotal: 28.8s\tremaining: 1m 27s\n",
      "247:\tlearn: 1.8712502\ttotal: 28.9s\tremaining: 1m 27s\n",
      "248:\tlearn: 1.8702023\ttotal: 29s\tremaining: 1m 27s\n",
      "249:\tlearn: 1.8684900\ttotal: 29.1s\tremaining: 1m 27s\n",
      "250:\tlearn: 1.8681434\ttotal: 29.2s\tremaining: 1m 27s\n",
      "251:\tlearn: 1.8673211\ttotal: 29.3s\tremaining: 1m 26s\n",
      "252:\tlearn: 1.8667634\ttotal: 29.4s\tremaining: 1m 26s\n",
      "253:\tlearn: 1.8653853\ttotal: 29.5s\tremaining: 1m 26s\n",
      "254:\tlearn: 1.8650435\ttotal: 29.6s\tremaining: 1m 26s\n",
      "255:\tlearn: 1.8645468\ttotal: 29.7s\tremaining: 1m 26s\n",
      "256:\tlearn: 1.8627527\ttotal: 29.8s\tremaining: 1m 26s\n",
      "257:\tlearn: 1.8621449\ttotal: 30s\tremaining: 1m 26s\n",
      "258:\tlearn: 1.8616516\ttotal: 30.1s\tremaining: 1m 26s\n",
      "259:\tlearn: 1.8608121\ttotal: 30.2s\tremaining: 1m 25s\n",
      "260:\tlearn: 1.8603191\ttotal: 30.3s\tremaining: 1m 25s\n",
      "261:\tlearn: 1.8598344\ttotal: 30.4s\tremaining: 1m 25s\n",
      "262:\tlearn: 1.8595071\ttotal: 30.5s\tremaining: 1m 25s\n",
      "263:\tlearn: 1.8589013\ttotal: 30.6s\tremaining: 1m 25s\n",
      "264:\tlearn: 1.8584529\ttotal: 30.7s\tremaining: 1m 25s\n",
      "265:\tlearn: 1.8579307\ttotal: 30.8s\tremaining: 1m 25s\n",
      "266:\tlearn: 1.8574556\ttotal: 30.9s\tremaining: 1m 24s\n",
      "267:\tlearn: 1.8563237\ttotal: 31s\tremaining: 1m 24s\n",
      "268:\tlearn: 1.8556385\ttotal: 31.2s\tremaining: 1m 24s\n",
      "269:\tlearn: 1.8550443\ttotal: 31.3s\tremaining: 1m 24s\n",
      "270:\tlearn: 1.8531702\ttotal: 31.4s\tremaining: 1m 24s\n",
      "271:\tlearn: 1.8528605\ttotal: 31.5s\tremaining: 1m 24s\n",
      "272:\tlearn: 1.8518285\ttotal: 31.6s\tremaining: 1m 24s\n",
      "273:\tlearn: 1.8502970\ttotal: 31.7s\tremaining: 1m 24s\n",
      "274:\tlearn: 1.8488109\ttotal: 31.8s\tremaining: 1m 23s\n",
      "275:\tlearn: 1.8479755\ttotal: 31.9s\tremaining: 1m 23s\n",
      "276:\tlearn: 1.8474961\ttotal: 32s\tremaining: 1m 23s\n",
      "277:\tlearn: 1.8455602\ttotal: 32.2s\tremaining: 1m 23s\n",
      "278:\tlearn: 1.8450399\ttotal: 32.3s\tremaining: 1m 23s\n",
      "279:\tlearn: 1.8443713\ttotal: 32.4s\tremaining: 1m 23s\n",
      "280:\tlearn: 1.8428496\ttotal: 32.5s\tremaining: 1m 23s\n",
      "281:\tlearn: 1.8425444\ttotal: 32.6s\tremaining: 1m 23s\n",
      "282:\tlearn: 1.8420743\ttotal: 32.7s\tremaining: 1m 22s\n",
      "283:\tlearn: 1.8415936\ttotal: 32.8s\tremaining: 1m 22s\n",
      "284:\tlearn: 1.8411567\ttotal: 32.9s\tremaining: 1m 22s\n",
      "285:\tlearn: 1.8397405\ttotal: 33.1s\tremaining: 1m 22s\n",
      "286:\tlearn: 1.8382260\ttotal: 33.2s\tremaining: 1m 22s\n",
      "287:\tlearn: 1.8377589\ttotal: 33.3s\tremaining: 1m 22s\n",
      "288:\tlearn: 1.8364823\ttotal: 33.4s\tremaining: 1m 22s\n",
      "289:\tlearn: 1.8353998\ttotal: 33.5s\tremaining: 1m 22s\n",
      "290:\tlearn: 1.8349145\ttotal: 33.6s\tremaining: 1m 21s\n",
      "291:\tlearn: 1.8338102\ttotal: 33.7s\tremaining: 1m 21s\n",
      "292:\tlearn: 1.8334778\ttotal: 33.8s\tremaining: 1m 21s\n",
      "293:\tlearn: 1.8320386\ttotal: 34s\tremaining: 1m 21s\n",
      "294:\tlearn: 1.8304004\ttotal: 34.1s\tremaining: 1m 21s\n",
      "295:\tlearn: 1.8299741\ttotal: 34.2s\tremaining: 1m 21s\n",
      "296:\tlearn: 1.8294860\ttotal: 34.3s\tremaining: 1m 21s\n",
      "297:\tlearn: 1.8288412\ttotal: 34.4s\tremaining: 1m 21s\n",
      "298:\tlearn: 1.8282048\ttotal: 34.5s\tremaining: 1m 20s\n",
      "299:\tlearn: 1.8265306\ttotal: 34.6s\tremaining: 1m 20s\n",
      "300:\tlearn: 1.8260751\ttotal: 34.8s\tremaining: 1m 20s\n",
      "301:\tlearn: 1.8257868\ttotal: 34.9s\tremaining: 1m 20s\n",
      "302:\tlearn: 1.8241794\ttotal: 35s\tremaining: 1m 20s\n",
      "303:\tlearn: 1.8233945\ttotal: 35.1s\tremaining: 1m 20s\n",
      "304:\tlearn: 1.8219690\ttotal: 35.2s\tremaining: 1m 20s\n",
      "305:\tlearn: 1.8204231\ttotal: 35.3s\tremaining: 1m 20s\n",
      "306:\tlearn: 1.8192145\ttotal: 35.4s\tremaining: 1m 19s\n",
      "307:\tlearn: 1.8185509\ttotal: 35.5s\tremaining: 1m 19s\n",
      "308:\tlearn: 1.8182334\ttotal: 35.6s\tremaining: 1m 19s\n",
      "309:\tlearn: 1.8166743\ttotal: 35.7s\tremaining: 1m 19s\n",
      "310:\tlearn: 1.8162569\ttotal: 35.9s\tremaining: 1m 19s\n",
      "311:\tlearn: 1.8156085\ttotal: 36s\tremaining: 1m 19s\n",
      "312:\tlearn: 1.8144761\ttotal: 36.1s\tremaining: 1m 19s\n",
      "313:\tlearn: 1.8141794\ttotal: 36.2s\tremaining: 1m 19s\n",
      "314:\tlearn: 1.8138783\ttotal: 36.3s\tremaining: 1m 18s\n",
      "315:\tlearn: 1.8126952\ttotal: 36.4s\tremaining: 1m 18s\n",
      "316:\tlearn: 1.8115799\ttotal: 36.5s\tremaining: 1m 18s\n",
      "317:\tlearn: 1.8108008\ttotal: 36.6s\tremaining: 1m 18s\n",
      "318:\tlearn: 1.8100602\ttotal: 36.7s\tremaining: 1m 18s\n",
      "319:\tlearn: 1.8096553\ttotal: 36.8s\tremaining: 1m 18s\n",
      "320:\tlearn: 1.8088726\ttotal: 36.9s\tremaining: 1m 18s\n",
      "321:\tlearn: 1.8078614\ttotal: 37.1s\tremaining: 1m 18s\n",
      "322:\tlearn: 1.8068862\ttotal: 37.2s\tremaining: 1m 17s\n",
      "323:\tlearn: 1.8065873\ttotal: 37.3s\tremaining: 1m 17s\n",
      "324:\tlearn: 1.8060109\ttotal: 37.4s\tremaining: 1m 17s\n",
      "325:\tlearn: 1.8057223\ttotal: 37.5s\tremaining: 1m 17s\n",
      "326:\tlearn: 1.8037846\ttotal: 37.6s\tremaining: 1m 17s\n",
      "327:\tlearn: 1.8030537\ttotal: 37.7s\tremaining: 1m 17s\n",
      "328:\tlearn: 1.8019118\ttotal: 37.8s\tremaining: 1m 17s\n",
      "329:\tlearn: 1.8004077\ttotal: 37.9s\tremaining: 1m 17s\n",
      "330:\tlearn: 1.7994818\ttotal: 38s\tremaining: 1m 16s\n",
      "331:\tlearn: 1.7988783\ttotal: 38.2s\tremaining: 1m 16s\n",
      "332:\tlearn: 1.7974816\ttotal: 38.3s\tremaining: 1m 16s\n",
      "333:\tlearn: 1.7964076\ttotal: 38.4s\tremaining: 1m 16s\n",
      "334:\tlearn: 1.7953412\ttotal: 38.5s\tremaining: 1m 16s\n",
      "335:\tlearn: 1.7941965\ttotal: 38.6s\tremaining: 1m 16s\n",
      "336:\tlearn: 1.7936171\ttotal: 38.7s\tremaining: 1m 16s\n",
      "337:\tlearn: 1.7931635\ttotal: 38.8s\tremaining: 1m 16s\n",
      "338:\tlearn: 1.7928773\ttotal: 38.9s\tremaining: 1m 15s\n",
      "339:\tlearn: 1.7926047\ttotal: 39s\tremaining: 1m 15s\n",
      "340:\tlearn: 1.7922164\ttotal: 39.2s\tremaining: 1m 15s\n",
      "341:\tlearn: 1.7918293\ttotal: 39.3s\tremaining: 1m 15s\n",
      "342:\tlearn: 1.7907500\ttotal: 39.4s\tremaining: 1m 15s\n",
      "343:\tlearn: 1.7902115\ttotal: 39.5s\tremaining: 1m 15s\n",
      "344:\tlearn: 1.7890485\ttotal: 39.6s\tremaining: 1m 15s\n",
      "345:\tlearn: 1.7877218\ttotal: 39.7s\tremaining: 1m 15s\n",
      "346:\tlearn: 1.7871266\ttotal: 39.8s\tremaining: 1m 14s\n",
      "347:\tlearn: 1.7868493\ttotal: 39.9s\tremaining: 1m 14s\n",
      "348:\tlearn: 1.7860117\ttotal: 40s\tremaining: 1m 14s\n",
      "349:\tlearn: 1.7847176\ttotal: 40.2s\tremaining: 1m 14s\n",
      "350:\tlearn: 1.7836955\ttotal: 40.3s\tremaining: 1m 14s\n",
      "351:\tlearn: 1.7832068\ttotal: 40.4s\tremaining: 1m 14s\n",
      "352:\tlearn: 1.7828025\ttotal: 40.5s\tremaining: 1m 14s\n",
      "353:\tlearn: 1.7821812\ttotal: 40.6s\tremaining: 1m 14s\n",
      "354:\tlearn: 1.7814594\ttotal: 40.7s\tremaining: 1m 14s\n",
      "355:\tlearn: 1.7805236\ttotal: 40.9s\tremaining: 1m 13s\n",
      "356:\tlearn: 1.7795082\ttotal: 41s\tremaining: 1m 13s\n",
      "357:\tlearn: 1.7789617\ttotal: 41.1s\tremaining: 1m 13s\n",
      "358:\tlearn: 1.7781143\ttotal: 41.2s\tremaining: 1m 13s\n",
      "359:\tlearn: 1.7775518\ttotal: 41.3s\tremaining: 1m 13s\n",
      "360:\tlearn: 1.7767285\ttotal: 41.5s\tremaining: 1m 13s\n",
      "361:\tlearn: 1.7756953\ttotal: 41.6s\tremaining: 1m 13s\n",
      "362:\tlearn: 1.7750390\ttotal: 41.7s\tremaining: 1m 13s\n",
      "363:\tlearn: 1.7737592\ttotal: 41.8s\tremaining: 1m 13s\n",
      "364:\tlearn: 1.7731842\ttotal: 41.9s\tremaining: 1m 12s\n",
      "365:\tlearn: 1.7729038\ttotal: 42s\tremaining: 1m 12s\n",
      "366:\tlearn: 1.7726396\ttotal: 42.1s\tremaining: 1m 12s\n",
      "367:\tlearn: 1.7712348\ttotal: 42.2s\tremaining: 1m 12s\n",
      "368:\tlearn: 1.7708364\ttotal: 42.3s\tremaining: 1m 12s\n",
      "369:\tlearn: 1.7705699\ttotal: 42.4s\tremaining: 1m 12s\n",
      "370:\tlearn: 1.7701463\ttotal: 42.6s\tremaining: 1m 12s\n",
      "371:\tlearn: 1.7695818\ttotal: 42.7s\tremaining: 1m 12s\n",
      "372:\tlearn: 1.7689681\ttotal: 42.8s\tremaining: 1m 11s\n",
      "373:\tlearn: 1.7683202\ttotal: 42.9s\tremaining: 1m 11s\n",
      "374:\tlearn: 1.7679091\ttotal: 43s\tremaining: 1m 11s\n",
      "375:\tlearn: 1.7669374\ttotal: 43.1s\tremaining: 1m 11s\n",
      "376:\tlearn: 1.7658968\ttotal: 43.2s\tremaining: 1m 11s\n",
      "377:\tlearn: 1.7649676\ttotal: 43.3s\tremaining: 1m 11s\n",
      "378:\tlearn: 1.7638453\ttotal: 43.4s\tremaining: 1m 11s\n",
      "379:\tlearn: 1.7625620\ttotal: 43.6s\tremaining: 1m 11s\n",
      "380:\tlearn: 1.7621100\ttotal: 43.7s\tremaining: 1m 10s\n",
      "381:\tlearn: 1.7611483\ttotal: 43.8s\tremaining: 1m 10s\n",
      "382:\tlearn: 1.7600566\ttotal: 44s\tremaining: 1m 10s\n",
      "383:\tlearn: 1.7588992\ttotal: 44.1s\tremaining: 1m 10s\n",
      "384:\tlearn: 1.7584901\ttotal: 44.2s\tremaining: 1m 10s\n",
      "385:\tlearn: 1.7577626\ttotal: 44.3s\tremaining: 1m 10s\n",
      "386:\tlearn: 1.7575001\ttotal: 44.4s\tremaining: 1m 10s\n",
      "387:\tlearn: 1.7571151\ttotal: 44.6s\tremaining: 1m 10s\n",
      "388:\tlearn: 1.7559668\ttotal: 44.7s\tremaining: 1m 10s\n",
      "389:\tlearn: 1.7557099\ttotal: 44.8s\tremaining: 1m 10s\n",
      "390:\tlearn: 1.7553385\ttotal: 44.9s\tremaining: 1m 9s\n",
      "391:\tlearn: 1.7548183\ttotal: 45s\tremaining: 1m 9s\n",
      "392:\tlearn: 1.7543648\ttotal: 45.2s\tremaining: 1m 9s\n",
      "393:\tlearn: 1.7531299\ttotal: 45.3s\tremaining: 1m 9s\n",
      "394:\tlearn: 1.7528769\ttotal: 45.5s\tremaining: 1m 9s\n",
      "395:\tlearn: 1.7526151\ttotal: 45.6s\tremaining: 1m 9s\n",
      "396:\tlearn: 1.7520348\ttotal: 45.7s\tremaining: 1m 9s\n",
      "397:\tlearn: 1.7513709\ttotal: 45.9s\tremaining: 1m 9s\n",
      "398:\tlearn: 1.7506154\ttotal: 46s\tremaining: 1m 9s\n",
      "399:\tlearn: 1.7502626\ttotal: 46.1s\tremaining: 1m 9s\n",
      "400:\tlearn: 1.7498460\ttotal: 46.3s\tremaining: 1m 9s\n",
      "401:\tlearn: 1.7494608\ttotal: 46.4s\tremaining: 1m 8s\n",
      "402:\tlearn: 1.7484807\ttotal: 46.5s\tremaining: 1m 8s\n",
      "403:\tlearn: 1.7474196\ttotal: 46.6s\tremaining: 1m 8s\n",
      "404:\tlearn: 1.7470944\ttotal: 46.7s\tremaining: 1m 8s\n",
      "405:\tlearn: 1.7464903\ttotal: 46.9s\tremaining: 1m 8s\n",
      "406:\tlearn: 1.7460988\ttotal: 47s\tremaining: 1m 8s\n",
      "407:\tlearn: 1.7454467\ttotal: 47.1s\tremaining: 1m 8s\n",
      "408:\tlearn: 1.7450410\ttotal: 47.3s\tremaining: 1m 8s\n",
      "409:\tlearn: 1.7447952\ttotal: 47.4s\tremaining: 1m 8s\n",
      "410:\tlearn: 1.7434667\ttotal: 47.6s\tremaining: 1m 8s\n",
      "411:\tlearn: 1.7431109\ttotal: 47.7s\tremaining: 1m 8s\n",
      "412:\tlearn: 1.7419011\ttotal: 47.8s\tremaining: 1m 7s\n",
      "413:\tlearn: 1.7414749\ttotal: 47.9s\tremaining: 1m 7s\n",
      "414:\tlearn: 1.7411422\ttotal: 48s\tremaining: 1m 7s\n",
      "415:\tlearn: 1.7403815\ttotal: 48.1s\tremaining: 1m 7s\n",
      "416:\tlearn: 1.7394981\ttotal: 48.2s\tremaining: 1m 7s\n",
      "417:\tlearn: 1.7384147\ttotal: 48.3s\tremaining: 1m 7s\n",
      "418:\tlearn: 1.7378819\ttotal: 48.4s\tremaining: 1m 7s\n",
      "419:\tlearn: 1.7370133\ttotal: 48.5s\tremaining: 1m 7s\n",
      "420:\tlearn: 1.7358488\ttotal: 48.6s\tremaining: 1m 6s\n",
      "421:\tlearn: 1.7354706\ttotal: 48.8s\tremaining: 1m 6s\n",
      "422:\tlearn: 1.7352128\ttotal: 48.9s\tremaining: 1m 6s\n",
      "423:\tlearn: 1.7345565\ttotal: 49s\tremaining: 1m 6s\n",
      "424:\tlearn: 1.7336790\ttotal: 49.2s\tremaining: 1m 6s\n",
      "425:\tlearn: 1.7332976\ttotal: 49.3s\tremaining: 1m 6s\n",
      "426:\tlearn: 1.7321172\ttotal: 49.5s\tremaining: 1m 6s\n",
      "427:\tlearn: 1.7317500\ttotal: 49.6s\tremaining: 1m 6s\n",
      "428:\tlearn: 1.7305019\ttotal: 49.7s\tremaining: 1m 6s\n",
      "429:\tlearn: 1.7302874\ttotal: 49.8s\tremaining: 1m 6s\n",
      "430:\tlearn: 1.7296208\ttotal: 49.9s\tremaining: 1m 5s\n",
      "431:\tlearn: 1.7291804\ttotal: 50s\tremaining: 1m 5s\n",
      "432:\tlearn: 1.7288109\ttotal: 50.2s\tremaining: 1m 5s\n",
      "433:\tlearn: 1.7276738\ttotal: 50.3s\tremaining: 1m 5s\n",
      "434:\tlearn: 1.7262965\ttotal: 50.4s\tremaining: 1m 5s\n",
      "435:\tlearn: 1.7257532\ttotal: 50.5s\tremaining: 1m 5s\n",
      "436:\tlearn: 1.7245663\ttotal: 50.6s\tremaining: 1m 5s\n",
      "437:\tlearn: 1.7234541\ttotal: 50.7s\tremaining: 1m 5s\n",
      "438:\tlearn: 1.7229682\ttotal: 50.8s\tremaining: 1m 4s\n",
      "439:\tlearn: 1.7222217\ttotal: 50.9s\tremaining: 1m 4s\n",
      "440:\tlearn: 1.7214974\ttotal: 51s\tremaining: 1m 4s\n",
      "441:\tlearn: 1.7211844\ttotal: 51.2s\tremaining: 1m 4s\n",
      "442:\tlearn: 1.7208390\ttotal: 51.3s\tremaining: 1m 4s\n",
      "443:\tlearn: 1.7204783\ttotal: 51.4s\tremaining: 1m 4s\n",
      "444:\tlearn: 1.7201188\ttotal: 51.5s\tremaining: 1m 4s\n",
      "445:\tlearn: 1.7194030\ttotal: 51.6s\tremaining: 1m 4s\n",
      "446:\tlearn: 1.7191540\ttotal: 51.7s\tremaining: 1m 3s\n",
      "447:\tlearn: 1.7189225\ttotal: 51.8s\tremaining: 1m 3s\n",
      "448:\tlearn: 1.7185832\ttotal: 51.9s\tremaining: 1m 3s\n",
      "449:\tlearn: 1.7176474\ttotal: 52s\tremaining: 1m 3s\n",
      "450:\tlearn: 1.7171010\ttotal: 52.1s\tremaining: 1m 3s\n",
      "451:\tlearn: 1.7164145\ttotal: 52.3s\tremaining: 1m 3s\n",
      "452:\tlearn: 1.7155583\ttotal: 52.4s\tremaining: 1m 3s\n",
      "453:\tlearn: 1.7150322\ttotal: 52.5s\tremaining: 1m 3s\n",
      "454:\tlearn: 1.7144914\ttotal: 52.6s\tremaining: 1m 2s\n",
      "455:\tlearn: 1.7135998\ttotal: 52.7s\tremaining: 1m 2s\n",
      "456:\tlearn: 1.7126992\ttotal: 52.8s\tremaining: 1m 2s\n",
      "457:\tlearn: 1.7117381\ttotal: 52.9s\tremaining: 1m 2s\n",
      "458:\tlearn: 1.7112882\ttotal: 53s\tremaining: 1m 2s\n",
      "459:\tlearn: 1.7098154\ttotal: 53.1s\tremaining: 1m 2s\n",
      "460:\tlearn: 1.7089656\ttotal: 53.3s\tremaining: 1m 2s\n",
      "461:\tlearn: 1.7084337\ttotal: 53.4s\tremaining: 1m 2s\n",
      "462:\tlearn: 1.7076701\ttotal: 53.5s\tremaining: 1m 2s\n",
      "463:\tlearn: 1.7069490\ttotal: 53.6s\tremaining: 1m 1s\n",
      "464:\tlearn: 1.7059489\ttotal: 53.7s\tremaining: 1m 1s\n",
      "465:\tlearn: 1.7056481\ttotal: 53.8s\tremaining: 1m 1s\n",
      "466:\tlearn: 1.7052733\ttotal: 53.9s\tremaining: 1m 1s\n",
      "467:\tlearn: 1.7046318\ttotal: 54s\tremaining: 1m 1s\n",
      "468:\tlearn: 1.7042380\ttotal: 54.1s\tremaining: 1m 1s\n",
      "469:\tlearn: 1.7029857\ttotal: 54.3s\tremaining: 1m 1s\n",
      "470:\tlearn: 1.7021447\ttotal: 54.4s\tremaining: 1m 1s\n",
      "471:\tlearn: 1.7019159\ttotal: 54.5s\tremaining: 1m\n",
      "472:\tlearn: 1.7010426\ttotal: 54.6s\tremaining: 1m\n",
      "473:\tlearn: 1.6998648\ttotal: 54.7s\tremaining: 1m\n",
      "474:\tlearn: 1.6991753\ttotal: 54.8s\tremaining: 1m\n",
      "475:\tlearn: 1.6989510\ttotal: 54.9s\tremaining: 1m\n",
      "476:\tlearn: 1.6986611\ttotal: 55s\tremaining: 1m\n",
      "477:\tlearn: 1.6975417\ttotal: 55.1s\tremaining: 1m\n",
      "478:\tlearn: 1.6962492\ttotal: 55.2s\tremaining: 1m\n",
      "479:\tlearn: 1.6951910\ttotal: 55.4s\tremaining: 60s\n",
      "480:\tlearn: 1.6947521\ttotal: 55.5s\tremaining: 59.9s\n",
      "481:\tlearn: 1.6942896\ttotal: 55.6s\tremaining: 59.7s\n",
      "482:\tlearn: 1.6933629\ttotal: 55.7s\tremaining: 59.6s\n",
      "483:\tlearn: 1.6924068\ttotal: 55.8s\tremaining: 59.5s\n",
      "484:\tlearn: 1.6915464\ttotal: 55.9s\tremaining: 59.4s\n",
      "485:\tlearn: 1.6904018\ttotal: 56.1s\tremaining: 59.3s\n",
      "486:\tlearn: 1.6896488\ttotal: 56.2s\tremaining: 59.2s\n",
      "487:\tlearn: 1.6885260\ttotal: 56.3s\tremaining: 59s\n",
      "488:\tlearn: 1.6882768\ttotal: 56.4s\tremaining: 58.9s\n",
      "489:\tlearn: 1.6880444\ttotal: 56.5s\tremaining: 58.8s\n",
      "490:\tlearn: 1.6875524\ttotal: 56.6s\tremaining: 58.7s\n",
      "491:\tlearn: 1.6872011\ttotal: 56.7s\tremaining: 58.6s\n",
      "492:\tlearn: 1.6868107\ttotal: 56.8s\tremaining: 58.4s\n",
      "493:\tlearn: 1.6864246\ttotal: 56.9s\tremaining: 58.3s\n",
      "494:\tlearn: 1.6855769\ttotal: 57s\tremaining: 58.2s\n",
      "495:\tlearn: 1.6843284\ttotal: 57.1s\tremaining: 58.1s\n",
      "496:\tlearn: 1.6839216\ttotal: 57.3s\tremaining: 58s\n",
      "497:\tlearn: 1.6830329\ttotal: 57.4s\tremaining: 57.9s\n",
      "498:\tlearn: 1.6825201\ttotal: 57.5s\tremaining: 57.7s\n",
      "499:\tlearn: 1.6816991\ttotal: 57.6s\tremaining: 57.6s\n",
      "500:\tlearn: 1.6805614\ttotal: 57.8s\tremaining: 57.6s\n",
      "501:\tlearn: 1.6802324\ttotal: 57.9s\tremaining: 57.4s\n",
      "502:\tlearn: 1.6800216\ttotal: 58s\tremaining: 57.3s\n",
      "503:\tlearn: 1.6796113\ttotal: 58.1s\tremaining: 57.2s\n",
      "504:\tlearn: 1.6793251\ttotal: 58.3s\tremaining: 57.1s\n",
      "505:\tlearn: 1.6789787\ttotal: 58.4s\tremaining: 57s\n",
      "506:\tlearn: 1.6783400\ttotal: 58.6s\tremaining: 56.9s\n",
      "507:\tlearn: 1.6779271\ttotal: 58.7s\tremaining: 56.9s\n",
      "508:\tlearn: 1.6767468\ttotal: 58.8s\tremaining: 56.8s\n",
      "509:\tlearn: 1.6755228\ttotal: 59s\tremaining: 56.7s\n",
      "510:\tlearn: 1.6752353\ttotal: 59.1s\tremaining: 56.6s\n",
      "511:\tlearn: 1.6750066\ttotal: 59.2s\tremaining: 56.5s\n",
      "512:\tlearn: 1.6743383\ttotal: 59.4s\tremaining: 56.4s\n",
      "513:\tlearn: 1.6739067\ttotal: 59.5s\tremaining: 56.2s\n",
      "514:\tlearn: 1.6734313\ttotal: 59.6s\tremaining: 56.1s\n",
      "515:\tlearn: 1.6723371\ttotal: 59.7s\tremaining: 56s\n",
      "516:\tlearn: 1.6714679\ttotal: 59.9s\tremaining: 55.9s\n",
      "517:\tlearn: 1.6704482\ttotal: 60s\tremaining: 55.8s\n",
      "518:\tlearn: 1.6695426\ttotal: 1m\tremaining: 55.7s\n",
      "519:\tlearn: 1.6684091\ttotal: 1m\tremaining: 55.6s\n",
      "520:\tlearn: 1.6679469\ttotal: 1m\tremaining: 55.5s\n",
      "521:\tlearn: 1.6668000\ttotal: 1m\tremaining: 55.4s\n",
      "522:\tlearn: 1.6656925\ttotal: 1m\tremaining: 55.3s\n",
      "523:\tlearn: 1.6652716\ttotal: 1m\tremaining: 55.2s\n",
      "524:\tlearn: 1.6644362\ttotal: 1m\tremaining: 55.1s\n",
      "525:\tlearn: 1.6638342\ttotal: 1m\tremaining: 54.9s\n",
      "526:\tlearn: 1.6629635\ttotal: 1m 1s\tremaining: 54.8s\n",
      "527:\tlearn: 1.6626232\ttotal: 1m 1s\tremaining: 54.7s\n",
      "528:\tlearn: 1.6619628\ttotal: 1m 1s\tremaining: 54.6s\n",
      "529:\tlearn: 1.6613065\ttotal: 1m 1s\tremaining: 54.4s\n",
      "530:\tlearn: 1.6604834\ttotal: 1m 1s\tremaining: 54.3s\n",
      "531:\tlearn: 1.6594285\ttotal: 1m 1s\tremaining: 54.2s\n",
      "532:\tlearn: 1.6591545\ttotal: 1m 1s\tremaining: 54.1s\n",
      "533:\tlearn: 1.6585440\ttotal: 1m 1s\tremaining: 54s\n",
      "534:\tlearn: 1.6583358\ttotal: 1m 1s\tremaining: 53.9s\n",
      "535:\tlearn: 1.6575063\ttotal: 1m 2s\tremaining: 53.7s\n",
      "536:\tlearn: 1.6569503\ttotal: 1m 2s\tremaining: 53.6s\n",
      "537:\tlearn: 1.6567411\ttotal: 1m 2s\tremaining: 53.5s\n",
      "538:\tlearn: 1.6557036\ttotal: 1m 2s\tremaining: 53.4s\n",
      "539:\tlearn: 1.6551885\ttotal: 1m 2s\tremaining: 53.3s\n",
      "540:\tlearn: 1.6543573\ttotal: 1m 2s\tremaining: 53.1s\n",
      "541:\tlearn: 1.6535915\ttotal: 1m 2s\tremaining: 53s\n",
      "542:\tlearn: 1.6532097\ttotal: 1m 2s\tremaining: 52.9s\n",
      "543:\tlearn: 1.6524929\ttotal: 1m 2s\tremaining: 52.8s\n",
      "544:\tlearn: 1.6522740\ttotal: 1m 3s\tremaining: 52.7s\n",
      "545:\tlearn: 1.6517672\ttotal: 1m 3s\tremaining: 52.6s\n",
      "546:\tlearn: 1.6511368\ttotal: 1m 3s\tremaining: 52.4s\n",
      "547:\tlearn: 1.6502729\ttotal: 1m 3s\tremaining: 52.3s\n",
      "548:\tlearn: 1.6492157\ttotal: 1m 3s\tremaining: 52.2s\n",
      "549:\tlearn: 1.6489990\ttotal: 1m 3s\tremaining: 52.1s\n",
      "550:\tlearn: 1.6481522\ttotal: 1m 3s\tremaining: 52s\n",
      "551:\tlearn: 1.6478296\ttotal: 1m 3s\tremaining: 51.9s\n",
      "552:\tlearn: 1.6470319\ttotal: 1m 4s\tremaining: 51.8s\n",
      "553:\tlearn: 1.6462304\ttotal: 1m 4s\tremaining: 51.7s\n",
      "554:\tlearn: 1.6451152\ttotal: 1m 4s\tremaining: 51.6s\n",
      "555:\tlearn: 1.6443472\ttotal: 1m 4s\tremaining: 51.5s\n",
      "556:\tlearn: 1.6436591\ttotal: 1m 4s\tremaining: 51.4s\n",
      "557:\tlearn: 1.6433628\ttotal: 1m 4s\tremaining: 51.2s\n",
      "558:\tlearn: 1.6428676\ttotal: 1m 4s\tremaining: 51.1s\n",
      "559:\tlearn: 1.6422599\ttotal: 1m 4s\tremaining: 51s\n",
      "560:\tlearn: 1.6420465\ttotal: 1m 5s\tremaining: 50.9s\n",
      "561:\tlearn: 1.6415547\ttotal: 1m 5s\tremaining: 50.8s\n",
      "562:\tlearn: 1.6412827\ttotal: 1m 5s\tremaining: 50.6s\n",
      "563:\tlearn: 1.6402838\ttotal: 1m 5s\tremaining: 50.5s\n",
      "564:\tlearn: 1.6397835\ttotal: 1m 5s\tremaining: 50.4s\n",
      "565:\tlearn: 1.6393236\ttotal: 1m 5s\tremaining: 50.3s\n",
      "566:\tlearn: 1.6386983\ttotal: 1m 5s\tremaining: 50.2s\n",
      "567:\tlearn: 1.6380038\ttotal: 1m 5s\tremaining: 50s\n",
      "568:\tlearn: 1.6375962\ttotal: 1m 5s\tremaining: 49.9s\n",
      "569:\tlearn: 1.6373870\ttotal: 1m 6s\tremaining: 49.8s\n",
      "570:\tlearn: 1.6364423\ttotal: 1m 6s\tremaining: 49.7s\n",
      "571:\tlearn: 1.6358539\ttotal: 1m 6s\tremaining: 49.6s\n",
      "572:\tlearn: 1.6355668\ttotal: 1m 6s\tremaining: 49.5s\n",
      "573:\tlearn: 1.6342301\ttotal: 1m 6s\tremaining: 49.3s\n",
      "574:\tlearn: 1.6328930\ttotal: 1m 6s\tremaining: 49.2s\n",
      "575:\tlearn: 1.6324666\ttotal: 1m 6s\tremaining: 49.1s\n",
      "576:\tlearn: 1.6317214\ttotal: 1m 6s\tremaining: 49s\n",
      "577:\tlearn: 1.6309467\ttotal: 1m 6s\tremaining: 48.9s\n",
      "578:\tlearn: 1.6306421\ttotal: 1m 7s\tremaining: 48.7s\n",
      "579:\tlearn: 1.6300963\ttotal: 1m 7s\tremaining: 48.6s\n",
      "580:\tlearn: 1.6296440\ttotal: 1m 7s\tremaining: 48.5s\n",
      "581:\tlearn: 1.6288048\ttotal: 1m 7s\tremaining: 48.4s\n",
      "582:\tlearn: 1.6283094\ttotal: 1m 7s\tremaining: 48.3s\n",
      "583:\tlearn: 1.6278611\ttotal: 1m 7s\tremaining: 48.1s\n",
      "584:\tlearn: 1.6273845\ttotal: 1m 7s\tremaining: 48s\n",
      "585:\tlearn: 1.6271398\ttotal: 1m 7s\tremaining: 47.9s\n",
      "586:\tlearn: 1.6266472\ttotal: 1m 7s\tremaining: 47.8s\n",
      "587:\tlearn: 1.6256325\ttotal: 1m 8s\tremaining: 47.7s\n",
      "588:\tlearn: 1.6252210\ttotal: 1m 8s\tremaining: 47.5s\n",
      "589:\tlearn: 1.6249248\ttotal: 1m 8s\tremaining: 47.4s\n",
      "590:\tlearn: 1.6242449\ttotal: 1m 8s\tremaining: 47.3s\n",
      "591:\tlearn: 1.6239203\ttotal: 1m 8s\tremaining: 47.2s\n",
      "592:\tlearn: 1.6230423\ttotal: 1m 8s\tremaining: 47.1s\n",
      "593:\tlearn: 1.6221839\ttotal: 1m 8s\tremaining: 46.9s\n",
      "594:\tlearn: 1.6218452\ttotal: 1m 8s\tremaining: 46.8s\n",
      "595:\tlearn: 1.6215646\ttotal: 1m 8s\tremaining: 46.7s\n",
      "596:\tlearn: 1.6212762\ttotal: 1m 9s\tremaining: 46.6s\n",
      "597:\tlearn: 1.6210908\ttotal: 1m 9s\tremaining: 46.5s\n",
      "598:\tlearn: 1.6203917\ttotal: 1m 9s\tremaining: 46.4s\n",
      "599:\tlearn: 1.6196249\ttotal: 1m 9s\tremaining: 46.3s\n",
      "600:\tlearn: 1.6191623\ttotal: 1m 9s\tremaining: 46.1s\n",
      "601:\tlearn: 1.6185378\ttotal: 1m 9s\tremaining: 46s\n",
      "602:\tlearn: 1.6182616\ttotal: 1m 9s\tremaining: 45.9s\n",
      "603:\tlearn: 1.6173790\ttotal: 1m 9s\tremaining: 45.8s\n",
      "604:\tlearn: 1.6170547\ttotal: 1m 9s\tremaining: 45.7s\n",
      "605:\tlearn: 1.6165749\ttotal: 1m 10s\tremaining: 45.5s\n",
      "606:\tlearn: 1.6161770\ttotal: 1m 10s\tremaining: 45.4s\n",
      "607:\tlearn: 1.6153001\ttotal: 1m 10s\tremaining: 45.3s\n",
      "608:\tlearn: 1.6145031\ttotal: 1m 10s\tremaining: 45.2s\n",
      "609:\tlearn: 1.6136259\ttotal: 1m 10s\tremaining: 45.1s\n",
      "610:\tlearn: 1.6131930\ttotal: 1m 10s\tremaining: 45s\n",
      "611:\tlearn: 1.6129235\ttotal: 1m 10s\tremaining: 44.9s\n",
      "612:\tlearn: 1.6126163\ttotal: 1m 10s\tremaining: 44.8s\n",
      "613:\tlearn: 1.6117620\ttotal: 1m 11s\tremaining: 44.7s\n",
      "614:\tlearn: 1.6112282\ttotal: 1m 11s\tremaining: 44.6s\n",
      "615:\tlearn: 1.6102638\ttotal: 1m 11s\tremaining: 44.4s\n",
      "616:\tlearn: 1.6095564\ttotal: 1m 11s\tremaining: 44.3s\n",
      "617:\tlearn: 1.6086240\ttotal: 1m 11s\tremaining: 44.2s\n",
      "618:\tlearn: 1.6079962\ttotal: 1m 11s\tremaining: 44.1s\n",
      "619:\tlearn: 1.6072167\ttotal: 1m 11s\tremaining: 44s\n",
      "620:\tlearn: 1.6070388\ttotal: 1m 11s\tremaining: 43.8s\n",
      "621:\tlearn: 1.6064328\ttotal: 1m 11s\tremaining: 43.7s\n",
      "622:\tlearn: 1.6062379\ttotal: 1m 12s\tremaining: 43.6s\n",
      "623:\tlearn: 1.6058139\ttotal: 1m 12s\tremaining: 43.5s\n",
      "624:\tlearn: 1.6055426\ttotal: 1m 12s\tremaining: 43.4s\n",
      "625:\tlearn: 1.6052919\ttotal: 1m 12s\tremaining: 43.3s\n",
      "626:\tlearn: 1.6050103\ttotal: 1m 12s\tremaining: 43.2s\n",
      "627:\tlearn: 1.6047364\ttotal: 1m 12s\tremaining: 43s\n",
      "628:\tlearn: 1.6041184\ttotal: 1m 12s\tremaining: 42.9s\n",
      "629:\tlearn: 1.6037271\ttotal: 1m 12s\tremaining: 42.8s\n",
      "630:\tlearn: 1.6030679\ttotal: 1m 12s\tremaining: 42.7s\n",
      "631:\tlearn: 1.6024863\ttotal: 1m 13s\tremaining: 42.6s\n",
      "632:\tlearn: 1.6022070\ttotal: 1m 13s\tremaining: 42.4s\n",
      "633:\tlearn: 1.6015823\ttotal: 1m 13s\tremaining: 42.3s\n",
      "634:\tlearn: 1.6007607\ttotal: 1m 13s\tremaining: 42.2s\n",
      "635:\tlearn: 1.6003003\ttotal: 1m 13s\tremaining: 42.1s\n",
      "636:\tlearn: 1.5999606\ttotal: 1m 13s\tremaining: 42s\n",
      "637:\tlearn: 1.5997702\ttotal: 1m 13s\tremaining: 41.9s\n",
      "638:\tlearn: 1.5989414\ttotal: 1m 13s\tremaining: 41.8s\n",
      "639:\tlearn: 1.5985907\ttotal: 1m 14s\tremaining: 41.6s\n",
      "640:\tlearn: 1.5980127\ttotal: 1m 14s\tremaining: 41.5s\n",
      "641:\tlearn: 1.5977340\ttotal: 1m 14s\tremaining: 41.4s\n",
      "642:\tlearn: 1.5974273\ttotal: 1m 14s\tremaining: 41.3s\n",
      "643:\tlearn: 1.5968940\ttotal: 1m 14s\tremaining: 41.2s\n",
      "644:\tlearn: 1.5960104\ttotal: 1m 14s\tremaining: 41s\n",
      "645:\tlearn: 1.5954609\ttotal: 1m 14s\tremaining: 40.9s\n",
      "646:\tlearn: 1.5952709\ttotal: 1m 14s\tremaining: 40.8s\n",
      "647:\tlearn: 1.5944005\ttotal: 1m 14s\tremaining: 40.7s\n",
      "648:\tlearn: 1.5933769\ttotal: 1m 15s\tremaining: 40.6s\n",
      "649:\tlearn: 1.5929726\ttotal: 1m 15s\tremaining: 40.5s\n",
      "650:\tlearn: 1.5925851\ttotal: 1m 15s\tremaining: 40.3s\n",
      "651:\tlearn: 1.5916265\ttotal: 1m 15s\tremaining: 40.2s\n",
      "652:\tlearn: 1.5911253\ttotal: 1m 15s\tremaining: 40.1s\n",
      "653:\tlearn: 1.5901975\ttotal: 1m 15s\tremaining: 40s\n",
      "654:\tlearn: 1.5899257\ttotal: 1m 15s\tremaining: 39.9s\n",
      "655:\tlearn: 1.5896246\ttotal: 1m 15s\tremaining: 39.8s\n",
      "656:\tlearn: 1.5893580\ttotal: 1m 15s\tremaining: 39.6s\n",
      "657:\tlearn: 1.5884613\ttotal: 1m 16s\tremaining: 39.5s\n",
      "658:\tlearn: 1.5875940\ttotal: 1m 16s\tremaining: 39.4s\n",
      "659:\tlearn: 1.5870608\ttotal: 1m 16s\tremaining: 39.3s\n",
      "660:\tlearn: 1.5868840\ttotal: 1m 16s\tremaining: 39.2s\n",
      "661:\tlearn: 1.5862349\ttotal: 1m 16s\tremaining: 39s\n",
      "662:\tlearn: 1.5856382\ttotal: 1m 16s\tremaining: 38.9s\n",
      "663:\tlearn: 1.5853494\ttotal: 1m 16s\tremaining: 38.8s\n",
      "664:\tlearn: 1.5850936\ttotal: 1m 16s\tremaining: 38.7s\n",
      "665:\tlearn: 1.5846063\ttotal: 1m 16s\tremaining: 38.6s\n",
      "666:\tlearn: 1.5838228\ttotal: 1m 17s\tremaining: 38.5s\n",
      "667:\tlearn: 1.5834487\ttotal: 1m 17s\tremaining: 38.3s\n",
      "668:\tlearn: 1.5832631\ttotal: 1m 17s\tremaining: 38.2s\n",
      "669:\tlearn: 1.5830028\ttotal: 1m 17s\tremaining: 38.1s\n",
      "670:\tlearn: 1.5827485\ttotal: 1m 17s\tremaining: 38s\n",
      "671:\tlearn: 1.5825579\ttotal: 1m 17s\tremaining: 37.9s\n",
      "672:\tlearn: 1.5815366\ttotal: 1m 17s\tremaining: 37.8s\n",
      "673:\tlearn: 1.5804970\ttotal: 1m 17s\tremaining: 37.7s\n",
      "674:\tlearn: 1.5802291\ttotal: 1m 17s\tremaining: 37.5s\n",
      "675:\tlearn: 1.5793215\ttotal: 1m 18s\tremaining: 37.4s\n",
      "676:\tlearn: 1.5785327\ttotal: 1m 18s\tremaining: 37.3s\n",
      "677:\tlearn: 1.5776060\ttotal: 1m 18s\tremaining: 37.2s\n",
      "678:\tlearn: 1.5773464\ttotal: 1m 18s\tremaining: 37.1s\n",
      "679:\tlearn: 1.5768884\ttotal: 1m 18s\tremaining: 37s\n",
      "680:\tlearn: 1.5761108\ttotal: 1m 18s\tremaining: 36.8s\n",
      "681:\tlearn: 1.5758177\ttotal: 1m 18s\tremaining: 36.7s\n",
      "682:\tlearn: 1.5751101\ttotal: 1m 18s\tremaining: 36.6s\n",
      "683:\tlearn: 1.5742180\ttotal: 1m 18s\tremaining: 36.5s\n",
      "684:\tlearn: 1.5737737\ttotal: 1m 19s\tremaining: 36.4s\n",
      "685:\tlearn: 1.5730738\ttotal: 1m 19s\tremaining: 36.3s\n",
      "686:\tlearn: 1.5725311\ttotal: 1m 19s\tremaining: 36.1s\n",
      "687:\tlearn: 1.5716405\ttotal: 1m 19s\tremaining: 36s\n",
      "688:\tlearn: 1.5713533\ttotal: 1m 19s\tremaining: 35.9s\n",
      "689:\tlearn: 1.5708540\ttotal: 1m 19s\tremaining: 35.8s\n",
      "690:\tlearn: 1.5704779\ttotal: 1m 19s\tremaining: 35.7s\n",
      "691:\tlearn: 1.5696854\ttotal: 1m 19s\tremaining: 35.6s\n",
      "692:\tlearn: 1.5689556\ttotal: 1m 20s\tremaining: 35.4s\n",
      "693:\tlearn: 1.5683055\ttotal: 1m 20s\tremaining: 35.3s\n",
      "694:\tlearn: 1.5679852\ttotal: 1m 20s\tremaining: 35.2s\n",
      "695:\tlearn: 1.5672094\ttotal: 1m 20s\tremaining: 35.1s\n",
      "696:\tlearn: 1.5668974\ttotal: 1m 20s\tremaining: 35s\n",
      "697:\tlearn: 1.5663002\ttotal: 1m 20s\tremaining: 34.9s\n",
      "698:\tlearn: 1.5658619\ttotal: 1m 20s\tremaining: 34.7s\n",
      "699:\tlearn: 1.5650152\ttotal: 1m 20s\tremaining: 34.6s\n",
      "700:\tlearn: 1.5640718\ttotal: 1m 20s\tremaining: 34.5s\n",
      "701:\tlearn: 1.5635237\ttotal: 1m 21s\tremaining: 34.4s\n",
      "702:\tlearn: 1.5630911\ttotal: 1m 21s\tremaining: 34.3s\n",
      "703:\tlearn: 1.5629092\ttotal: 1m 21s\tremaining: 34.2s\n",
      "704:\tlearn: 1.5620684\ttotal: 1m 21s\tremaining: 34s\n",
      "705:\tlearn: 1.5612255\ttotal: 1m 21s\tremaining: 33.9s\n",
      "706:\tlearn: 1.5609121\ttotal: 1m 21s\tremaining: 33.8s\n",
      "707:\tlearn: 1.5606505\ttotal: 1m 21s\tremaining: 33.7s\n",
      "708:\tlearn: 1.5599330\ttotal: 1m 21s\tremaining: 33.6s\n",
      "709:\tlearn: 1.5596954\ttotal: 1m 21s\tremaining: 33.5s\n",
      "710:\tlearn: 1.5589538\ttotal: 1m 22s\tremaining: 33.4s\n",
      "711:\tlearn: 1.5586175\ttotal: 1m 22s\tremaining: 33.2s\n",
      "712:\tlearn: 1.5583913\ttotal: 1m 22s\tremaining: 33.1s\n",
      "713:\tlearn: 1.5582043\ttotal: 1m 22s\tremaining: 33s\n",
      "714:\tlearn: 1.5576506\ttotal: 1m 22s\tremaining: 32.9s\n",
      "715:\tlearn: 1.5574479\ttotal: 1m 22s\tremaining: 32.8s\n",
      "716:\tlearn: 1.5569855\ttotal: 1m 22s\tremaining: 32.7s\n",
      "717:\tlearn: 1.5559450\ttotal: 1m 22s\tremaining: 32.6s\n",
      "718:\tlearn: 1.5556256\ttotal: 1m 23s\tremaining: 32.4s\n",
      "719:\tlearn: 1.5549901\ttotal: 1m 23s\tremaining: 32.3s\n",
      "720:\tlearn: 1.5541352\ttotal: 1m 23s\tremaining: 32.2s\n",
      "721:\tlearn: 1.5533110\ttotal: 1m 23s\tremaining: 32.1s\n",
      "722:\tlearn: 1.5527777\ttotal: 1m 23s\tremaining: 32s\n",
      "723:\tlearn: 1.5523507\ttotal: 1m 23s\tremaining: 31.9s\n",
      "724:\tlearn: 1.5521660\ttotal: 1m 23s\tremaining: 31.7s\n",
      "725:\tlearn: 1.5514400\ttotal: 1m 23s\tremaining: 31.6s\n",
      "726:\tlearn: 1.5504764\ttotal: 1m 23s\tremaining: 31.5s\n",
      "727:\tlearn: 1.5501724\ttotal: 1m 24s\tremaining: 31.4s\n",
      "728:\tlearn: 1.5499485\ttotal: 1m 24s\tremaining: 31.3s\n",
      "729:\tlearn: 1.5496161\ttotal: 1m 24s\tremaining: 31.2s\n",
      "730:\tlearn: 1.5486377\ttotal: 1m 24s\tremaining: 31.1s\n",
      "731:\tlearn: 1.5477643\ttotal: 1m 24s\tremaining: 30.9s\n",
      "732:\tlearn: 1.5472869\ttotal: 1m 24s\tremaining: 30.8s\n",
      "733:\tlearn: 1.5467460\ttotal: 1m 24s\tremaining: 30.7s\n",
      "734:\tlearn: 1.5460894\ttotal: 1m 24s\tremaining: 30.6s\n",
      "735:\tlearn: 1.5454351\ttotal: 1m 24s\tremaining: 30.5s\n",
      "736:\tlearn: 1.5451759\ttotal: 1m 25s\tremaining: 30.4s\n",
      "737:\tlearn: 1.5445230\ttotal: 1m 25s\tremaining: 30.2s\n",
      "738:\tlearn: 1.5435788\ttotal: 1m 25s\tremaining: 30.1s\n",
      "739:\tlearn: 1.5431669\ttotal: 1m 25s\tremaining: 30s\n",
      "740:\tlearn: 1.5428705\ttotal: 1m 25s\tremaining: 29.9s\n",
      "741:\tlearn: 1.5427017\ttotal: 1m 25s\tremaining: 29.8s\n",
      "742:\tlearn: 1.5420613\ttotal: 1m 25s\tremaining: 29.7s\n",
      "743:\tlearn: 1.5412853\ttotal: 1m 25s\tremaining: 29.5s\n",
      "744:\tlearn: 1.5409163\ttotal: 1m 25s\tremaining: 29.4s\n",
      "745:\tlearn: 1.5401726\ttotal: 1m 26s\tremaining: 29.3s\n",
      "746:\tlearn: 1.5399238\ttotal: 1m 26s\tremaining: 29.2s\n",
      "747:\tlearn: 1.5392700\ttotal: 1m 26s\tremaining: 29.1s\n",
      "748:\tlearn: 1.5387405\ttotal: 1m 26s\tremaining: 29s\n",
      "749:\tlearn: 1.5379298\ttotal: 1m 26s\tremaining: 28.8s\n",
      "750:\tlearn: 1.5375946\ttotal: 1m 26s\tremaining: 28.7s\n",
      "751:\tlearn: 1.5374141\ttotal: 1m 26s\tremaining: 28.6s\n",
      "752:\tlearn: 1.5369522\ttotal: 1m 26s\tremaining: 28.5s\n",
      "753:\tlearn: 1.5360584\ttotal: 1m 26s\tremaining: 28.4s\n",
      "754:\tlearn: 1.5357051\ttotal: 1m 27s\tremaining: 28.3s\n",
      "755:\tlearn: 1.5350521\ttotal: 1m 27s\tremaining: 28.1s\n",
      "756:\tlearn: 1.5345335\ttotal: 1m 27s\tremaining: 28s\n",
      "757:\tlearn: 1.5336758\ttotal: 1m 27s\tremaining: 27.9s\n",
      "758:\tlearn: 1.5331822\ttotal: 1m 27s\tremaining: 27.8s\n",
      "759:\tlearn: 1.5325995\ttotal: 1m 27s\tremaining: 27.7s\n",
      "760:\tlearn: 1.5322792\ttotal: 1m 27s\tremaining: 27.6s\n",
      "761:\tlearn: 1.5315467\ttotal: 1m 27s\tremaining: 27.4s\n",
      "762:\tlearn: 1.5313089\ttotal: 1m 27s\tremaining: 27.3s\n",
      "763:\tlearn: 1.5304019\ttotal: 1m 28s\tremaining: 27.2s\n",
      "764:\tlearn: 1.5298573\ttotal: 1m 28s\tremaining: 27.1s\n",
      "765:\tlearn: 1.5296777\ttotal: 1m 28s\tremaining: 27s\n",
      "766:\tlearn: 1.5288410\ttotal: 1m 28s\tremaining: 26.9s\n",
      "767:\tlearn: 1.5282056\ttotal: 1m 28s\tremaining: 26.8s\n",
      "768:\tlearn: 1.5279345\ttotal: 1m 28s\tremaining: 26.6s\n",
      "769:\tlearn: 1.5275674\ttotal: 1m 28s\tremaining: 26.5s\n",
      "770:\tlearn: 1.5273296\ttotal: 1m 28s\tremaining: 26.4s\n",
      "771:\tlearn: 1.5267600\ttotal: 1m 29s\tremaining: 26.3s\n",
      "772:\tlearn: 1.5261979\ttotal: 1m 29s\tremaining: 26.2s\n",
      "773:\tlearn: 1.5257110\ttotal: 1m 29s\tremaining: 26.1s\n",
      "774:\tlearn: 1.5255419\ttotal: 1m 29s\tremaining: 25.9s\n",
      "775:\tlearn: 1.5247172\ttotal: 1m 29s\tremaining: 25.8s\n",
      "776:\tlearn: 1.5240947\ttotal: 1m 29s\tremaining: 25.7s\n",
      "777:\tlearn: 1.5236148\ttotal: 1m 29s\tremaining: 25.6s\n",
      "778:\tlearn: 1.5232624\ttotal: 1m 29s\tremaining: 25.5s\n",
      "779:\tlearn: 1.5230670\ttotal: 1m 29s\tremaining: 25.4s\n",
      "780:\tlearn: 1.5221873\ttotal: 1m 30s\tremaining: 25.3s\n",
      "781:\tlearn: 1.5216649\ttotal: 1m 30s\tremaining: 25.1s\n",
      "782:\tlearn: 1.5213515\ttotal: 1m 30s\tremaining: 25s\n",
      "783:\tlearn: 1.5206779\ttotal: 1m 30s\tremaining: 24.9s\n",
      "784:\tlearn: 1.5200721\ttotal: 1m 30s\tremaining: 24.8s\n",
      "785:\tlearn: 1.5198267\ttotal: 1m 30s\tremaining: 24.7s\n",
      "786:\tlearn: 1.5192792\ttotal: 1m 30s\tremaining: 24.6s\n",
      "787:\tlearn: 1.5190727\ttotal: 1m 30s\tremaining: 24.4s\n",
      "788:\tlearn: 1.5187066\ttotal: 1m 30s\tremaining: 24.3s\n",
      "789:\tlearn: 1.5183565\ttotal: 1m 31s\tremaining: 24.2s\n",
      "790:\tlearn: 1.5180796\ttotal: 1m 31s\tremaining: 24.1s\n",
      "791:\tlearn: 1.5176316\ttotal: 1m 31s\tremaining: 24s\n",
      "792:\tlearn: 1.5170323\ttotal: 1m 31s\tremaining: 23.9s\n",
      "793:\tlearn: 1.5160464\ttotal: 1m 31s\tremaining: 23.7s\n",
      "794:\tlearn: 1.5152366\ttotal: 1m 31s\tremaining: 23.6s\n",
      "795:\tlearn: 1.5143735\ttotal: 1m 31s\tremaining: 23.5s\n",
      "796:\tlearn: 1.5134893\ttotal: 1m 31s\tremaining: 23.4s\n",
      "797:\tlearn: 1.5128913\ttotal: 1m 31s\tremaining: 23.3s\n",
      "798:\tlearn: 1.5124089\ttotal: 1m 32s\tremaining: 23.2s\n",
      "799:\tlearn: 1.5117047\ttotal: 1m 32s\tremaining: 23s\n",
      "800:\tlearn: 1.5114537\ttotal: 1m 32s\tremaining: 22.9s\n",
      "801:\tlearn: 1.5112305\ttotal: 1m 32s\tremaining: 22.8s\n",
      "802:\tlearn: 1.5110647\ttotal: 1m 32s\tremaining: 22.7s\n",
      "803:\tlearn: 1.5101600\ttotal: 1m 32s\tremaining: 22.6s\n",
      "804:\tlearn: 1.5098737\ttotal: 1m 32s\tremaining: 22.5s\n",
      "805:\tlearn: 1.5095731\ttotal: 1m 32s\tremaining: 22.3s\n",
      "806:\tlearn: 1.5087392\ttotal: 1m 32s\tremaining: 22.2s\n",
      "807:\tlearn: 1.5085547\ttotal: 1m 33s\tremaining: 22.1s\n",
      "808:\tlearn: 1.5079706\ttotal: 1m 33s\tremaining: 22s\n",
      "809:\tlearn: 1.5073863\ttotal: 1m 33s\tremaining: 21.9s\n",
      "810:\tlearn: 1.5072135\ttotal: 1m 33s\tremaining: 21.8s\n",
      "811:\tlearn: 1.5067695\ttotal: 1m 33s\tremaining: 21.7s\n",
      "812:\tlearn: 1.5063752\ttotal: 1m 33s\tremaining: 21.5s\n",
      "813:\tlearn: 1.5058381\ttotal: 1m 33s\tremaining: 21.4s\n",
      "814:\tlearn: 1.5055089\ttotal: 1m 33s\tremaining: 21.3s\n",
      "815:\tlearn: 1.5049090\ttotal: 1m 33s\tremaining: 21.2s\n",
      "816:\tlearn: 1.5042474\ttotal: 1m 34s\tremaining: 21.1s\n",
      "817:\tlearn: 1.5036062\ttotal: 1m 34s\tremaining: 21s\n",
      "818:\tlearn: 1.5028723\ttotal: 1m 34s\tremaining: 20.8s\n",
      "819:\tlearn: 1.5026614\ttotal: 1m 34s\tremaining: 20.7s\n",
      "820:\tlearn: 1.5017923\ttotal: 1m 34s\tremaining: 20.6s\n",
      "821:\tlearn: 1.5010478\ttotal: 1m 34s\tremaining: 20.5s\n",
      "822:\tlearn: 1.5002730\ttotal: 1m 34s\tremaining: 20.4s\n",
      "823:\tlearn: 1.4995918\ttotal: 1m 34s\tremaining: 20.3s\n",
      "824:\tlearn: 1.4988413\ttotal: 1m 35s\tremaining: 20.2s\n",
      "825:\tlearn: 1.4979698\ttotal: 1m 35s\tremaining: 20s\n",
      "826:\tlearn: 1.4973821\ttotal: 1m 35s\tremaining: 19.9s\n",
      "827:\tlearn: 1.4970557\ttotal: 1m 35s\tremaining: 19.8s\n",
      "828:\tlearn: 1.4964354\ttotal: 1m 35s\tremaining: 19.7s\n",
      "829:\tlearn: 1.4957498\ttotal: 1m 35s\tremaining: 19.6s\n",
      "830:\tlearn: 1.4952090\ttotal: 1m 35s\tremaining: 19.5s\n",
      "831:\tlearn: 1.4944159\ttotal: 1m 35s\tremaining: 19.3s\n",
      "832:\tlearn: 1.4939488\ttotal: 1m 35s\tremaining: 19.2s\n",
      "833:\tlearn: 1.4930689\ttotal: 1m 36s\tremaining: 19.1s\n",
      "834:\tlearn: 1.4929130\ttotal: 1m 36s\tremaining: 19s\n",
      "835:\tlearn: 1.4926199\ttotal: 1m 36s\tremaining: 18.9s\n",
      "836:\tlearn: 1.4919014\ttotal: 1m 36s\tremaining: 18.8s\n",
      "837:\tlearn: 1.4915771\ttotal: 1m 36s\tremaining: 18.7s\n",
      "838:\tlearn: 1.4911752\ttotal: 1m 36s\tremaining: 18.5s\n",
      "839:\tlearn: 1.4908331\ttotal: 1m 36s\tremaining: 18.4s\n",
      "840:\tlearn: 1.4903163\ttotal: 1m 36s\tremaining: 18.3s\n",
      "841:\tlearn: 1.4899413\ttotal: 1m 36s\tremaining: 18.2s\n",
      "842:\tlearn: 1.4896455\ttotal: 1m 37s\tremaining: 18.1s\n",
      "843:\tlearn: 1.4894285\ttotal: 1m 37s\tremaining: 18s\n",
      "844:\tlearn: 1.4884881\ttotal: 1m 37s\tremaining: 17.8s\n",
      "845:\tlearn: 1.4882160\ttotal: 1m 37s\tremaining: 17.7s\n",
      "846:\tlearn: 1.4878278\ttotal: 1m 37s\tremaining: 17.6s\n",
      "847:\tlearn: 1.4874751\ttotal: 1m 37s\tremaining: 17.5s\n",
      "848:\tlearn: 1.4867650\ttotal: 1m 37s\tremaining: 17.4s\n",
      "849:\tlearn: 1.4858861\ttotal: 1m 37s\tremaining: 17.3s\n",
      "850:\tlearn: 1.4856610\ttotal: 1m 37s\tremaining: 17.1s\n",
      "851:\tlearn: 1.4851608\ttotal: 1m 38s\tremaining: 17s\n",
      "852:\tlearn: 1.4847578\ttotal: 1m 38s\tremaining: 16.9s\n",
      "853:\tlearn: 1.4845455\ttotal: 1m 38s\tremaining: 16.8s\n",
      "854:\tlearn: 1.4840876\ttotal: 1m 38s\tremaining: 16.7s\n",
      "855:\tlearn: 1.4838238\ttotal: 1m 38s\tremaining: 16.6s\n",
      "856:\tlearn: 1.4835716\ttotal: 1m 38s\tremaining: 16.5s\n",
      "857:\tlearn: 1.4830545\ttotal: 1m 38s\tremaining: 16.3s\n",
      "858:\tlearn: 1.4828875\ttotal: 1m 38s\tremaining: 16.2s\n",
      "859:\tlearn: 1.4820399\ttotal: 1m 38s\tremaining: 16.1s\n",
      "860:\tlearn: 1.4813215\ttotal: 1m 39s\tremaining: 16s\n",
      "861:\tlearn: 1.4805054\ttotal: 1m 39s\tremaining: 15.9s\n",
      "862:\tlearn: 1.4803489\ttotal: 1m 39s\tremaining: 15.8s\n",
      "863:\tlearn: 1.4800495\ttotal: 1m 39s\tremaining: 15.6s\n",
      "864:\tlearn: 1.4791857\ttotal: 1m 39s\tremaining: 15.5s\n",
      "865:\tlearn: 1.4788917\ttotal: 1m 39s\tremaining: 15.4s\n",
      "866:\tlearn: 1.4782918\ttotal: 1m 39s\tremaining: 15.3s\n",
      "867:\tlearn: 1.4780550\ttotal: 1m 39s\tremaining: 15.2s\n",
      "868:\tlearn: 1.4770842\ttotal: 1m 39s\tremaining: 15.1s\n",
      "869:\tlearn: 1.4765929\ttotal: 1m 40s\tremaining: 14.9s\n",
      "870:\tlearn: 1.4763330\ttotal: 1m 40s\tremaining: 14.8s\n",
      "871:\tlearn: 1.4757887\ttotal: 1m 40s\tremaining: 14.7s\n",
      "872:\tlearn: 1.4755657\ttotal: 1m 40s\tremaining: 14.6s\n",
      "873:\tlearn: 1.4753663\ttotal: 1m 40s\tremaining: 14.5s\n",
      "874:\tlearn: 1.4751593\ttotal: 1m 40s\tremaining: 14.4s\n",
      "875:\tlearn: 1.4749014\ttotal: 1m 40s\tremaining: 14.3s\n",
      "876:\tlearn: 1.4746812\ttotal: 1m 40s\tremaining: 14.1s\n",
      "877:\tlearn: 1.4737930\ttotal: 1m 40s\tremaining: 14s\n",
      "878:\tlearn: 1.4732677\ttotal: 1m 41s\tremaining: 13.9s\n",
      "879:\tlearn: 1.4729927\ttotal: 1m 41s\tremaining: 13.8s\n",
      "880:\tlearn: 1.4723608\ttotal: 1m 41s\tremaining: 13.7s\n",
      "881:\tlearn: 1.4717191\ttotal: 1m 41s\tremaining: 13.6s\n",
      "882:\tlearn: 1.4714652\ttotal: 1m 41s\tremaining: 13.4s\n",
      "883:\tlearn: 1.4708479\ttotal: 1m 41s\tremaining: 13.3s\n",
      "884:\tlearn: 1.4699606\ttotal: 1m 41s\tremaining: 13.2s\n",
      "885:\tlearn: 1.4691082\ttotal: 1m 41s\tremaining: 13.1s\n",
      "886:\tlearn: 1.4684951\ttotal: 1m 41s\tremaining: 13s\n",
      "887:\tlearn: 1.4682761\ttotal: 1m 42s\tremaining: 12.9s\n",
      "888:\tlearn: 1.4678371\ttotal: 1m 42s\tremaining: 12.8s\n",
      "889:\tlearn: 1.4668654\ttotal: 1m 42s\tremaining: 12.6s\n",
      "890:\tlearn: 1.4666661\ttotal: 1m 42s\tremaining: 12.5s\n",
      "891:\tlearn: 1.4665422\ttotal: 1m 42s\tremaining: 12.4s\n",
      "892:\tlearn: 1.4659692\ttotal: 1m 42s\tremaining: 12.3s\n",
      "893:\tlearn: 1.4651611\ttotal: 1m 42s\tremaining: 12.2s\n",
      "894:\tlearn: 1.4644667\ttotal: 1m 42s\tremaining: 12.1s\n",
      "895:\tlearn: 1.4638379\ttotal: 1m 42s\tremaining: 12s\n",
      "896:\tlearn: 1.4631090\ttotal: 1m 43s\tremaining: 11.8s\n",
      "897:\tlearn: 1.4628880\ttotal: 1m 43s\tremaining: 11.7s\n",
      "898:\tlearn: 1.4623005\ttotal: 1m 43s\tremaining: 11.6s\n",
      "899:\tlearn: 1.4620852\ttotal: 1m 43s\tremaining: 11.5s\n",
      "900:\tlearn: 1.4616631\ttotal: 1m 43s\tremaining: 11.4s\n",
      "901:\tlearn: 1.4612738\ttotal: 1m 43s\tremaining: 11.3s\n",
      "902:\tlearn: 1.4609422\ttotal: 1m 43s\tremaining: 11.2s\n",
      "903:\tlearn: 1.4605906\ttotal: 1m 43s\tremaining: 11s\n",
      "904:\tlearn: 1.4599989\ttotal: 1m 44s\tremaining: 10.9s\n",
      "905:\tlearn: 1.4591963\ttotal: 1m 44s\tremaining: 10.8s\n",
      "906:\tlearn: 1.4588357\ttotal: 1m 44s\tremaining: 10.7s\n",
      "907:\tlearn: 1.4583675\ttotal: 1m 44s\tremaining: 10.6s\n",
      "908:\tlearn: 1.4577105\ttotal: 1m 44s\tremaining: 10.5s\n",
      "909:\tlearn: 1.4572654\ttotal: 1m 44s\tremaining: 10.3s\n",
      "910:\tlearn: 1.4570487\ttotal: 1m 44s\tremaining: 10.2s\n",
      "911:\tlearn: 1.4566103\ttotal: 1m 44s\tremaining: 10.1s\n",
      "912:\tlearn: 1.4558431\ttotal: 1m 44s\tremaining: 10s\n",
      "913:\tlearn: 1.4551271\ttotal: 1m 45s\tremaining: 9.89s\n",
      "914:\tlearn: 1.4547860\ttotal: 1m 45s\tremaining: 9.77s\n",
      "915:\tlearn: 1.4544082\ttotal: 1m 45s\tremaining: 9.65s\n",
      "916:\tlearn: 1.4539410\ttotal: 1m 45s\tremaining: 9.54s\n",
      "917:\tlearn: 1.4537965\ttotal: 1m 45s\tremaining: 9.43s\n",
      "918:\tlearn: 1.4531503\ttotal: 1m 45s\tremaining: 9.31s\n",
      "919:\tlearn: 1.4530093\ttotal: 1m 45s\tremaining: 9.2s\n",
      "920:\tlearn: 1.4520582\ttotal: 1m 45s\tremaining: 9.08s\n",
      "921:\tlearn: 1.4513629\ttotal: 1m 45s\tremaining: 8.97s\n",
      "922:\tlearn: 1.4510158\ttotal: 1m 46s\tremaining: 8.85s\n",
      "923:\tlearn: 1.4502217\ttotal: 1m 46s\tremaining: 8.74s\n",
      "924:\tlearn: 1.4498216\ttotal: 1m 46s\tremaining: 8.62s\n",
      "925:\tlearn: 1.4492253\ttotal: 1m 46s\tremaining: 8.51s\n",
      "926:\tlearn: 1.4486487\ttotal: 1m 46s\tremaining: 8.39s\n",
      "927:\tlearn: 1.4482774\ttotal: 1m 46s\tremaining: 8.28s\n",
      "928:\tlearn: 1.4478903\ttotal: 1m 46s\tremaining: 8.16s\n",
      "929:\tlearn: 1.4472207\ttotal: 1m 46s\tremaining: 8.04s\n",
      "930:\tlearn: 1.4465525\ttotal: 1m 47s\tremaining: 7.93s\n",
      "931:\tlearn: 1.4460990\ttotal: 1m 47s\tremaining: 7.82s\n",
      "932:\tlearn: 1.4455036\ttotal: 1m 47s\tremaining: 7.7s\n",
      "933:\tlearn: 1.4448924\ttotal: 1m 47s\tremaining: 7.59s\n",
      "934:\tlearn: 1.4439894\ttotal: 1m 47s\tremaining: 7.47s\n",
      "935:\tlearn: 1.4438551\ttotal: 1m 47s\tremaining: 7.36s\n",
      "936:\tlearn: 1.4436455\ttotal: 1m 47s\tremaining: 7.24s\n",
      "937:\tlearn: 1.4426683\ttotal: 1m 47s\tremaining: 7.13s\n",
      "938:\tlearn: 1.4418942\ttotal: 1m 47s\tremaining: 7.01s\n",
      "939:\tlearn: 1.4416206\ttotal: 1m 48s\tremaining: 6.9s\n",
      "940:\tlearn: 1.4409810\ttotal: 1m 48s\tremaining: 6.78s\n",
      "941:\tlearn: 1.4406920\ttotal: 1m 48s\tremaining: 6.67s\n",
      "942:\tlearn: 1.4401037\ttotal: 1m 48s\tremaining: 6.55s\n",
      "943:\tlearn: 1.4395290\ttotal: 1m 48s\tremaining: 6.44s\n",
      "944:\tlearn: 1.4389982\ttotal: 1m 48s\tremaining: 6.32s\n",
      "945:\tlearn: 1.4385408\ttotal: 1m 48s\tremaining: 6.21s\n",
      "946:\tlearn: 1.4378873\ttotal: 1m 48s\tremaining: 6.09s\n",
      "947:\tlearn: 1.4372060\ttotal: 1m 48s\tremaining: 5.98s\n",
      "948:\tlearn: 1.4365836\ttotal: 1m 49s\tremaining: 5.86s\n",
      "949:\tlearn: 1.4362922\ttotal: 1m 49s\tremaining: 5.75s\n",
      "950:\tlearn: 1.4360006\ttotal: 1m 49s\tremaining: 5.63s\n",
      "951:\tlearn: 1.4354217\ttotal: 1m 49s\tremaining: 5.52s\n",
      "952:\tlearn: 1.4349977\ttotal: 1m 49s\tremaining: 5.4s\n",
      "953:\tlearn: 1.4346389\ttotal: 1m 49s\tremaining: 5.29s\n",
      "954:\tlearn: 1.4340944\ttotal: 1m 49s\tremaining: 5.17s\n",
      "955:\tlearn: 1.4337968\ttotal: 1m 49s\tremaining: 5.06s\n",
      "956:\tlearn: 1.4331187\ttotal: 1m 50s\tremaining: 4.94s\n",
      "957:\tlearn: 1.4328244\ttotal: 1m 50s\tremaining: 4.83s\n",
      "958:\tlearn: 1.4322415\ttotal: 1m 50s\tremaining: 4.71s\n",
      "959:\tlearn: 1.4320068\ttotal: 1m 50s\tremaining: 4.6s\n",
      "960:\tlearn: 1.4318503\ttotal: 1m 50s\tremaining: 4.48s\n",
      "961:\tlearn: 1.4311734\ttotal: 1m 50s\tremaining: 4.37s\n",
      "962:\tlearn: 1.4309495\ttotal: 1m 50s\tremaining: 4.25s\n",
      "963:\tlearn: 1.4305385\ttotal: 1m 50s\tremaining: 4.14s\n",
      "964:\tlearn: 1.4299197\ttotal: 1m 50s\tremaining: 4.02s\n",
      "965:\tlearn: 1.4293805\ttotal: 1m 51s\tremaining: 3.91s\n",
      "966:\tlearn: 1.4290378\ttotal: 1m 51s\tremaining: 3.79s\n",
      "967:\tlearn: 1.4285647\ttotal: 1m 51s\tremaining: 3.68s\n",
      "968:\tlearn: 1.4277632\ttotal: 1m 51s\tremaining: 3.56s\n",
      "969:\tlearn: 1.4274300\ttotal: 1m 51s\tremaining: 3.45s\n",
      "970:\tlearn: 1.4269620\ttotal: 1m 51s\tremaining: 3.33s\n",
      "971:\tlearn: 1.4263064\ttotal: 1m 51s\tremaining: 3.22s\n",
      "972:\tlearn: 1.4256856\ttotal: 1m 51s\tremaining: 3.1s\n",
      "973:\tlearn: 1.4254757\ttotal: 1m 51s\tremaining: 2.99s\n",
      "974:\tlearn: 1.4251697\ttotal: 1m 52s\tremaining: 2.87s\n",
      "975:\tlearn: 1.4245407\ttotal: 1m 52s\tremaining: 2.76s\n",
      "976:\tlearn: 1.4238470\ttotal: 1m 52s\tremaining: 2.64s\n",
      "977:\tlearn: 1.4232883\ttotal: 1m 52s\tremaining: 2.53s\n",
      "978:\tlearn: 1.4231348\ttotal: 1m 52s\tremaining: 2.41s\n",
      "979:\tlearn: 1.4229298\ttotal: 1m 52s\tremaining: 2.3s\n",
      "980:\tlearn: 1.4224870\ttotal: 1m 52s\tremaining: 2.18s\n",
      "981:\tlearn: 1.4221954\ttotal: 1m 52s\tremaining: 2.07s\n",
      "982:\tlearn: 1.4215634\ttotal: 1m 52s\tremaining: 1.95s\n",
      "983:\tlearn: 1.4209203\ttotal: 1m 53s\tremaining: 1.84s\n",
      "984:\tlearn: 1.4201096\ttotal: 1m 53s\tremaining: 1.72s\n",
      "985:\tlearn: 1.4195105\ttotal: 1m 53s\tremaining: 1.61s\n",
      "986:\tlearn: 1.4185787\ttotal: 1m 53s\tremaining: 1.49s\n",
      "987:\tlearn: 1.4181531\ttotal: 1m 53s\tremaining: 1.38s\n",
      "988:\tlearn: 1.4176971\ttotal: 1m 53s\tremaining: 1.26s\n",
      "989:\tlearn: 1.4169535\ttotal: 1m 53s\tremaining: 1.15s\n",
      "990:\tlearn: 1.4162694\ttotal: 1m 53s\tremaining: 1.03s\n",
      "991:\tlearn: 1.4159965\ttotal: 1m 53s\tremaining: 919ms\n",
      "992:\tlearn: 1.4154340\ttotal: 1m 54s\tremaining: 804ms\n",
      "993:\tlearn: 1.4146453\ttotal: 1m 54s\tremaining: 689ms\n",
      "994:\tlearn: 1.4141439\ttotal: 1m 54s\tremaining: 574ms\n",
      "995:\tlearn: 1.4139532\ttotal: 1m 54s\tremaining: 459ms\n",
      "996:\tlearn: 1.4134716\ttotal: 1m 54s\tremaining: 344ms\n",
      "997:\tlearn: 1.4131920\ttotal: 1m 54s\tremaining: 230ms\n",
      "998:\tlearn: 1.4127446\ttotal: 1m 54s\tremaining: 115ms\n",
      "999:\tlearn: 1.4124722\ttotal: 1m 54s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_squared_error': 4.1158709165198495,\n",
       " 'mean_absolute_percentage_error': 3116774256794.7705,\n",
       " 'r2': 0.05578023078144623}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "model = CatBoostRegressor()\n",
    "\n",
    "model.fit(X_train_body_vectorized, y_train)\n",
    "\n",
    "scores = {\n",
    "    'mean_squared_error': mean_squared_error(y_test, model.predict(X_test_body_vectorized)),\n",
    "    'mean_absolute_percentage_error': mean_absolute_percentage_error(y_test, model.predict(X_test_body_vectorized)),\n",
    "    'r2': r2_score(y_test, model.predict(X_test_body_vectorized)),\n",
    "}\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f3d224b5-4e11-4b65-a8f4-f51092b0e22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_squared_error': 4.381126780122696,\n",
       " 'mean_absolute_percentage_error': 6707651970997.321,\n",
       " 'r2': -0.005071976538681078}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor()\n",
    "\n",
    "model.fit(X_train_body_vectorized, y_train)\n",
    "\n",
    "scores = {\n",
    "    'mean_squared_error': mean_squared_error(y_test, model.predict(X_test_body_vectorized)),\n",
    "    'mean_absolute_percentage_error': mean_absolute_percentage_error(y_test, model.predict(X_test_body_vectorized)),\n",
    "    'r2': r2_score(y_test, model.predict(X_test_body_vectorized)),\n",
    "}\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4353f459-1505-47cc-9d84-c88196da2c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.247370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 407666\n",
      "[LightGBM] [Info] Number of data points in the train set: 8607, number of used features: 8083\n",
      "[LightGBM] [Info] Start training from score 0.089547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_squared_error': 4.224062468412791,\n",
       " 'mean_absolute_percentage_error': 7944728957177.876,\n",
       " 'r2': 0.030960064106703045}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    " \n",
    "model = LGBMRegressor(metric='mse')\n",
    "\n",
    "model.fit(X_train_body_vectorized, y_train)\n",
    "\n",
    "scores = {\n",
    "    'mean_squared_error': mean_squared_error(y_test, model.predict(X_test_body_vectorized)),\n",
    "    'mean_absolute_percentage_error': mean_absolute_percentage_error(y_test, model.predict(X_test_body_vectorized)),\n",
    "    'r2': r2_score(y_test, model.predict(X_test_body_vectorized)),\n",
    "}\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95c558f-8f0c-4ea9-9a7c-f8c6c2a30410",
   "metadata": {},
   "source": [
    "Merge all news of one week for every ticker in one string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c27773c-7781-4b31-9310-0d9415cd0ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updated</th>\n",
       "      <th>stocks</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>BROAD</td>\n",
       "      <td>Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>BZSUM</td>\n",
       "      <td>Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>CAR</td>\n",
       "      <td>Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>EARLY</td>\n",
       "      <td>Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     updated stocks                                               body\n",
       "1 2013-01-02   AAPL  Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...\n",
       "1 2013-01-02  BROAD  Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...\n",
       "1 2013-01-02  BZSUM  Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...\n",
       "1 2013-01-02    CAR  Futures Up Strong on Fiscal Cliff Deal\\nU.S. e...\n",
       "1 2013-01-02  EARLY  Futures Up Strong on Fiscal Cliff Deal\\nU.S. e..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news = pd.read_csv('datasets/news_sp_500.csv').iloc[:,2:][['updated', 'stocks', 'body']].dropna()\n",
    "\n",
    "df_news['stocks'] = df_news['stocks'].apply(eval).apply(lambda x: [entry['name'] for entry in x])\n",
    "\n",
    "df_news = df_news.explode('stocks')\n",
    "\n",
    "df_news['updated'] = pd.to_datetime(df_news['updated']).dt.tz_localize(None)\n",
    "\n",
    "df_news['updated'] = df_news['updated'].dt.date\n",
    "df_news['updated'] = pd.to_datetime(df_news['updated'])\n",
    "\n",
    "df_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27ba9319-13af-4f81-bd4f-23cb55815d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news_daily = df_news.groupby([df_news['updated'], 'stocks'])['body'].apply(lambda x: '\\n'.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b26a6c76-2697-463f-b27c-35253cab3678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from ta.trend import MACD\n",
    "\n",
    "def apply_features(group):\n",
    "    group.index = pd.to_datetime(group.index)\n",
    "\n",
    "    # Compute lag features, moving averages, etc., for the group\n",
    "    for lag in range(1, 4):\n",
    "        group[f'lag_{lag}'] = group['Close'].shift(lag)\n",
    "    group['weekly_return'] = group['Close'].pct_change(5)\n",
    "    group['5_day_MA'] = group['Close'].rolling(window=5).mean()\n",
    "    group['20_day_MA'] = group['Close'].rolling(window=20).mean()\n",
    "    group['5_day_volatility'] = group['Close'].rolling(window=5).std()\n",
    "    group['momentum'] = group['Close'] - group['Close'].shift(1)\n",
    "    \n",
    "    # MACD, ensuring you handle NaNs as per your strategy\n",
    "\n",
    "    macd = MACD(close=group['Close'], window_slow=26, window_fast=12, window_sign=9)\n",
    "    group['MACD'] = macd.macd()\n",
    "    group['MACD_signal'] = macd.macd_signal()\n",
    "    group['MACD_histogram'] = macd.macd_diff()\n",
    "\n",
    "    # Adjusting for multi-stock data: adding week_of_year and month\n",
    "    group['week_of_year'] = group.index.isocalendar().week\n",
    "    group['month'] = group.index.month\n",
    "    \n",
    "    return group.dropna()  # Optionally drop NaNs\n",
    "\n",
    "# Apply the function to each group and recombine\n",
    "# data_grouped = data.groupby('Symbol').apply(apply_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3531d5e2-0f4f-4c30-b965-b804129b65ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks = stocks.groupby('Symbol').apply(apply_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fded9b04-5f41-419c-a255-129d49aef120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>...</th>\n",
       "      <th>weekly_return</th>\n",
       "      <th>5_day_MA</th>\n",
       "      <th>20_day_MA</th>\n",
       "      <th>5_day_volatility</th>\n",
       "      <th>momentum</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_signal</th>\n",
       "      <th>MACD_histogram</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-20</td>\n",
       "      <td>A</td>\n",
       "      <td>27.471472</td>\n",
       "      <td>30.214592</td>\n",
       "      <td>30.650930</td>\n",
       "      <td>30.200287</td>\n",
       "      <td>30.643778</td>\n",
       "      <td>5410260.0</td>\n",
       "      <td>30.765379</td>\n",
       "      <td>30.221745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053339</td>\n",
       "      <td>31.020028</td>\n",
       "      <td>31.796495</td>\n",
       "      <td>0.878207</td>\n",
       "      <td>-0.550787</td>\n",
       "      <td>-0.056695</td>\n",
       "      <td>0.209343</td>\n",
       "      <td>-0.266038</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-21</td>\n",
       "      <td>A</td>\n",
       "      <td>27.074751</td>\n",
       "      <td>29.778255</td>\n",
       "      <td>30.143063</td>\n",
       "      <td>29.663805</td>\n",
       "      <td>30.143063</td>\n",
       "      <td>4774450.0</td>\n",
       "      <td>30.214592</td>\n",
       "      <td>30.765379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069721</td>\n",
       "      <td>30.573677</td>\n",
       "      <td>31.701001</td>\n",
       "      <td>0.814060</td>\n",
       "      <td>-0.436337</td>\n",
       "      <td>-0.177837</td>\n",
       "      <td>0.131907</td>\n",
       "      <td>-0.309744</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-22</td>\n",
       "      <td>A</td>\n",
       "      <td>27.185310</td>\n",
       "      <td>29.899857</td>\n",
       "      <td>30.092991</td>\n",
       "      <td>29.742489</td>\n",
       "      <td>29.921316</td>\n",
       "      <td>4690150.0</td>\n",
       "      <td>29.778255</td>\n",
       "      <td>30.214592</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062360</td>\n",
       "      <td>30.175965</td>\n",
       "      <td>31.598712</td>\n",
       "      <td>0.382559</td>\n",
       "      <td>0.121601</td>\n",
       "      <td>-0.261022</td>\n",
       "      <td>0.053321</td>\n",
       "      <td>-0.314343</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>A</td>\n",
       "      <td>26.853619</td>\n",
       "      <td>29.535049</td>\n",
       "      <td>30.200287</td>\n",
       "      <td>29.535049</td>\n",
       "      <td>30.107296</td>\n",
       "      <td>5064255.0</td>\n",
       "      <td>29.899857</td>\n",
       "      <td>29.778255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022722</td>\n",
       "      <td>30.038626</td>\n",
       "      <td>31.455651</td>\n",
       "      <td>0.474282</td>\n",
       "      <td>-0.364807</td>\n",
       "      <td>-0.352323</td>\n",
       "      <td>-0.027808</td>\n",
       "      <td>-0.324515</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-26</td>\n",
       "      <td>A</td>\n",
       "      <td>26.645504</td>\n",
       "      <td>29.306152</td>\n",
       "      <td>29.535049</td>\n",
       "      <td>28.748213</td>\n",
       "      <td>29.055794</td>\n",
       "      <td>8647888.0</td>\n",
       "      <td>29.535049</td>\n",
       "      <td>29.899857</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047431</td>\n",
       "      <td>29.746781</td>\n",
       "      <td>31.305079</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>-0.228897</td>\n",
       "      <td>-0.438099</td>\n",
       "      <td>-0.109866</td>\n",
       "      <td>-0.328233</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348219</th>\n",
       "      <td>2024-02-15</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>189.649994</td>\n",
       "      <td>189.649994</td>\n",
       "      <td>190.339996</td>\n",
       "      <td>183.860001</td>\n",
       "      <td>183.860001</td>\n",
       "      <td>2725600.0</td>\n",
       "      <td>184.080002</td>\n",
       "      <td>183.490005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031162</td>\n",
       "      <td>190.246002</td>\n",
       "      <td>190.657500</td>\n",
       "      <td>6.625424</td>\n",
       "      <td>5.569992</td>\n",
       "      <td>-0.425651</td>\n",
       "      <td>0.179822</td>\n",
       "      <td>-0.605472</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348220</th>\n",
       "      <td>2024-02-16</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>188.389999</td>\n",
       "      <td>188.389999</td>\n",
       "      <td>190.350006</td>\n",
       "      <td>187.929993</td>\n",
       "      <td>189.399994</td>\n",
       "      <td>1953700.0</td>\n",
       "      <td>189.649994</td>\n",
       "      <td>184.080002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045256</td>\n",
       "      <td>188.460001</td>\n",
       "      <td>190.658000</td>\n",
       "      <td>5.315994</td>\n",
       "      <td>-1.259995</td>\n",
       "      <td>-0.585697</td>\n",
       "      <td>0.026718</td>\n",
       "      <td>-0.612414</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348221</th>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>186.550003</td>\n",
       "      <td>186.550003</td>\n",
       "      <td>189.410004</td>\n",
       "      <td>186.240005</td>\n",
       "      <td>187.300003</td>\n",
       "      <td>2502800.0</td>\n",
       "      <td>188.389999</td>\n",
       "      <td>189.649994</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051553</td>\n",
       "      <td>186.432001</td>\n",
       "      <td>190.425500</td>\n",
       "      <td>2.664132</td>\n",
       "      <td>-1.839996</td>\n",
       "      <td>-0.851194</td>\n",
       "      <td>-0.148865</td>\n",
       "      <td>-0.702330</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348222</th>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>188.380005</td>\n",
       "      <td>188.380005</td>\n",
       "      <td>188.860001</td>\n",
       "      <td>186.660004</td>\n",
       "      <td>186.660004</td>\n",
       "      <td>3179300.0</td>\n",
       "      <td>186.550003</td>\n",
       "      <td>188.389999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026650</td>\n",
       "      <td>187.410001</td>\n",
       "      <td>190.439500</td>\n",
       "      <td>2.164911</td>\n",
       "      <td>1.830002</td>\n",
       "      <td>-0.903522</td>\n",
       "      <td>-0.299796</td>\n",
       "      <td>-0.603726</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348223</th>\n",
       "      <td>2024-02-22</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>196.660004</td>\n",
       "      <td>196.660004</td>\n",
       "      <td>196.669998</td>\n",
       "      <td>188.539993</td>\n",
       "      <td>189.309998</td>\n",
       "      <td>3339700.0</td>\n",
       "      <td>188.380005</td>\n",
       "      <td>186.550003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068340</td>\n",
       "      <td>189.926001</td>\n",
       "      <td>190.969000</td>\n",
       "      <td>3.923319</td>\n",
       "      <td>8.279999</td>\n",
       "      <td>-0.273710</td>\n",
       "      <td>-0.294579</td>\n",
       "      <td>0.020868</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1348224 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date Symbol   Adj Close       Close        High         Low  \\\n",
       "0       2013-02-20      A   27.471472   30.214592   30.650930   30.200287   \n",
       "1       2013-02-21      A   27.074751   29.778255   30.143063   29.663805   \n",
       "2       2013-02-22      A   27.185310   29.899857   30.092991   29.742489   \n",
       "3       2013-02-25      A   26.853619   29.535049   30.200287   29.535049   \n",
       "4       2013-02-26      A   26.645504   29.306152   29.535049   28.748213   \n",
       "...            ...    ...         ...         ...         ...         ...   \n",
       "1348219 2024-02-15    ZTS  189.649994  189.649994  190.339996  183.860001   \n",
       "1348220 2024-02-16    ZTS  188.389999  188.389999  190.350006  187.929993   \n",
       "1348221 2024-02-20    ZTS  186.550003  186.550003  189.410004  186.240005   \n",
       "1348222 2024-02-21    ZTS  188.380005  188.380005  188.860001  186.660004   \n",
       "1348223 2024-02-22    ZTS  196.660004  196.660004  196.669998  188.539993   \n",
       "\n",
       "               Open     Volume       lag_1       lag_2  ...  weekly_return  \\\n",
       "0         30.643778  5410260.0   30.765379   30.221745  ...      -0.053339   \n",
       "1         30.143063  4774450.0   30.214592   30.765379  ...      -0.069721   \n",
       "2         29.921316  4690150.0   29.778255   30.214592  ...      -0.062360   \n",
       "3         30.107296  5064255.0   29.899857   29.778255  ...      -0.022722   \n",
       "4         29.055794  8647888.0   29.535049   29.899857  ...      -0.047431   \n",
       "...             ...        ...         ...         ...  ...            ...   \n",
       "1348219  183.860001  2725600.0  184.080002  183.490005  ...      -0.031162   \n",
       "1348220  189.399994  1953700.0  189.649994  184.080002  ...      -0.045256   \n",
       "1348221  187.300003  2502800.0  188.389999  189.649994  ...      -0.051553   \n",
       "1348222  186.660004  3179300.0  186.550003  188.389999  ...       0.026650   \n",
       "1348223  189.309998  3339700.0  188.380005  186.550003  ...       0.068340   \n",
       "\n",
       "           5_day_MA   20_day_MA  5_day_volatility  momentum      MACD  \\\n",
       "0         31.020028   31.796495          0.878207 -0.550787 -0.056695   \n",
       "1         30.573677   31.701001          0.814060 -0.436337 -0.177837   \n",
       "2         30.175965   31.598712          0.382559  0.121601 -0.261022   \n",
       "3         30.038626   31.455651          0.474282 -0.364807 -0.352323   \n",
       "4         29.746781   31.305079          0.347222 -0.228897 -0.438099   \n",
       "...             ...         ...               ...       ...       ...   \n",
       "1348219  190.246002  190.657500          6.625424  5.569992 -0.425651   \n",
       "1348220  188.460001  190.658000          5.315994 -1.259995 -0.585697   \n",
       "1348221  186.432001  190.425500          2.664132 -1.839996 -0.851194   \n",
       "1348222  187.410001  190.439500          2.164911  1.830002 -0.903522   \n",
       "1348223  189.926001  190.969000          3.923319  8.279999 -0.273710   \n",
       "\n",
       "         MACD_signal  MACD_histogram  week_of_year  month  \n",
       "0           0.209343       -0.266038             8      2  \n",
       "1           0.131907       -0.309744             8      2  \n",
       "2           0.053321       -0.314343             8      2  \n",
       "3          -0.027808       -0.324515             9      2  \n",
       "4          -0.109866       -0.328233             9      2  \n",
       "...              ...             ...           ...    ...  \n",
       "1348219     0.179822       -0.605472             7      2  \n",
       "1348220     0.026718       -0.612414             7      2  \n",
       "1348221    -0.148865       -0.702330             8      2  \n",
       "1348222    -0.299796       -0.603726             8      2  \n",
       "1348223    -0.294579        0.020868             8      2  \n",
       "\n",
       "[1348224 rows x 21 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stocks.index = df_stocks.index.droplevel()\n",
    "df_stocks.reset_index(inplace=True)\n",
    "df_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "328ce613-3e11-4218-8ecc-b84b4dcb2107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>adj close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>...</th>\n",
       "      <th>weekly_return</th>\n",
       "      <th>5_day_ma</th>\n",
       "      <th>20_day_ma</th>\n",
       "      <th>5_day_volatility</th>\n",
       "      <th>momentum</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>macd_histogram</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shares of Apple (NASDAQ: AAPL) are trading dow...</td>\n",
       "      <td>2013-02-20</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>13.771608</td>\n",
       "      <td>16.030357</td>\n",
       "      <td>16.346071</td>\n",
       "      <td>16.028570</td>\n",
       "      <td>16.346071</td>\n",
       "      <td>476302400.0</td>\n",
       "      <td>16.428213</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040714</td>\n",
       "      <td>16.447143</td>\n",
       "      <td>16.481375</td>\n",
       "      <td>0.262181</td>\n",
       "      <td>-0.397856</td>\n",
       "      <td>-0.427553</td>\n",
       "      <td>-0.489380</td>\n",
       "      <td>0.061827</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shares of Apple (NASDAQ: AAPL) are trading dow...</td>\n",
       "      <td>2013-02-20</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>13.320500</td>\n",
       "      <td>13.320500</td>\n",
       "      <td>13.715000</td>\n",
       "      <td>13.318500</td>\n",
       "      <td>13.510000</td>\n",
       "      <td>70578000.0</td>\n",
       "      <td>13.487500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029803</td>\n",
       "      <td>13.399600</td>\n",
       "      <td>13.330875</td>\n",
       "      <td>0.105347</td>\n",
       "      <td>-0.167000</td>\n",
       "      <td>0.012436</td>\n",
       "      <td>-0.008985</td>\n",
       "      <td>0.021421</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boeing (NYSE: BA) and its negotiations team ar...</td>\n",
       "      <td>2013-02-20</td>\n",
       "      <td>BA</td>\n",
       "      <td>63.067375</td>\n",
       "      <td>74.779999</td>\n",
       "      <td>76.250000</td>\n",
       "      <td>74.750000</td>\n",
       "      <td>75.639999</td>\n",
       "      <td>7551300.0</td>\n",
       "      <td>74.650002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015923</td>\n",
       "      <td>74.834000</td>\n",
       "      <td>75.151500</td>\n",
       "      <td>0.147749</td>\n",
       "      <td>0.129997</td>\n",
       "      <td>-0.211090</td>\n",
       "      <td>-0.116235</td>\n",
       "      <td>-0.094855</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\r\\n\\tAlthough Congress is in recess for the w...</td>\n",
       "      <td>2013-02-20</td>\n",
       "      <td>CI</td>\n",
       "      <td>56.092823</td>\n",
       "      <td>59.270000</td>\n",
       "      <td>60.580002</td>\n",
       "      <td>59.220001</td>\n",
       "      <td>60.570000</td>\n",
       "      <td>1876800.0</td>\n",
       "      <td>60.430000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043724</td>\n",
       "      <td>60.824001</td>\n",
       "      <td>59.843500</td>\n",
       "      <td>1.020284</td>\n",
       "      <td>-1.160000</td>\n",
       "      <td>1.135656</td>\n",
       "      <td>1.358660</td>\n",
       "      <td>-0.223004</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>With the fiscal cliff having been averted, bu...</td>\n",
       "      <td>2013-02-20</td>\n",
       "      <td>COST</td>\n",
       "      <td>80.679810</td>\n",
       "      <td>101.080002</td>\n",
       "      <td>102.629997</td>\n",
       "      <td>101.050003</td>\n",
       "      <td>102.180000</td>\n",
       "      <td>1915100.0</td>\n",
       "      <td>101.900002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006682</td>\n",
       "      <td>101.759999</td>\n",
       "      <td>102.346000</td>\n",
       "      <td>0.428543</td>\n",
       "      <td>-0.820000</td>\n",
       "      <td>-0.034452</td>\n",
       "      <td>0.111248</td>\n",
       "      <td>-0.145701</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86227</th>\n",
       "      <td>On CNBCs \"Mad Money Lightning Round,\" Jim Cra...</td>\n",
       "      <td>2024-02-02</td>\n",
       "      <td>SLB</td>\n",
       "      <td>48.722450</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>49.180000</td>\n",
       "      <td>48.490002</td>\n",
       "      <td>48.900002</td>\n",
       "      <td>19020300.0</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074074</td>\n",
       "      <td>49.850000</td>\n",
       "      <td>49.987000</td>\n",
       "      <td>1.886797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.406141</td>\n",
       "      <td>-0.320799</td>\n",
       "      <td>-0.085342</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86228</th>\n",
       "      <td>Meta Platforms, Inc.(NASDAQ:META) announced o...</td>\n",
       "      <td>2024-02-02</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>187.910004</td>\n",
       "      <td>187.910004</td>\n",
       "      <td>188.690002</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>185.039993</td>\n",
       "      <td>110505100.0</td>\n",
       "      <td>188.860001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025430</td>\n",
       "      <td>189.315997</td>\n",
       "      <td>209.535501</td>\n",
       "      <td>1.875200</td>\n",
       "      <td>-0.949997</td>\n",
       "      <td>-13.777086</td>\n",
       "      <td>-12.046669</td>\n",
       "      <td>-1.730417</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86229</th>\n",
       "      <td>Billionaire Elon Musk tried to play down Apple...</td>\n",
       "      <td>2024-02-02</td>\n",
       "      <td>WBD</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>10.370000</td>\n",
       "      <td>10.130000</td>\n",
       "      <td>10.370000</td>\n",
       "      <td>16107500.0</td>\n",
       "      <td>10.460000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034840</td>\n",
       "      <td>10.264000</td>\n",
       "      <td>10.543500</td>\n",
       "      <td>0.209833</td>\n",
       "      <td>-0.210000</td>\n",
       "      <td>-0.233812</td>\n",
       "      <td>-0.223187</td>\n",
       "      <td>-0.010625</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86230</th>\n",
       "      <td>Plug Power, Inc.(NASDAQ:PLUG) shares are trad...</td>\n",
       "      <td>2024-02-02</td>\n",
       "      <td>WMT</td>\n",
       "      <td>169.570007</td>\n",
       "      <td>169.570007</td>\n",
       "      <td>170.580002</td>\n",
       "      <td>167.919998</td>\n",
       "      <td>168.149994</td>\n",
       "      <td>7218900.0</td>\n",
       "      <td>168.309998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032264</td>\n",
       "      <td>166.751999</td>\n",
       "      <td>162.653501</td>\n",
       "      <td>2.055830</td>\n",
       "      <td>1.260010</td>\n",
       "      <td>2.503528</td>\n",
       "      <td>1.903171</td>\n",
       "      <td>0.600356</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86231</th>\n",
       "      <td>With U.S. stock futures trading mostly higher ...</td>\n",
       "      <td>2024-02-02</td>\n",
       "      <td>XOM</td>\n",
       "      <td>101.031052</td>\n",
       "      <td>101.970001</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>101.610001</td>\n",
       "      <td>103.750000</td>\n",
       "      <td>21968200.0</td>\n",
       "      <td>102.389999</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>103.029999</td>\n",
       "      <td>100.177999</td>\n",
       "      <td>1.107248</td>\n",
       "      <td>-0.419998</td>\n",
       "      <td>0.469548</td>\n",
       "      <td>-0.056360</td>\n",
       "      <td>0.525908</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86232 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body       date symbol  \\\n",
       "0      Shares of Apple (NASDAQ: AAPL) are trading dow... 2013-02-20   AAPL   \n",
       "1      Shares of Apple (NASDAQ: AAPL) are trading dow... 2013-02-20   AMZN   \n",
       "2      Boeing (NYSE: BA) and its negotiations team ar... 2013-02-20     BA   \n",
       "3      \\r\\n\\tAlthough Congress is in recess for the w... 2013-02-20     CI   \n",
       "4      With the fiscal cliff having been averted, bu... 2013-02-20   COST   \n",
       "...                                                  ...        ...    ...   \n",
       "86227  On CNBCs \"Mad Money Lightning Round,\" Jim Cra... 2024-02-02    SLB   \n",
       "86228  Meta Platforms, Inc.(NASDAQ:META) announced o... 2024-02-02   TSLA   \n",
       "86229  Billionaire Elon Musk tried to play down Apple... 2024-02-02    WBD   \n",
       "86230  Plug Power, Inc.(NASDAQ:PLUG) shares are trad... 2024-02-02    WMT   \n",
       "86231  With U.S. stock futures trading mostly higher ... 2024-02-02    XOM   \n",
       "\n",
       "        adj close       close        high         low        open  \\\n",
       "0       13.771608   16.030357   16.346071   16.028570   16.346071   \n",
       "1       13.320500   13.320500   13.715000   13.318500   13.510000   \n",
       "2       63.067375   74.779999   76.250000   74.750000   75.639999   \n",
       "3       56.092823   59.270000   60.580002   59.220001   60.570000   \n",
       "4       80.679810  101.080002  102.629997  101.050003  102.180000   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "86227   48.722450   49.000000   49.180000   48.490002   48.900002   \n",
       "86228  187.910004  187.910004  188.690002  182.000000  185.039993   \n",
       "86229   10.250000   10.250000   10.370000   10.130000   10.370000   \n",
       "86230  169.570007  169.570007  170.580002  167.919998  168.149994   \n",
       "86231  101.031052  101.970001  104.000000  101.610001  103.750000   \n",
       "\n",
       "            volume       lag_1  ...  weekly_return    5_day_ma   20_day_ma  \\\n",
       "0      476302400.0   16.428213  ...      -0.040714   16.447143   16.481375   \n",
       "1       70578000.0   13.487500  ...       0.029803   13.399600   13.330875   \n",
       "2        7551300.0   74.650002  ...      -0.015923   74.834000   75.151500   \n",
       "3        1876800.0   60.430000  ...      -0.043724   60.824001   59.843500   \n",
       "4        1915100.0  101.900002  ...      -0.006682  101.759999  102.346000   \n",
       "...            ...         ...  ...            ...         ...         ...   \n",
       "86227   19020300.0   49.000000  ...      -0.074074   49.850000   49.987000   \n",
       "86228  110505100.0  188.860001  ...       0.025430  189.315997  209.535501   \n",
       "86229   16107500.0   10.460000  ...      -0.034840   10.264000   10.543500   \n",
       "86230    7218900.0  168.309998  ...       0.032264  166.751999  162.653501   \n",
       "86231   21968200.0  102.389999  ...      -0.010000  103.029999  100.177999   \n",
       "\n",
       "       5_day_volatility  momentum       macd  macd_signal  macd_histogram  \\\n",
       "0              0.262181 -0.397856  -0.427553    -0.489380        0.061827   \n",
       "1              0.105347 -0.167000   0.012436    -0.008985        0.021421   \n",
       "2              0.147749  0.129997  -0.211090    -0.116235       -0.094855   \n",
       "3              1.020284 -1.160000   1.135656     1.358660       -0.223004   \n",
       "4              0.428543 -0.820000  -0.034452     0.111248       -0.145701   \n",
       "...                 ...       ...        ...          ...             ...   \n",
       "86227          1.886797  0.000000  -0.406141    -0.320799       -0.085342   \n",
       "86228          1.875200 -0.949997 -13.777086   -12.046669       -1.730417   \n",
       "86229          0.209833 -0.210000  -0.233812    -0.223187       -0.010625   \n",
       "86230          2.055830  1.260010   2.503528     1.903171        0.600356   \n",
       "86231          1.107248 -0.419998   0.469548    -0.056360        0.525908   \n",
       "\n",
       "       week_of_year  month  \n",
       "0                 8      2  \n",
       "1                 8      2  \n",
       "2                 8      2  \n",
       "3                 8      2  \n",
       "4                 8      2  \n",
       "...             ...    ...  \n",
       "86227             5      2  \n",
       "86228             5      2  \n",
       "86229             5      2  \n",
       "86230             5      2  \n",
       "86231             5      2  \n",
       "\n",
       "[86232 rows x 22 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_news_daily.merge(df_stocks,\n",
    "                                how='inner',\n",
    "                                left_on=['updated', 'stocks'],\n",
    "                                right_on=['Date', 'Symbol'])\n",
    "\n",
    "\n",
    "df_merged.drop(['stocks', 'updated'], axis=1, inplace=True)\n",
    "df_merged.columns = df_merged.columns.str.lower()\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "14e70845-daed-40d3-9886-0f94ceaabea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_wordlist(text, remove_stop_words=True, stem_words=False): \n",
    "    text = text.replace('\\n', '')\n",
    "    text = text.replace('\\r', '')\n",
    "    text = re.sub(r\"[^A-Za-z0-9]\", \" \", text).lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation from text\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "    if remove_stop_words:\n",
    "        stop_words = set(stopwords.words(\"english\")) \n",
    "        word_tokens = word_tokenize(text) \n",
    "        text = [word for word in word_tokens if word not in stop_words] \n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "    if stem_words:\n",
    "        # text = text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        text = [stemmer.stem(word) for word in text]\n",
    "    \n",
    "    # Return a list of words\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4a21ea8d-4591-42c2-832c-65cf75e4f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect \n",
    "q = inflect.engine() \n",
    "  \n",
    "def is_digit(string):\n",
    "    try:\n",
    "        float(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False \n",
    "        \n",
    "def convert_num(text): \n",
    "    # split strings into list of texts \n",
    "    # temp_string = text.split() \n",
    "    # initialise empty list \n",
    "    new_str = [] \n",
    "  \n",
    "    for word in text: \n",
    "        # if text is a digit, convert the digit \n",
    "        # to numbers and append into the new_str list \n",
    "        if is_digit(word): \n",
    "            temp = q.number_to_words(word) \n",
    "            new_str.append(temp) \n",
    "  \n",
    "        # append the texts as it is \n",
    "        else: \n",
    "            new_str.append(word) \n",
    "  \n",
    "    # join the texts of new_str to form a string \n",
    "    temp_str = ' '.join(new_str) \n",
    "    return temp_str \n",
    "\n",
    "\n",
    "\n",
    "def text_to_wordlist(text, remove_stop_words=True, stem_words=False, convert_numbers=True): \n",
    "    text = text.replace('\\n', '')\n",
    "    text = text.replace('\\r', '')\n",
    "    text = re.sub(r\"[^A-Za-z0-9]\", \" \", text).lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation from text\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "    if remove_stop_words:\n",
    "        stop_words = set(stopwords.words(\"english\")) \n",
    "        word_tokens = word_tokenize(text) \n",
    "        text = [word for word in word_tokens if word not in stop_words] \n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "    if stem_words:\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        text = [stemmer.stem(word) for word in text]\n",
    "        \n",
    "    if convert_numbers:\n",
    "        text = convert_num(text)\n",
    "        \n",
    "    # Return a list of words\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8e61efd8-30f3-49a1-bbc2-e4a90b76b2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 8s, sys: 4.25 s, total: 15min 12s\n",
      "Wall time: 15min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_merged['body_preprocessed'] = df_merged['body'].apply(lambda x: text_to_wordlist(x, stem_words=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7c4eaa87-12c3-4fcd-87a8-d4cfd79c056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop('body', axis=1).to_csv('datasets/df_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "de15f128-7f23-4cc0-b556-46c87d9e9fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "750a1108-e1f7-460b-b31d-e525bd295abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop(\"body\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "4d81ab0d-914d-43c0-a53e-85edb60ad3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.2 ms, sys: 23.5 ms, total: 45.8 ms\n",
      "Wall time: 52.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_merged.drop(['date', 'symbol', 'weekly_return'], axis=1),\n",
    "                                                    df_merged[\"weekly_return\"],\n",
    "                                                    test_size=0.3)\n",
    "\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train[\"body_preprocessed\"])\n",
    "X_test = vectorizer.transform(X_test[\"body_preprocessed\"])\n",
    "\n",
    "\n",
    "model = CatBoostRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "scores = {\n",
    "    'mean_squared_error': mean_squared_error(y_test, model.predict(X_test)),\n",
    "    'mean_absolute_percentage_error': mean_absolute_percentage_error(y_test, model.predict(X_test)),\n",
    "    'r2': r2_score(y_test, model.predict(X_test)),\n",
    "}\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "13f7f2a4-97d6-4215-b53e-f8ed2c5d1891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.07826\n",
      "0:\tlearn: 0.0594483\ttotal: 1.22s\tremaining: 20m 13s\n",
      "1:\tlearn: 0.0572738\ttotal: 2.14s\tremaining: 17m 49s\n",
      "2:\tlearn: 0.0552361\ttotal: 3.1s\tremaining: 17m 11s\n",
      "3:\tlearn: 0.0534326\ttotal: 4.11s\tremaining: 17m 2s\n",
      "4:\tlearn: 0.0517727\ttotal: 5.2s\tremaining: 17m 14s\n",
      "5:\tlearn: 0.0503338\ttotal: 6.21s\tremaining: 17m 9s\n",
      "6:\tlearn: 0.0491500\ttotal: 7.27s\tremaining: 17m 10s\n",
      "7:\tlearn: 0.0479706\ttotal: 8.3s\tremaining: 17m 9s\n",
      "8:\tlearn: 0.0468571\ttotal: 9.26s\tremaining: 16m 59s\n",
      "9:\tlearn: 0.0457921\ttotal: 10.2s\tremaining: 16m 52s\n",
      "10:\tlearn: 0.0448724\ttotal: 11.3s\tremaining: 16m 54s\n",
      "11:\tlearn: 0.0440140\ttotal: 12.3s\tremaining: 16m 53s\n",
      "12:\tlearn: 0.0431950\ttotal: 13.2s\tremaining: 16m 44s\n",
      "13:\tlearn: 0.0424706\ttotal: 14.2s\tremaining: 16m 38s\n",
      "14:\tlearn: 0.0417427\ttotal: 15.2s\tremaining: 16m 36s\n",
      "15:\tlearn: 0.0411340\ttotal: 16.2s\tremaining: 16m 37s\n",
      "16:\tlearn: 0.0405875\ttotal: 17.3s\tremaining: 16m 37s\n",
      "17:\tlearn: 0.0399826\ttotal: 18.2s\tremaining: 16m 30s\n",
      "18:\tlearn: 0.0394867\ttotal: 19.1s\tremaining: 16m 27s\n",
      "19:\tlearn: 0.0389929\ttotal: 20.1s\tremaining: 16m 25s\n",
      "20:\tlearn: 0.0385071\ttotal: 21.2s\tremaining: 16m 27s\n",
      "21:\tlearn: 0.0380655\ttotal: 22.2s\tremaining: 16m 25s\n",
      "22:\tlearn: 0.0377057\ttotal: 23.2s\tremaining: 16m 25s\n",
      "23:\tlearn: 0.0372865\ttotal: 24.3s\tremaining: 16m 26s\n",
      "24:\tlearn: 0.0370067\ttotal: 25.3s\tremaining: 16m 27s\n",
      "25:\tlearn: 0.0367007\ttotal: 26.3s\tremaining: 16m 26s\n",
      "26:\tlearn: 0.0363480\ttotal: 27.3s\tremaining: 16m 23s\n",
      "27:\tlearn: 0.0361107\ttotal: 28.3s\tremaining: 16m 23s\n",
      "28:\tlearn: 0.0358339\ttotal: 29.2s\tremaining: 16m 19s\n",
      "29:\tlearn: 0.0355480\ttotal: 30.3s\tremaining: 16m 21s\n",
      "30:\tlearn: 0.0353418\ttotal: 31.3s\tremaining: 16m 18s\n",
      "31:\tlearn: 0.0351351\ttotal: 32.4s\tremaining: 16m 21s\n",
      "32:\tlearn: 0.0348968\ttotal: 33.5s\tremaining: 16m 21s\n",
      "33:\tlearn: 0.0346986\ttotal: 34.6s\tremaining: 16m 21s\n",
      "34:\tlearn: 0.0344957\ttotal: 35.6s\tremaining: 16m 22s\n",
      "35:\tlearn: 0.0343526\ttotal: 36.7s\tremaining: 16m 22s\n",
      "36:\tlearn: 0.0342562\ttotal: 37.7s\tremaining: 16m 20s\n",
      "37:\tlearn: 0.0340752\ttotal: 38.6s\tremaining: 16m 18s\n",
      "38:\tlearn: 0.0338730\ttotal: 39.7s\tremaining: 16m 18s\n",
      "39:\tlearn: 0.0337802\ttotal: 40.8s\tremaining: 16m 18s\n",
      "40:\tlearn: 0.0336274\ttotal: 41.9s\tremaining: 16m 19s\n",
      "41:\tlearn: 0.0334932\ttotal: 43s\tremaining: 16m 21s\n",
      "42:\tlearn: 0.0334206\ttotal: 44.1s\tremaining: 16m 21s\n",
      "43:\tlearn: 0.0332232\ttotal: 45.3s\tremaining: 16m 23s\n",
      "44:\tlearn: 0.0331053\ttotal: 46.3s\tremaining: 16m 22s\n",
      "45:\tlearn: 0.0330344\ttotal: 47.4s\tremaining: 16m 23s\n",
      "46:\tlearn: 0.0329196\ttotal: 48.4s\tremaining: 16m 21s\n",
      "47:\tlearn: 0.0328037\ttotal: 49.6s\tremaining: 16m 23s\n",
      "48:\tlearn: 0.0326266\ttotal: 50.8s\tremaining: 16m 26s\n",
      "49:\tlearn: 0.0325756\ttotal: 52s\tremaining: 16m 27s\n",
      "50:\tlearn: 0.0325347\ttotal: 52.9s\tremaining: 16m 25s\n",
      "51:\tlearn: 0.0324866\ttotal: 54s\tremaining: 16m 25s\n",
      "52:\tlearn: 0.0324277\ttotal: 55.2s\tremaining: 16m 25s\n",
      "53:\tlearn: 0.0322897\ttotal: 56.4s\tremaining: 16m 27s\n",
      "54:\tlearn: 0.0322627\ttotal: 57.3s\tremaining: 16m 24s\n",
      "55:\tlearn: 0.0321912\ttotal: 58.4s\tremaining: 16m 23s\n",
      "56:\tlearn: 0.0320921\ttotal: 59.6s\tremaining: 16m 25s\n",
      "57:\tlearn: 0.0320820\ttotal: 1m\tremaining: 16m 26s\n",
      "58:\tlearn: 0.0320711\ttotal: 1m 1s\tremaining: 16m 24s\n",
      "59:\tlearn: 0.0320365\ttotal: 1m 2s\tremaining: 16m 26s\n",
      "60:\tlearn: 0.0320304\ttotal: 1m 3s\tremaining: 16m 23s\n",
      "61:\tlearn: 0.0319726\ttotal: 1m 4s\tremaining: 16m 23s\n",
      "62:\tlearn: 0.0318774\ttotal: 1m 5s\tremaining: 16m 21s\n",
      "63:\tlearn: 0.0317768\ttotal: 1m 7s\tremaining: 16m 20s\n",
      "64:\tlearn: 0.0316401\ttotal: 1m 8s\tremaining: 16m 20s\n",
      "65:\tlearn: 0.0316070\ttotal: 1m 9s\tremaining: 16m 19s\n",
      "66:\tlearn: 0.0315986\ttotal: 1m 10s\tremaining: 16m 15s\n",
      "67:\tlearn: 0.0314902\ttotal: 1m 11s\tremaining: 16m 15s\n",
      "68:\tlearn: 0.0313848\ttotal: 1m 12s\tremaining: 16m 14s\n",
      "69:\tlearn: 0.0313777\ttotal: 1m 13s\tremaining: 16m 14s\n",
      "70:\tlearn: 0.0313696\ttotal: 1m 14s\tremaining: 16m 13s\n",
      "71:\tlearn: 0.0313548\ttotal: 1m 15s\tremaining: 16m 13s\n",
      "72:\tlearn: 0.0313492\ttotal: 1m 16s\tremaining: 16m 11s\n",
      "73:\tlearn: 0.0312664\ttotal: 1m 17s\tremaining: 16m 13s\n",
      "74:\tlearn: 0.0311889\ttotal: 1m 18s\tremaining: 16m 12s\n",
      "75:\tlearn: 0.0311578\ttotal: 1m 19s\tremaining: 16m 11s\n",
      "76:\tlearn: 0.0311503\ttotal: 1m 20s\tremaining: 16m 10s\n",
      "77:\tlearn: 0.0310800\ttotal: 1m 21s\tremaining: 16m 7s\n",
      "78:\tlearn: 0.0309970\ttotal: 1m 23s\tremaining: 16m 8s\n",
      "79:\tlearn: 0.0309196\ttotal: 1m 24s\tremaining: 16m 6s\n",
      "80:\tlearn: 0.0309117\ttotal: 1m 24s\tremaining: 16m 4s\n",
      "81:\tlearn: 0.0309056\ttotal: 1m 26s\tremaining: 16m 3s\n",
      "82:\tlearn: 0.0308371\ttotal: 1m 27s\tremaining: 16m 2s\n",
      "83:\tlearn: 0.0307440\ttotal: 1m 28s\tremaining: 16m 3s\n",
      "84:\tlearn: 0.0306643\ttotal: 1m 29s\tremaining: 16m 1s\n",
      "85:\tlearn: 0.0305828\ttotal: 1m 30s\tremaining: 16m\n",
      "86:\tlearn: 0.0305534\ttotal: 1m 31s\tremaining: 15m 58s\n",
      "87:\tlearn: 0.0305152\ttotal: 1m 32s\tremaining: 15m 56s\n",
      "88:\tlearn: 0.0304896\ttotal: 1m 33s\tremaining: 15m 53s\n",
      "89:\tlearn: 0.0304153\ttotal: 1m 34s\tremaining: 15m 52s\n",
      "90:\tlearn: 0.0303334\ttotal: 1m 35s\tremaining: 15m 51s\n",
      "91:\tlearn: 0.0302962\ttotal: 1m 36s\tremaining: 15m 49s\n",
      "92:\tlearn: 0.0302907\ttotal: 1m 37s\tremaining: 15m 48s\n",
      "93:\tlearn: 0.0302708\ttotal: 1m 38s\tremaining: 15m 46s\n",
      "94:\tlearn: 0.0302540\ttotal: 1m 39s\tremaining: 15m 44s\n",
      "95:\tlearn: 0.0302264\ttotal: 1m 39s\tremaining: 15m 41s\n",
      "96:\tlearn: 0.0302018\ttotal: 1m 40s\tremaining: 15m 38s\n",
      "97:\tlearn: 0.0301969\ttotal: 1m 41s\tremaining: 15m 36s\n",
      "98:\tlearn: 0.0301442\ttotal: 1m 42s\tremaining: 15m 35s\n",
      "99:\tlearn: 0.0301402\ttotal: 1m 43s\tremaining: 15m 33s\n",
      "100:\tlearn: 0.0301360\ttotal: 1m 44s\tremaining: 15m 32s\n",
      "101:\tlearn: 0.0300525\ttotal: 1m 45s\tremaining: 15m 31s\n",
      "102:\tlearn: 0.0300472\ttotal: 1m 46s\tremaining: 15m 29s\n",
      "103:\tlearn: 0.0299675\ttotal: 1m 47s\tremaining: 15m 29s\n",
      "104:\tlearn: 0.0299221\ttotal: 1m 48s\tremaining: 15m 28s\n",
      "105:\tlearn: 0.0298790\ttotal: 1m 50s\tremaining: 15m 28s\n",
      "106:\tlearn: 0.0298152\ttotal: 1m 51s\tremaining: 15m 26s\n",
      "107:\tlearn: 0.0297855\ttotal: 1m 51s\tremaining: 15m 24s\n",
      "108:\tlearn: 0.0297611\ttotal: 1m 52s\tremaining: 15m 21s\n",
      "109:\tlearn: 0.0297022\ttotal: 1m 53s\tremaining: 15m 20s\n",
      "110:\tlearn: 0.0296811\ttotal: 1m 54s\tremaining: 15m 18s\n",
      "111:\tlearn: 0.0296628\ttotal: 1m 55s\tremaining: 15m 16s\n",
      "112:\tlearn: 0.0296221\ttotal: 1m 56s\tremaining: 15m 14s\n",
      "113:\tlearn: 0.0295893\ttotal: 1m 57s\tremaining: 15m 12s\n",
      "114:\tlearn: 0.0295610\ttotal: 1m 58s\tremaining: 15m 10s\n",
      "115:\tlearn: 0.0295246\ttotal: 1m 59s\tremaining: 15m 8s\n",
      "116:\tlearn: 0.0295059\ttotal: 2m\tremaining: 15m 6s\n",
      "117:\tlearn: 0.0294941\ttotal: 2m 1s\tremaining: 15m 5s\n",
      "118:\tlearn: 0.0294747\ttotal: 2m 2s\tremaining: 15m 4s\n",
      "119:\tlearn: 0.0294520\ttotal: 2m 3s\tremaining: 15m 3s\n",
      "120:\tlearn: 0.0294038\ttotal: 2m 4s\tremaining: 15m 2s\n",
      "121:\tlearn: 0.0293987\ttotal: 2m 5s\tremaining: 15m 2s\n",
      "122:\tlearn: 0.0293947\ttotal: 2m 6s\tremaining: 15m 1s\n",
      "123:\tlearn: 0.0293756\ttotal: 2m 7s\tremaining: 15m\n",
      "124:\tlearn: 0.0293686\ttotal: 2m 8s\tremaining: 14m 58s\n",
      "125:\tlearn: 0.0293390\ttotal: 2m 9s\tremaining: 14m 57s\n",
      "126:\tlearn: 0.0292749\ttotal: 2m 10s\tremaining: 14m 56s\n",
      "127:\tlearn: 0.0292181\ttotal: 2m 11s\tremaining: 14m 55s\n",
      "128:\tlearn: 0.0292135\ttotal: 2m 12s\tremaining: 14m 53s\n",
      "129:\tlearn: 0.0292105\ttotal: 2m 13s\tremaining: 14m 52s\n",
      "130:\tlearn: 0.0292048\ttotal: 2m 14s\tremaining: 14m 51s\n",
      "131:\tlearn: 0.0291402\ttotal: 2m 15s\tremaining: 14m 51s\n",
      "132:\tlearn: 0.0290875\ttotal: 2m 16s\tremaining: 14m 51s\n",
      "133:\tlearn: 0.0290833\ttotal: 2m 17s\tremaining: 14m 49s\n",
      "134:\tlearn: 0.0290561\ttotal: 2m 18s\tremaining: 14m 49s\n",
      "135:\tlearn: 0.0290483\ttotal: 2m 19s\tremaining: 14m 47s\n",
      "136:\tlearn: 0.0290033\ttotal: 2m 21s\tremaining: 14m 48s\n",
      "137:\tlearn: 0.0289680\ttotal: 2m 22s\tremaining: 14m 47s\n",
      "138:\tlearn: 0.0289297\ttotal: 2m 23s\tremaining: 14m 47s\n",
      "139:\tlearn: 0.0288891\ttotal: 2m 24s\tremaining: 14m 46s\n",
      "140:\tlearn: 0.0288612\ttotal: 2m 25s\tremaining: 14m 46s\n",
      "141:\tlearn: 0.0288037\ttotal: 2m 26s\tremaining: 14m 45s\n",
      "142:\tlearn: 0.0287921\ttotal: 2m 27s\tremaining: 14m 44s\n",
      "143:\tlearn: 0.0287262\ttotal: 2m 28s\tremaining: 14m 44s\n",
      "144:\tlearn: 0.0286984\ttotal: 2m 29s\tremaining: 14m 43s\n",
      "145:\tlearn: 0.0286697\ttotal: 2m 30s\tremaining: 14m 42s\n",
      "146:\tlearn: 0.0286314\ttotal: 2m 31s\tremaining: 14m 41s\n",
      "147:\tlearn: 0.0285948\ttotal: 2m 33s\tremaining: 14m 40s\n",
      "148:\tlearn: 0.0285663\ttotal: 2m 34s\tremaining: 14m 40s\n",
      "149:\tlearn: 0.0285114\ttotal: 2m 35s\tremaining: 14m 39s\n",
      "150:\tlearn: 0.0284785\ttotal: 2m 36s\tremaining: 14m 37s\n",
      "151:\tlearn: 0.0284486\ttotal: 2m 36s\tremaining: 14m 35s\n",
      "152:\tlearn: 0.0284355\ttotal: 2m 37s\tremaining: 14m 34s\n",
      "153:\tlearn: 0.0284097\ttotal: 2m 38s\tremaining: 14m 33s\n",
      "154:\tlearn: 0.0283957\ttotal: 2m 39s\tremaining: 14m 31s\n",
      "155:\tlearn: 0.0283871\ttotal: 2m 40s\tremaining: 14m 29s\n",
      "156:\tlearn: 0.0283459\ttotal: 2m 41s\tremaining: 14m 28s\n",
      "157:\tlearn: 0.0283378\ttotal: 2m 42s\tremaining: 14m 26s\n",
      "158:\tlearn: 0.0283316\ttotal: 2m 43s\tremaining: 14m 24s\n",
      "159:\tlearn: 0.0283121\ttotal: 2m 44s\tremaining: 14m 23s\n",
      "160:\tlearn: 0.0282914\ttotal: 2m 45s\tremaining: 14m 21s\n",
      "161:\tlearn: 0.0282879\ttotal: 2m 46s\tremaining: 14m 19s\n",
      "162:\tlearn: 0.0282503\ttotal: 2m 47s\tremaining: 14m 19s\n",
      "163:\tlearn: 0.0282383\ttotal: 2m 48s\tremaining: 14m 17s\n",
      "164:\tlearn: 0.0282038\ttotal: 2m 49s\tremaining: 14m 16s\n",
      "165:\tlearn: 0.0281990\ttotal: 2m 50s\tremaining: 14m 14s\n",
      "166:\tlearn: 0.0281829\ttotal: 2m 51s\tremaining: 14m 14s\n",
      "167:\tlearn: 0.0281759\ttotal: 2m 52s\tremaining: 14m 13s\n",
      "168:\tlearn: 0.0281619\ttotal: 2m 53s\tremaining: 14m 12s\n",
      "169:\tlearn: 0.0281414\ttotal: 2m 54s\tremaining: 14m 10s\n",
      "170:\tlearn: 0.0281352\ttotal: 2m 55s\tremaining: 14m 8s\n",
      "171:\tlearn: 0.0280936\ttotal: 2m 56s\tremaining: 14m 8s\n",
      "172:\tlearn: 0.0280901\ttotal: 2m 57s\tremaining: 14m 6s\n",
      "173:\tlearn: 0.0280638\ttotal: 2m 58s\tremaining: 14m 5s\n",
      "174:\tlearn: 0.0280604\ttotal: 2m 58s\tremaining: 14m 3s\n",
      "175:\tlearn: 0.0280101\ttotal: 3m\tremaining: 14m 2s\n",
      "176:\tlearn: 0.0279864\ttotal: 3m 1s\tremaining: 14m 1s\n",
      "177:\tlearn: 0.0279556\ttotal: 3m 2s\tremaining: 14m 1s\n",
      "178:\tlearn: 0.0279392\ttotal: 3m 3s\tremaining: 13m 59s\n",
      "179:\tlearn: 0.0279236\ttotal: 3m 4s\tremaining: 13m 58s\n",
      "180:\tlearn: 0.0279097\ttotal: 3m 5s\tremaining: 13m 57s\n",
      "181:\tlearn: 0.0279038\ttotal: 3m 5s\tremaining: 13m 55s\n",
      "182:\tlearn: 0.0278913\ttotal: 3m 6s\tremaining: 13m 53s\n",
      "183:\tlearn: 0.0278464\ttotal: 3m 7s\tremaining: 13m 52s\n",
      "184:\tlearn: 0.0278363\ttotal: 3m 8s\tremaining: 13m 50s\n",
      "185:\tlearn: 0.0278004\ttotal: 3m 9s\tremaining: 13m 49s\n",
      "186:\tlearn: 0.0277645\ttotal: 3m 10s\tremaining: 13m 48s\n",
      "187:\tlearn: 0.0277550\ttotal: 3m 11s\tremaining: 13m 46s\n",
      "188:\tlearn: 0.0277089\ttotal: 3m 12s\tremaining: 13m 45s\n",
      "189:\tlearn: 0.0276970\ttotal: 3m 13s\tremaining: 13m 43s\n",
      "190:\tlearn: 0.0276628\ttotal: 3m 14s\tremaining: 13m 42s\n",
      "191:\tlearn: 0.0276468\ttotal: 3m 15s\tremaining: 13m 40s\n",
      "192:\tlearn: 0.0276413\ttotal: 3m 15s\tremaining: 13m 38s\n",
      "193:\tlearn: 0.0276380\ttotal: 3m 16s\tremaining: 13m 37s\n",
      "194:\tlearn: 0.0276211\ttotal: 3m 17s\tremaining: 13m 35s\n",
      "195:\tlearn: 0.0276179\ttotal: 3m 18s\tremaining: 13m 33s\n",
      "196:\tlearn: 0.0276102\ttotal: 3m 19s\tremaining: 13m 32s\n",
      "197:\tlearn: 0.0276053\ttotal: 3m 20s\tremaining: 13m 30s\n",
      "198:\tlearn: 0.0275812\ttotal: 3m 21s\tremaining: 13m 29s\n",
      "199:\tlearn: 0.0275651\ttotal: 3m 22s\tremaining: 13m 28s\n",
      "200:\tlearn: 0.0275621\ttotal: 3m 22s\tremaining: 13m 26s\n",
      "201:\tlearn: 0.0275415\ttotal: 3m 23s\tremaining: 13m 25s\n",
      "202:\tlearn: 0.0275382\ttotal: 3m 24s\tremaining: 13m 23s\n",
      "203:\tlearn: 0.0275319\ttotal: 3m 25s\tremaining: 13m 22s\n",
      "204:\tlearn: 0.0275287\ttotal: 3m 26s\tremaining: 13m 20s\n",
      "205:\tlearn: 0.0275162\ttotal: 3m 27s\tremaining: 13m 19s\n",
      "206:\tlearn: 0.0275131\ttotal: 3m 28s\tremaining: 13m 17s\n",
      "207:\tlearn: 0.0275069\ttotal: 3m 29s\tremaining: 13m 16s\n",
      "208:\tlearn: 0.0274736\ttotal: 3m 30s\tremaining: 13m 15s\n",
      "209:\tlearn: 0.0274707\ttotal: 3m 30s\tremaining: 13m 13s\n",
      "210:\tlearn: 0.0274602\ttotal: 3m 31s\tremaining: 13m 11s\n",
      "211:\tlearn: 0.0274510\ttotal: 3m 32s\tremaining: 13m 9s\n",
      "212:\tlearn: 0.0274267\ttotal: 3m 33s\tremaining: 13m 8s\n",
      "213:\tlearn: 0.0273899\ttotal: 3m 34s\tremaining: 13m 7s\n",
      "214:\tlearn: 0.0273431\ttotal: 3m 35s\tremaining: 13m 6s\n",
      "215:\tlearn: 0.0273383\ttotal: 3m 36s\tremaining: 13m 4s\n",
      "216:\tlearn: 0.0273261\ttotal: 3m 36s\tremaining: 13m 2s\n",
      "217:\tlearn: 0.0272930\ttotal: 3m 37s\tremaining: 13m\n",
      "218:\tlearn: 0.0272707\ttotal: 3m 38s\tremaining: 12m 58s\n",
      "219:\tlearn: 0.0272508\ttotal: 3m 39s\tremaining: 12m 56s\n",
      "220:\tlearn: 0.0272464\ttotal: 3m 39s\tremaining: 12m 54s\n",
      "221:\tlearn: 0.0272183\ttotal: 3m 40s\tremaining: 12m 53s\n",
      "222:\tlearn: 0.0272077\ttotal: 3m 41s\tremaining: 12m 52s\n",
      "223:\tlearn: 0.0271985\ttotal: 3m 42s\tremaining: 12m 50s\n",
      "224:\tlearn: 0.0271857\ttotal: 3m 43s\tremaining: 12m 49s\n",
      "225:\tlearn: 0.0271720\ttotal: 3m 44s\tremaining: 12m 47s\n",
      "226:\tlearn: 0.0271636\ttotal: 3m 44s\tremaining: 12m 45s\n",
      "227:\tlearn: 0.0271486\ttotal: 3m 45s\tremaining: 12m 44s\n",
      "228:\tlearn: 0.0271359\ttotal: 3m 46s\tremaining: 12m 43s\n",
      "229:\tlearn: 0.0271268\ttotal: 3m 47s\tremaining: 12m 41s\n",
      "230:\tlearn: 0.0271120\ttotal: 3m 48s\tremaining: 12m 40s\n",
      "231:\tlearn: 0.0270949\ttotal: 3m 49s\tremaining: 12m 39s\n",
      "232:\tlearn: 0.0270886\ttotal: 3m 50s\tremaining: 12m 38s\n",
      "233:\tlearn: 0.0270591\ttotal: 3m 51s\tremaining: 12m 36s\n",
      "234:\tlearn: 0.0270372\ttotal: 3m 52s\tremaining: 12m 35s\n",
      "235:\tlearn: 0.0270330\ttotal: 3m 52s\tremaining: 12m 33s\n",
      "236:\tlearn: 0.0269969\ttotal: 3m 53s\tremaining: 12m 32s\n",
      "237:\tlearn: 0.0269778\ttotal: 3m 54s\tremaining: 12m 31s\n",
      "238:\tlearn: 0.0269538\ttotal: 3m 55s\tremaining: 12m 30s\n",
      "239:\tlearn: 0.0269402\ttotal: 3m 56s\tremaining: 12m 29s\n",
      "240:\tlearn: 0.0269200\ttotal: 3m 57s\tremaining: 12m 27s\n",
      "241:\tlearn: 0.0269147\ttotal: 3m 58s\tremaining: 12m 26s\n",
      "242:\tlearn: 0.0269121\ttotal: 3m 59s\tremaining: 12m 24s\n",
      "243:\tlearn: 0.0268949\ttotal: 3m 59s\tremaining: 12m 23s\n",
      "244:\tlearn: 0.0268824\ttotal: 4m\tremaining: 12m 21s\n",
      "245:\tlearn: 0.0268622\ttotal: 4m 1s\tremaining: 12m 20s\n",
      "246:\tlearn: 0.0268327\ttotal: 4m 2s\tremaining: 12m 20s\n",
      "247:\tlearn: 0.0268285\ttotal: 4m 3s\tremaining: 12m 19s\n",
      "248:\tlearn: 0.0268097\ttotal: 4m 4s\tremaining: 12m 18s\n",
      "249:\tlearn: 0.0268042\ttotal: 4m 5s\tremaining: 12m 17s\n",
      "250:\tlearn: 0.0267806\ttotal: 4m 6s\tremaining: 12m 16s\n",
      "251:\tlearn: 0.0267691\ttotal: 4m 7s\tremaining: 12m 15s\n",
      "252:\tlearn: 0.0267549\ttotal: 4m 8s\tremaining: 12m 14s\n",
      "253:\tlearn: 0.0267492\ttotal: 4m 9s\tremaining: 12m 13s\n",
      "254:\tlearn: 0.0267329\ttotal: 4m 10s\tremaining: 12m 11s\n",
      "255:\tlearn: 0.0267143\ttotal: 4m 11s\tremaining: 12m 10s\n",
      "256:\tlearn: 0.0266982\ttotal: 4m 12s\tremaining: 12m 9s\n",
      "257:\tlearn: 0.0266956\ttotal: 4m 13s\tremaining: 12m 7s\n",
      "258:\tlearn: 0.0266810\ttotal: 4m 13s\tremaining: 12m 6s\n",
      "259:\tlearn: 0.0266778\ttotal: 4m 14s\tremaining: 12m 5s\n",
      "260:\tlearn: 0.0266685\ttotal: 4m 15s\tremaining: 12m 4s\n",
      "261:\tlearn: 0.0266583\ttotal: 4m 16s\tremaining: 12m 2s\n",
      "262:\tlearn: 0.0266514\ttotal: 4m 17s\tremaining: 12m 1s\n",
      "263:\tlearn: 0.0266489\ttotal: 4m 18s\tremaining: 12m\n",
      "264:\tlearn: 0.0266332\ttotal: 4m 19s\tremaining: 11m 59s\n",
      "265:\tlearn: 0.0266249\ttotal: 4m 20s\tremaining: 11m 58s\n",
      "266:\tlearn: 0.0266171\ttotal: 4m 21s\tremaining: 11m 57s\n",
      "267:\tlearn: 0.0266043\ttotal: 4m 22s\tremaining: 11m 56s\n",
      "268:\tlearn: 0.0265921\ttotal: 4m 23s\tremaining: 11m 55s\n",
      "269:\tlearn: 0.0265882\ttotal: 4m 24s\tremaining: 11m 54s\n",
      "270:\tlearn: 0.0265824\ttotal: 4m 25s\tremaining: 11m 53s\n",
      "271:\tlearn: 0.0265800\ttotal: 4m 26s\tremaining: 11m 52s\n",
      "272:\tlearn: 0.0265756\ttotal: 4m 26s\tremaining: 11m 50s\n",
      "273:\tlearn: 0.0265622\ttotal: 4m 27s\tremaining: 11m 49s\n",
      "274:\tlearn: 0.0265519\ttotal: 4m 28s\tremaining: 11m 48s\n",
      "275:\tlearn: 0.0265283\ttotal: 4m 29s\tremaining: 11m 47s\n",
      "276:\tlearn: 0.0265220\ttotal: 4m 30s\tremaining: 11m 46s\n",
      "277:\tlearn: 0.0264883\ttotal: 4m 31s\tremaining: 11m 45s\n",
      "278:\tlearn: 0.0264817\ttotal: 4m 32s\tremaining: 11m 44s\n",
      "279:\tlearn: 0.0264785\ttotal: 4m 33s\tremaining: 11m 43s\n",
      "280:\tlearn: 0.0264761\ttotal: 4m 34s\tremaining: 11m 42s\n",
      "281:\tlearn: 0.0264647\ttotal: 4m 35s\tremaining: 11m 41s\n",
      "282:\tlearn: 0.0264550\ttotal: 4m 36s\tremaining: 11m 39s\n",
      "283:\tlearn: 0.0264487\ttotal: 4m 37s\tremaining: 11m 38s\n",
      "284:\tlearn: 0.0264442\ttotal: 4m 38s\tremaining: 11m 37s\n",
      "285:\tlearn: 0.0264418\ttotal: 4m 38s\tremaining: 11m 36s\n",
      "286:\tlearn: 0.0264396\ttotal: 4m 39s\tremaining: 11m 34s\n",
      "287:\tlearn: 0.0264318\ttotal: 4m 40s\tremaining: 11m 33s\n",
      "288:\tlearn: 0.0264210\ttotal: 4m 41s\tremaining: 11m 32s\n",
      "289:\tlearn: 0.0264072\ttotal: 4m 42s\tremaining: 11m 31s\n",
      "290:\tlearn: 0.0263986\ttotal: 4m 43s\tremaining: 11m 30s\n",
      "291:\tlearn: 0.0263949\ttotal: 4m 44s\tremaining: 11m 29s\n",
      "292:\tlearn: 0.0263853\ttotal: 4m 45s\tremaining: 11m 28s\n",
      "293:\tlearn: 0.0263808\ttotal: 4m 46s\tremaining: 11m 26s\n",
      "294:\tlearn: 0.0263770\ttotal: 4m 46s\tremaining: 11m 25s\n",
      "295:\tlearn: 0.0263747\ttotal: 4m 47s\tremaining: 11m 24s\n",
      "296:\tlearn: 0.0263701\ttotal: 4m 48s\tremaining: 11m 23s\n",
      "297:\tlearn: 0.0263679\ttotal: 4m 49s\tremaining: 11m 22s\n",
      "298:\tlearn: 0.0263624\ttotal: 4m 50s\tremaining: 11m 21s\n",
      "299:\tlearn: 0.0263587\ttotal: 4m 51s\tremaining: 11m 20s\n",
      "300:\tlearn: 0.0263538\ttotal: 4m 52s\tremaining: 11m 18s\n",
      "301:\tlearn: 0.0263245\ttotal: 4m 53s\tremaining: 11m 17s\n",
      "302:\tlearn: 0.0263072\ttotal: 4m 54s\tremaining: 11m 17s\n",
      "303:\tlearn: 0.0262942\ttotal: 4m 55s\tremaining: 11m 15s\n",
      "304:\tlearn: 0.0262914\ttotal: 4m 55s\tremaining: 11m 14s\n",
      "305:\tlearn: 0.0262709\ttotal: 4m 56s\tremaining: 11m 13s\n",
      "306:\tlearn: 0.0262685\ttotal: 4m 57s\tremaining: 11m 11s\n",
      "307:\tlearn: 0.0262340\ttotal: 4m 58s\tremaining: 11m 11s\n",
      "308:\tlearn: 0.0262186\ttotal: 4m 59s\tremaining: 11m 9s\n",
      "309:\tlearn: 0.0261861\ttotal: 5m\tremaining: 11m 8s\n",
      "310:\tlearn: 0.0261749\ttotal: 5m 1s\tremaining: 11m 7s\n",
      "311:\tlearn: 0.0261622\ttotal: 5m 2s\tremaining: 11m 6s\n",
      "312:\tlearn: 0.0261560\ttotal: 5m 3s\tremaining: 11m 5s\n",
      "313:\tlearn: 0.0261440\ttotal: 5m 4s\tremaining: 11m 4s\n",
      "314:\tlearn: 0.0261293\ttotal: 5m 5s\tremaining: 11m 3s\n",
      "315:\tlearn: 0.0261161\ttotal: 5m 5s\tremaining: 11m 2s\n",
      "316:\tlearn: 0.0261139\ttotal: 5m 6s\tremaining: 11m 1s\n",
      "317:\tlearn: 0.0261118\ttotal: 5m 7s\tremaining: 11m\n",
      "318:\tlearn: 0.0261098\ttotal: 5m 8s\tremaining: 10m 59s\n",
      "319:\tlearn: 0.0261006\ttotal: 5m 9s\tremaining: 10m 57s\n",
      "320:\tlearn: 0.0260925\ttotal: 5m 10s\tremaining: 10m 56s\n",
      "321:\tlearn: 0.0260692\ttotal: 5m 11s\tremaining: 10m 55s\n",
      "322:\tlearn: 0.0260671\ttotal: 5m 12s\tremaining: 10m 54s\n",
      "323:\tlearn: 0.0260648\ttotal: 5m 13s\tremaining: 10m 53s\n",
      "324:\tlearn: 0.0260593\ttotal: 5m 14s\tremaining: 10m 52s\n",
      "325:\tlearn: 0.0260482\ttotal: 5m 15s\tremaining: 10m 51s\n",
      "326:\tlearn: 0.0260376\ttotal: 5m 16s\tremaining: 10m 50s\n",
      "327:\tlearn: 0.0260205\ttotal: 5m 17s\tremaining: 10m 49s\n",
      "328:\tlearn: 0.0260110\ttotal: 5m 18s\tremaining: 10m 48s\n",
      "329:\tlearn: 0.0260008\ttotal: 5m 19s\tremaining: 10m 47s\n",
      "330:\tlearn: 0.0259893\ttotal: 5m 20s\tremaining: 10m 46s\n",
      "331:\tlearn: 0.0259819\ttotal: 5m 20s\tremaining: 10m 45s\n",
      "332:\tlearn: 0.0259625\ttotal: 5m 21s\tremaining: 10m 44s\n",
      "333:\tlearn: 0.0259600\ttotal: 5m 22s\tremaining: 10m 43s\n",
      "334:\tlearn: 0.0259401\ttotal: 5m 23s\tremaining: 10m 42s\n",
      "335:\tlearn: 0.0259286\ttotal: 5m 24s\tremaining: 10m 41s\n",
      "336:\tlearn: 0.0259207\ttotal: 5m 25s\tremaining: 10m 39s\n",
      "337:\tlearn: 0.0259186\ttotal: 5m 26s\tremaining: 10m 38s\n",
      "338:\tlearn: 0.0259068\ttotal: 5m 26s\tremaining: 10m 37s\n",
      "339:\tlearn: 0.0258995\ttotal: 5m 27s\tremaining: 10m 36s\n",
      "340:\tlearn: 0.0258949\ttotal: 5m 28s\tremaining: 10m 35s\n",
      "341:\tlearn: 0.0258860\ttotal: 5m 29s\tremaining: 10m 34s\n",
      "342:\tlearn: 0.0258836\ttotal: 5m 30s\tremaining: 10m 33s\n",
      "343:\tlearn: 0.0258745\ttotal: 5m 31s\tremaining: 10m 32s\n",
      "344:\tlearn: 0.0258656\ttotal: 5m 32s\tremaining: 10m 31s\n",
      "345:\tlearn: 0.0258490\ttotal: 5m 33s\tremaining: 10m 29s\n",
      "346:\tlearn: 0.0258470\ttotal: 5m 33s\tremaining: 10m 28s\n",
      "347:\tlearn: 0.0258260\ttotal: 5m 34s\tremaining: 10m 27s\n",
      "348:\tlearn: 0.0258155\ttotal: 5m 35s\tremaining: 10m 26s\n",
      "349:\tlearn: 0.0258137\ttotal: 5m 36s\tremaining: 10m 25s\n",
      "350:\tlearn: 0.0258055\ttotal: 5m 37s\tremaining: 10m 24s\n",
      "351:\tlearn: 0.0258018\ttotal: 5m 38s\tremaining: 10m 23s\n",
      "352:\tlearn: 0.0257843\ttotal: 5m 39s\tremaining: 10m 22s\n",
      "353:\tlearn: 0.0257815\ttotal: 5m 40s\tremaining: 10m 21s\n",
      "354:\tlearn: 0.0257686\ttotal: 5m 41s\tremaining: 10m 20s\n",
      "355:\tlearn: 0.0257654\ttotal: 5m 42s\tremaining: 10m 19s\n",
      "356:\tlearn: 0.0257558\ttotal: 5m 43s\tremaining: 10m 18s\n",
      "357:\tlearn: 0.0257447\ttotal: 5m 43s\tremaining: 10m 16s\n",
      "358:\tlearn: 0.0257426\ttotal: 5m 44s\tremaining: 10m 15s\n",
      "359:\tlearn: 0.0257284\ttotal: 5m 45s\tremaining: 10m 13s\n",
      "360:\tlearn: 0.0257184\ttotal: 5m 46s\tremaining: 10m 12s\n",
      "361:\tlearn: 0.0257129\ttotal: 5m 46s\tremaining: 10m 11s\n",
      "362:\tlearn: 0.0256895\ttotal: 5m 47s\tremaining: 10m 10s\n",
      "363:\tlearn: 0.0256722\ttotal: 5m 48s\tremaining: 10m 9s\n",
      "364:\tlearn: 0.0256617\ttotal: 5m 49s\tremaining: 10m 8s\n",
      "365:\tlearn: 0.0256576\ttotal: 5m 50s\tremaining: 10m 7s\n",
      "366:\tlearn: 0.0256559\ttotal: 5m 51s\tremaining: 10m 6s\n",
      "367:\tlearn: 0.0256383\ttotal: 5m 52s\tremaining: 10m 5s\n",
      "368:\tlearn: 0.0256320\ttotal: 5m 53s\tremaining: 10m 4s\n",
      "369:\tlearn: 0.0256221\ttotal: 5m 54s\tremaining: 10m 2s\n",
      "370:\tlearn: 0.0256191\ttotal: 5m 54s\tremaining: 10m 1s\n",
      "371:\tlearn: 0.0256173\ttotal: 5m 55s\tremaining: 10m\n",
      "372:\tlearn: 0.0256123\ttotal: 5m 56s\tremaining: 9m 59s\n",
      "373:\tlearn: 0.0256076\ttotal: 5m 57s\tremaining: 9m 58s\n",
      "374:\tlearn: 0.0255877\ttotal: 5m 58s\tremaining: 9m 57s\n",
      "375:\tlearn: 0.0255679\ttotal: 5m 59s\tremaining: 9m 56s\n",
      "376:\tlearn: 0.0255660\ttotal: 6m\tremaining: 9m 55s\n",
      "377:\tlearn: 0.0255524\ttotal: 6m 1s\tremaining: 9m 54s\n",
      "378:\tlearn: 0.0255481\ttotal: 6m 2s\tremaining: 9m 53s\n",
      "379:\tlearn: 0.0255384\ttotal: 6m 3s\tremaining: 9m 52s\n",
      "380:\tlearn: 0.0255270\ttotal: 6m 3s\tremaining: 9m 51s\n",
      "381:\tlearn: 0.0255216\ttotal: 6m 4s\tremaining: 9m 50s\n",
      "382:\tlearn: 0.0255187\ttotal: 6m 5s\tremaining: 9m 49s\n",
      "383:\tlearn: 0.0255113\ttotal: 6m 6s\tremaining: 9m 48s\n",
      "384:\tlearn: 0.0255025\ttotal: 6m 7s\tremaining: 9m 47s\n",
      "385:\tlearn: 0.0254918\ttotal: 6m 8s\tremaining: 9m 46s\n",
      "386:\tlearn: 0.0254822\ttotal: 6m 9s\tremaining: 9m 45s\n",
      "387:\tlearn: 0.0254718\ttotal: 6m 10s\tremaining: 9m 44s\n",
      "388:\tlearn: 0.0254700\ttotal: 6m 11s\tremaining: 9m 43s\n",
      "389:\tlearn: 0.0254654\ttotal: 6m 12s\tremaining: 9m 42s\n",
      "390:\tlearn: 0.0254574\ttotal: 6m 13s\tremaining: 9m 41s\n",
      "391:\tlearn: 0.0254472\ttotal: 6m 14s\tremaining: 9m 40s\n",
      "392:\tlearn: 0.0254444\ttotal: 6m 14s\tremaining: 9m 39s\n",
      "393:\tlearn: 0.0254426\ttotal: 6m 15s\tremaining: 9m 38s\n",
      "394:\tlearn: 0.0254229\ttotal: 6m 16s\tremaining: 9m 37s\n",
      "395:\tlearn: 0.0254213\ttotal: 6m 17s\tremaining: 9m 36s\n",
      "396:\tlearn: 0.0253961\ttotal: 6m 18s\tremaining: 9m 35s\n",
      "397:\tlearn: 0.0253932\ttotal: 6m 19s\tremaining: 9m 34s\n",
      "398:\tlearn: 0.0253859\ttotal: 6m 20s\tremaining: 9m 33s\n",
      "399:\tlearn: 0.0253842\ttotal: 6m 21s\tremaining: 9m 32s\n",
      "400:\tlearn: 0.0253824\ttotal: 6m 22s\tremaining: 9m 31s\n",
      "401:\tlearn: 0.0253773\ttotal: 6m 23s\tremaining: 9m 30s\n",
      "402:\tlearn: 0.0253622\ttotal: 6m 24s\tremaining: 9m 29s\n",
      "403:\tlearn: 0.0253551\ttotal: 6m 25s\tremaining: 9m 28s\n",
      "404:\tlearn: 0.0253489\ttotal: 6m 26s\tremaining: 9m 27s\n",
      "405:\tlearn: 0.0253451\ttotal: 6m 27s\tremaining: 9m 26s\n",
      "406:\tlearn: 0.0253374\ttotal: 6m 28s\tremaining: 9m 25s\n",
      "407:\tlearn: 0.0253342\ttotal: 6m 29s\tremaining: 9m 24s\n",
      "408:\tlearn: 0.0253325\ttotal: 6m 30s\tremaining: 9m 23s\n",
      "409:\tlearn: 0.0253290\ttotal: 6m 31s\tremaining: 9m 23s\n",
      "410:\tlearn: 0.0253160\ttotal: 6m 32s\tremaining: 9m 22s\n",
      "411:\tlearn: 0.0253124\ttotal: 6m 33s\tremaining: 9m 21s\n",
      "412:\tlearn: 0.0253073\ttotal: 6m 34s\tremaining: 9m 20s\n",
      "413:\tlearn: 0.0252999\ttotal: 6m 35s\tremaining: 9m 19s\n",
      "414:\tlearn: 0.0252902\ttotal: 6m 36s\tremaining: 9m 18s\n",
      "415:\tlearn: 0.0252826\ttotal: 6m 36s\tremaining: 9m 17s\n",
      "416:\tlearn: 0.0252780\ttotal: 6m 37s\tremaining: 9m 16s\n",
      "417:\tlearn: 0.0252717\ttotal: 6m 38s\tremaining: 9m 15s\n",
      "418:\tlearn: 0.0252682\ttotal: 6m 39s\tremaining: 9m 13s\n",
      "419:\tlearn: 0.0252592\ttotal: 6m 40s\tremaining: 9m 12s\n",
      "420:\tlearn: 0.0252561\ttotal: 6m 41s\tremaining: 9m 12s\n",
      "421:\tlearn: 0.0252543\ttotal: 6m 42s\tremaining: 9m 11s\n",
      "422:\tlearn: 0.0252437\ttotal: 6m 43s\tremaining: 9m 10s\n",
      "423:\tlearn: 0.0252339\ttotal: 6m 44s\tremaining: 9m 9s\n",
      "424:\tlearn: 0.0252322\ttotal: 6m 45s\tremaining: 9m 8s\n",
      "425:\tlearn: 0.0252305\ttotal: 6m 45s\tremaining: 9m 6s\n",
      "426:\tlearn: 0.0252236\ttotal: 6m 46s\tremaining: 9m 5s\n",
      "427:\tlearn: 0.0252014\ttotal: 6m 47s\tremaining: 9m 5s\n",
      "428:\tlearn: 0.0251954\ttotal: 6m 48s\tremaining: 9m 4s\n",
      "429:\tlearn: 0.0251886\ttotal: 6m 49s\tremaining: 9m 3s\n",
      "430:\tlearn: 0.0251765\ttotal: 6m 50s\tremaining: 9m 2s\n",
      "431:\tlearn: 0.0251750\ttotal: 6m 51s\tremaining: 9m 1s\n",
      "432:\tlearn: 0.0251683\ttotal: 6m 52s\tremaining: 9m\n",
      "433:\tlearn: 0.0251616\ttotal: 6m 53s\tremaining: 8m 59s\n",
      "434:\tlearn: 0.0251382\ttotal: 6m 54s\tremaining: 8m 58s\n",
      "435:\tlearn: 0.0251347\ttotal: 6m 55s\tremaining: 8m 57s\n",
      "436:\tlearn: 0.0251319\ttotal: 6m 56s\tremaining: 8m 56s\n",
      "437:\tlearn: 0.0251182\ttotal: 6m 57s\tremaining: 8m 55s\n",
      "438:\tlearn: 0.0251167\ttotal: 6m 58s\tremaining: 8m 54s\n",
      "439:\tlearn: 0.0251103\ttotal: 6m 59s\tremaining: 8m 53s\n",
      "440:\tlearn: 0.0251064\ttotal: 7m\tremaining: 8m 52s\n",
      "441:\tlearn: 0.0250916\ttotal: 7m 1s\tremaining: 8m 51s\n",
      "442:\tlearn: 0.0250801\ttotal: 7m 2s\tremaining: 8m 50s\n",
      "443:\tlearn: 0.0250711\ttotal: 7m 3s\tremaining: 8m 49s\n",
      "444:\tlearn: 0.0250620\ttotal: 7m 3s\tremaining: 8m 48s\n",
      "445:\tlearn: 0.0250604\ttotal: 7m 4s\tremaining: 8m 47s\n",
      "446:\tlearn: 0.0250562\ttotal: 7m 5s\tremaining: 8m 46s\n",
      "447:\tlearn: 0.0250536\ttotal: 7m 6s\tremaining: 8m 45s\n",
      "448:\tlearn: 0.0250521\ttotal: 7m 7s\tremaining: 8m 44s\n",
      "449:\tlearn: 0.0250462\ttotal: 7m 8s\tremaining: 8m 43s\n",
      "450:\tlearn: 0.0250447\ttotal: 7m 9s\tremaining: 8m 42s\n",
      "451:\tlearn: 0.0250320\ttotal: 7m 10s\tremaining: 8m 41s\n",
      "452:\tlearn: 0.0250253\ttotal: 7m 11s\tremaining: 8m 40s\n",
      "453:\tlearn: 0.0250216\ttotal: 7m 12s\tremaining: 8m 39s\n",
      "454:\tlearn: 0.0250185\ttotal: 7m 12s\tremaining: 8m 38s\n",
      "455:\tlearn: 0.0250161\ttotal: 7m 13s\tremaining: 8m 37s\n",
      "456:\tlearn: 0.0250082\ttotal: 7m 14s\tremaining: 8m 36s\n",
      "457:\tlearn: 0.0250056\ttotal: 7m 15s\tremaining: 8m 35s\n",
      "458:\tlearn: 0.0250041\ttotal: 7m 16s\tremaining: 8m 34s\n",
      "459:\tlearn: 0.0250017\ttotal: 7m 17s\tremaining: 8m 33s\n",
      "460:\tlearn: 0.0249989\ttotal: 7m 18s\tremaining: 8m 32s\n",
      "461:\tlearn: 0.0249962\ttotal: 7m 19s\tremaining: 8m 31s\n",
      "462:\tlearn: 0.0249907\ttotal: 7m 20s\tremaining: 8m 30s\n",
      "463:\tlearn: 0.0249846\ttotal: 7m 21s\tremaining: 8m 29s\n",
      "464:\tlearn: 0.0249767\ttotal: 7m 22s\tremaining: 8m 28s\n",
      "465:\tlearn: 0.0249751\ttotal: 7m 22s\tremaining: 8m 27s\n",
      "466:\tlearn: 0.0249722\ttotal: 7m 23s\tremaining: 8m 26s\n",
      "467:\tlearn: 0.0249654\ttotal: 7m 24s\tremaining: 8m 25s\n",
      "468:\tlearn: 0.0249583\ttotal: 7m 25s\tremaining: 8m 24s\n",
      "469:\tlearn: 0.0249440\ttotal: 7m 26s\tremaining: 8m 23s\n",
      "470:\tlearn: 0.0249341\ttotal: 7m 27s\tremaining: 8m 22s\n",
      "471:\tlearn: 0.0249295\ttotal: 7m 28s\tremaining: 8m 21s\n",
      "472:\tlearn: 0.0249158\ttotal: 7m 29s\tremaining: 8m 20s\n",
      "473:\tlearn: 0.0249120\ttotal: 7m 30s\tremaining: 8m 19s\n",
      "474:\tlearn: 0.0249089\ttotal: 7m 30s\tremaining: 8m 18s\n",
      "475:\tlearn: 0.0249031\ttotal: 7m 32s\tremaining: 8m 17s\n",
      "476:\tlearn: 0.0248986\ttotal: 7m 33s\tremaining: 8m 16s\n",
      "477:\tlearn: 0.0248912\ttotal: 7m 33s\tremaining: 8m 15s\n",
      "478:\tlearn: 0.0248847\ttotal: 7m 34s\tremaining: 8m 14s\n",
      "479:\tlearn: 0.0248812\ttotal: 7m 35s\tremaining: 8m 13s\n",
      "480:\tlearn: 0.0248731\ttotal: 7m 36s\tremaining: 8m 12s\n",
      "481:\tlearn: 0.0248609\ttotal: 7m 37s\tremaining: 8m 11s\n",
      "482:\tlearn: 0.0248595\ttotal: 7m 38s\tremaining: 8m 10s\n",
      "483:\tlearn: 0.0248485\ttotal: 7m 39s\tremaining: 8m 9s\n",
      "484:\tlearn: 0.0248460\ttotal: 7m 40s\tremaining: 8m 8s\n",
      "485:\tlearn: 0.0248440\ttotal: 7m 40s\tremaining: 8m 7s\n",
      "486:\tlearn: 0.0248350\ttotal: 7m 41s\tremaining: 8m 6s\n",
      "487:\tlearn: 0.0248190\ttotal: 7m 42s\tremaining: 8m 5s\n",
      "488:\tlearn: 0.0248003\ttotal: 7m 43s\tremaining: 8m 4s\n",
      "489:\tlearn: 0.0247988\ttotal: 7m 44s\tremaining: 8m 3s\n",
      "490:\tlearn: 0.0247932\ttotal: 7m 45s\tremaining: 8m 2s\n",
      "491:\tlearn: 0.0247875\ttotal: 7m 46s\tremaining: 8m 1s\n",
      "492:\tlearn: 0.0247819\ttotal: 7m 47s\tremaining: 8m\n",
      "493:\tlearn: 0.0247678\ttotal: 7m 48s\tremaining: 7m 59s\n",
      "494:\tlearn: 0.0247611\ttotal: 7m 49s\tremaining: 7m 58s\n",
      "495:\tlearn: 0.0247545\ttotal: 7m 50s\tremaining: 7m 57s\n",
      "496:\tlearn: 0.0247530\ttotal: 7m 51s\tremaining: 7m 56s\n",
      "497:\tlearn: 0.0247510\ttotal: 7m 52s\tremaining: 7m 55s\n",
      "498:\tlearn: 0.0247360\ttotal: 7m 53s\tremaining: 7m 55s\n",
      "499:\tlearn: 0.0247298\ttotal: 7m 54s\tremaining: 7m 54s\n",
      "500:\tlearn: 0.0247230\ttotal: 7m 54s\tremaining: 7m 53s\n",
      "501:\tlearn: 0.0247019\ttotal: 7m 56s\tremaining: 7m 52s\n",
      "502:\tlearn: 0.0246984\ttotal: 7m 56s\tremaining: 7m 51s\n",
      "503:\tlearn: 0.0246964\ttotal: 7m 57s\tremaining: 7m 50s\n",
      "504:\tlearn: 0.0246796\ttotal: 7m 58s\tremaining: 7m 49s\n",
      "505:\tlearn: 0.0246771\ttotal: 7m 59s\tremaining: 7m 48s\n",
      "506:\tlearn: 0.0246721\ttotal: 8m\tremaining: 7m 47s\n",
      "507:\tlearn: 0.0246706\ttotal: 8m 1s\tremaining: 7m 46s\n",
      "508:\tlearn: 0.0246587\ttotal: 8m 2s\tremaining: 7m 45s\n",
      "509:\tlearn: 0.0246516\ttotal: 8m 3s\tremaining: 7m 44s\n",
      "510:\tlearn: 0.0246498\ttotal: 8m 4s\tremaining: 7m 43s\n",
      "511:\tlearn: 0.0246477\ttotal: 8m 5s\tremaining: 7m 42s\n",
      "512:\tlearn: 0.0246457\ttotal: 8m 6s\tremaining: 7m 41s\n",
      "513:\tlearn: 0.0246243\ttotal: 8m 7s\tremaining: 7m 40s\n",
      "514:\tlearn: 0.0246210\ttotal: 8m 8s\tremaining: 7m 39s\n",
      "515:\tlearn: 0.0246081\ttotal: 8m 9s\tremaining: 7m 38s\n",
      "516:\tlearn: 0.0246067\ttotal: 8m 9s\tremaining: 7m 37s\n",
      "517:\tlearn: 0.0245961\ttotal: 8m 10s\tremaining: 7m 36s\n",
      "518:\tlearn: 0.0245891\ttotal: 8m 11s\tremaining: 7m 35s\n",
      "519:\tlearn: 0.0245843\ttotal: 8m 12s\tremaining: 7m 34s\n",
      "520:\tlearn: 0.0245806\ttotal: 8m 13s\tremaining: 7m 34s\n",
      "521:\tlearn: 0.0245656\ttotal: 8m 14s\tremaining: 7m 33s\n",
      "522:\tlearn: 0.0245630\ttotal: 8m 15s\tremaining: 7m 32s\n",
      "523:\tlearn: 0.0245615\ttotal: 8m 16s\tremaining: 7m 31s\n",
      "524:\tlearn: 0.0245568\ttotal: 8m 17s\tremaining: 7m 30s\n",
      "525:\tlearn: 0.0245511\ttotal: 8m 18s\tremaining: 7m 29s\n",
      "526:\tlearn: 0.0245432\ttotal: 8m 19s\tremaining: 7m 28s\n",
      "527:\tlearn: 0.0245339\ttotal: 8m 20s\tremaining: 7m 27s\n",
      "528:\tlearn: 0.0245291\ttotal: 8m 21s\tremaining: 7m 26s\n",
      "529:\tlearn: 0.0245272\ttotal: 8m 22s\tremaining: 7m 25s\n",
      "530:\tlearn: 0.0245214\ttotal: 8m 23s\tremaining: 7m 24s\n",
      "531:\tlearn: 0.0245130\ttotal: 8m 24s\tremaining: 7m 23s\n",
      "532:\tlearn: 0.0245074\ttotal: 8m 25s\tremaining: 7m 22s\n",
      "533:\tlearn: 0.0244982\ttotal: 8m 25s\tremaining: 7m 21s\n",
      "534:\tlearn: 0.0244968\ttotal: 8m 26s\tremaining: 7m 20s\n",
      "535:\tlearn: 0.0244941\ttotal: 8m 27s\tremaining: 7m 19s\n",
      "536:\tlearn: 0.0244806\ttotal: 8m 28s\tremaining: 7m 18s\n",
      "537:\tlearn: 0.0244746\ttotal: 8m 29s\tremaining: 7m 17s\n",
      "538:\tlearn: 0.0244708\ttotal: 8m 30s\tremaining: 7m 16s\n",
      "539:\tlearn: 0.0244647\ttotal: 8m 31s\tremaining: 7m 15s\n",
      "540:\tlearn: 0.0244599\ttotal: 8m 32s\tremaining: 7m 14s\n",
      "541:\tlearn: 0.0244511\ttotal: 8m 33s\tremaining: 7m 13s\n",
      "542:\tlearn: 0.0244420\ttotal: 8m 34s\tremaining: 7m 12s\n",
      "543:\tlearn: 0.0244375\ttotal: 8m 35s\tremaining: 7m 12s\n",
      "544:\tlearn: 0.0244266\ttotal: 8m 36s\tremaining: 7m 11s\n",
      "545:\tlearn: 0.0244241\ttotal: 8m 37s\tremaining: 7m 10s\n",
      "546:\tlearn: 0.0244151\ttotal: 8m 38s\tremaining: 7m 9s\n",
      "547:\tlearn: 0.0244138\ttotal: 8m 39s\tremaining: 7m 8s\n",
      "548:\tlearn: 0.0244090\ttotal: 8m 39s\tremaining: 7m 7s\n",
      "549:\tlearn: 0.0244021\ttotal: 8m 41s\tremaining: 7m 6s\n",
      "550:\tlearn: 0.0244008\ttotal: 8m 42s\tremaining: 7m 5s\n",
      "551:\tlearn: 0.0243950\ttotal: 8m 43s\tremaining: 7m 4s\n",
      "552:\tlearn: 0.0243928\ttotal: 8m 43s\tremaining: 7m 3s\n",
      "553:\tlearn: 0.0243840\ttotal: 8m 44s\tremaining: 7m 2s\n",
      "554:\tlearn: 0.0243745\ttotal: 8m 45s\tremaining: 7m 1s\n",
      "555:\tlearn: 0.0243675\ttotal: 8m 46s\tremaining: 7m\n",
      "556:\tlearn: 0.0243646\ttotal: 8m 47s\tremaining: 6m 59s\n",
      "557:\tlearn: 0.0243632\ttotal: 8m 48s\tremaining: 6m 58s\n",
      "558:\tlearn: 0.0243599\ttotal: 8m 49s\tremaining: 6m 57s\n",
      "559:\tlearn: 0.0243586\ttotal: 8m 50s\tremaining: 6m 56s\n",
      "560:\tlearn: 0.0243462\ttotal: 8m 51s\tremaining: 6m 55s\n",
      "561:\tlearn: 0.0243377\ttotal: 8m 52s\tremaining: 6m 54s\n",
      "562:\tlearn: 0.0243358\ttotal: 8m 53s\tremaining: 6m 53s\n",
      "563:\tlearn: 0.0243269\ttotal: 8m 54s\tremaining: 6m 53s\n",
      "564:\tlearn: 0.0243195\ttotal: 8m 55s\tremaining: 6m 52s\n",
      "565:\tlearn: 0.0243183\ttotal: 8m 56s\tremaining: 6m 51s\n",
      "566:\tlearn: 0.0243171\ttotal: 8m 57s\tremaining: 6m 50s\n",
      "567:\tlearn: 0.0243057\ttotal: 8m 58s\tremaining: 6m 49s\n",
      "568:\tlearn: 0.0242989\ttotal: 8m 58s\tremaining: 6m 48s\n",
      "569:\tlearn: 0.0242952\ttotal: 8m 59s\tremaining: 6m 47s\n",
      "570:\tlearn: 0.0242809\ttotal: 9m\tremaining: 6m 46s\n",
      "571:\tlearn: 0.0242752\ttotal: 9m 1s\tremaining: 6m 45s\n",
      "572:\tlearn: 0.0242680\ttotal: 9m 2s\tremaining: 6m 44s\n",
      "573:\tlearn: 0.0242627\ttotal: 9m 3s\tremaining: 6m 43s\n",
      "574:\tlearn: 0.0242585\ttotal: 9m 4s\tremaining: 6m 42s\n",
      "575:\tlearn: 0.0242535\ttotal: 9m 5s\tremaining: 6m 41s\n",
      "576:\tlearn: 0.0242524\ttotal: 9m 6s\tremaining: 6m 40s\n",
      "577:\tlearn: 0.0242359\ttotal: 9m 7s\tremaining: 6m 39s\n",
      "578:\tlearn: 0.0242291\ttotal: 9m 8s\tremaining: 6m 38s\n",
      "579:\tlearn: 0.0242131\ttotal: 9m 8s\tremaining: 6m 37s\n",
      "580:\tlearn: 0.0242101\ttotal: 9m 9s\tremaining: 6m 36s\n",
      "581:\tlearn: 0.0242075\ttotal: 9m 10s\tremaining: 6m 35s\n",
      "582:\tlearn: 0.0242018\ttotal: 9m 11s\tremaining: 6m 34s\n",
      "583:\tlearn: 0.0241953\ttotal: 9m 12s\tremaining: 6m 33s\n",
      "584:\tlearn: 0.0241858\ttotal: 9m 13s\tremaining: 6m 32s\n",
      "585:\tlearn: 0.0241811\ttotal: 9m 14s\tremaining: 6m 31s\n",
      "586:\tlearn: 0.0241799\ttotal: 9m 15s\tremaining: 6m 30s\n",
      "587:\tlearn: 0.0241714\ttotal: 9m 16s\tremaining: 6m 29s\n",
      "588:\tlearn: 0.0241669\ttotal: 9m 17s\tremaining: 6m 28s\n",
      "589:\tlearn: 0.0241658\ttotal: 9m 17s\tremaining: 6m 27s\n",
      "590:\tlearn: 0.0241604\ttotal: 9m 18s\tremaining: 6m 26s\n",
      "591:\tlearn: 0.0241565\ttotal: 9m 19s\tremaining: 6m 25s\n",
      "592:\tlearn: 0.0241517\ttotal: 9m 20s\tremaining: 6m 24s\n",
      "593:\tlearn: 0.0241416\ttotal: 9m 21s\tremaining: 6m 23s\n",
      "594:\tlearn: 0.0241370\ttotal: 9m 22s\tremaining: 6m 22s\n",
      "595:\tlearn: 0.0241236\ttotal: 9m 23s\tremaining: 6m 21s\n",
      "596:\tlearn: 0.0241199\ttotal: 9m 24s\tremaining: 6m 20s\n",
      "597:\tlearn: 0.0241180\ttotal: 9m 25s\tremaining: 6m 19s\n",
      "598:\tlearn: 0.0241155\ttotal: 9m 26s\tremaining: 6m 18s\n",
      "599:\tlearn: 0.0241086\ttotal: 9m 27s\tremaining: 6m 18s\n",
      "600:\tlearn: 0.0241035\ttotal: 9m 28s\tremaining: 6m 17s\n",
      "601:\tlearn: 0.0240948\ttotal: 9m 29s\tremaining: 6m 16s\n",
      "602:\tlearn: 0.0240885\ttotal: 9m 29s\tremaining: 6m 15s\n",
      "603:\tlearn: 0.0240806\ttotal: 9m 30s\tremaining: 6m 14s\n",
      "604:\tlearn: 0.0240794\ttotal: 9m 31s\tremaining: 6m 13s\n",
      "605:\tlearn: 0.0240760\ttotal: 9m 32s\tremaining: 6m 12s\n",
      "606:\tlearn: 0.0240692\ttotal: 9m 33s\tremaining: 6m 11s\n",
      "607:\tlearn: 0.0240573\ttotal: 9m 34s\tremaining: 6m 10s\n",
      "608:\tlearn: 0.0240463\ttotal: 9m 35s\tremaining: 6m 9s\n",
      "609:\tlearn: 0.0240347\ttotal: 9m 36s\tremaining: 6m 8s\n",
      "610:\tlearn: 0.0240329\ttotal: 9m 37s\tremaining: 6m 7s\n",
      "611:\tlearn: 0.0240312\ttotal: 9m 38s\tremaining: 6m 6s\n",
      "612:\tlearn: 0.0240294\ttotal: 9m 39s\tremaining: 6m 5s\n",
      "613:\tlearn: 0.0240275\ttotal: 9m 40s\tremaining: 6m 4s\n",
      "614:\tlearn: 0.0240237\ttotal: 9m 41s\tremaining: 6m 3s\n",
      "615:\tlearn: 0.0240200\ttotal: 9m 41s\tremaining: 6m 2s\n",
      "616:\tlearn: 0.0240160\ttotal: 9m 42s\tremaining: 6m 1s\n",
      "617:\tlearn: 0.0240148\ttotal: 9m 43s\tremaining: 6m\n",
      "618:\tlearn: 0.0240023\ttotal: 9m 44s\tremaining: 5m 59s\n",
      "619:\tlearn: 0.0239965\ttotal: 9m 45s\tremaining: 5m 58s\n",
      "620:\tlearn: 0.0239900\ttotal: 9m 46s\tremaining: 5m 57s\n",
      "621:\tlearn: 0.0239835\ttotal: 9m 47s\tremaining: 5m 56s\n",
      "622:\tlearn: 0.0239808\ttotal: 9m 48s\tremaining: 5m 55s\n",
      "623:\tlearn: 0.0239753\ttotal: 9m 49s\tremaining: 5m 55s\n",
      "624:\tlearn: 0.0239685\ttotal: 9m 50s\tremaining: 5m 54s\n",
      "625:\tlearn: 0.0239603\ttotal: 9m 51s\tremaining: 5m 53s\n",
      "626:\tlearn: 0.0239553\ttotal: 9m 51s\tremaining: 5m 52s\n",
      "627:\tlearn: 0.0239503\ttotal: 9m 52s\tremaining: 5m 51s\n",
      "628:\tlearn: 0.0239492\ttotal: 9m 53s\tremaining: 5m 50s\n",
      "629:\tlearn: 0.0239343\ttotal: 9m 54s\tremaining: 5m 49s\n",
      "630:\tlearn: 0.0239332\ttotal: 9m 55s\tremaining: 5m 48s\n",
      "631:\tlearn: 0.0239234\ttotal: 9m 56s\tremaining: 5m 47s\n",
      "632:\tlearn: 0.0239199\ttotal: 9m 57s\tremaining: 5m 46s\n",
      "633:\tlearn: 0.0239150\ttotal: 9m 58s\tremaining: 5m 45s\n",
      "634:\tlearn: 0.0239128\ttotal: 9m 59s\tremaining: 5m 44s\n",
      "635:\tlearn: 0.0239116\ttotal: 10m\tremaining: 5m 43s\n",
      "636:\tlearn: 0.0239105\ttotal: 10m 1s\tremaining: 5m 42s\n",
      "637:\tlearn: 0.0239038\ttotal: 10m 2s\tremaining: 5m 41s\n",
      "638:\tlearn: 0.0239015\ttotal: 10m 2s\tremaining: 5m 40s\n",
      "639:\tlearn: 0.0238948\ttotal: 10m 3s\tremaining: 5m 39s\n",
      "640:\tlearn: 0.0238882\ttotal: 10m 4s\tremaining: 5m 38s\n",
      "641:\tlearn: 0.0238872\ttotal: 10m 5s\tremaining: 5m 37s\n",
      "642:\tlearn: 0.0238814\ttotal: 10m 6s\tremaining: 5m 36s\n",
      "643:\tlearn: 0.0238610\ttotal: 10m 7s\tremaining: 5m 35s\n",
      "644:\tlearn: 0.0238595\ttotal: 10m 8s\tremaining: 5m 34s\n",
      "645:\tlearn: 0.0238507\ttotal: 10m 9s\tremaining: 5m 33s\n",
      "646:\tlearn: 0.0238456\ttotal: 10m 10s\tremaining: 5m 33s\n",
      "647:\tlearn: 0.0238388\ttotal: 10m 11s\tremaining: 5m 32s\n",
      "648:\tlearn: 0.0238320\ttotal: 10m 12s\tremaining: 5m 31s\n",
      "649:\tlearn: 0.0238309\ttotal: 10m 13s\tremaining: 5m 30s\n",
      "650:\tlearn: 0.0238253\ttotal: 10m 14s\tremaining: 5m 29s\n",
      "651:\tlearn: 0.0238186\ttotal: 10m 15s\tremaining: 5m 28s\n",
      "652:\tlearn: 0.0238153\ttotal: 10m 16s\tremaining: 5m 27s\n",
      "653:\tlearn: 0.0238124\ttotal: 10m 17s\tremaining: 5m 26s\n",
      "654:\tlearn: 0.0238057\ttotal: 10m 18s\tremaining: 5m 25s\n",
      "655:\tlearn: 0.0238031\ttotal: 10m 19s\tremaining: 5m 24s\n",
      "656:\tlearn: 0.0238020\ttotal: 10m 19s\tremaining: 5m 23s\n",
      "657:\tlearn: 0.0237931\ttotal: 10m 20s\tremaining: 5m 22s\n",
      "658:\tlearn: 0.0237907\ttotal: 10m 21s\tremaining: 5m 21s\n",
      "659:\tlearn: 0.0237897\ttotal: 10m 22s\tremaining: 5m 20s\n",
      "660:\tlearn: 0.0237841\ttotal: 10m 23s\tremaining: 5m 19s\n",
      "661:\tlearn: 0.0237746\ttotal: 10m 24s\tremaining: 5m 18s\n",
      "662:\tlearn: 0.0237600\ttotal: 10m 25s\tremaining: 5m 17s\n",
      "663:\tlearn: 0.0237560\ttotal: 10m 26s\tremaining: 5m 16s\n",
      "664:\tlearn: 0.0237478\ttotal: 10m 27s\tremaining: 5m 16s\n",
      "665:\tlearn: 0.0237450\ttotal: 10m 28s\tremaining: 5m 15s\n",
      "666:\tlearn: 0.0237366\ttotal: 10m 29s\tremaining: 5m 14s\n",
      "667:\tlearn: 0.0237297\ttotal: 10m 29s\tremaining: 5m 13s\n",
      "668:\tlearn: 0.0237243\ttotal: 10m 30s\tremaining: 5m 12s\n",
      "669:\tlearn: 0.0237226\ttotal: 10m 31s\tremaining: 5m 11s\n",
      "670:\tlearn: 0.0237216\ttotal: 10m 32s\tremaining: 5m 10s\n",
      "671:\tlearn: 0.0237186\ttotal: 10m 33s\tremaining: 5m 9s\n",
      "672:\tlearn: 0.0237136\ttotal: 10m 34s\tremaining: 5m 8s\n",
      "673:\tlearn: 0.0237074\ttotal: 10m 35s\tremaining: 5m 7s\n",
      "674:\tlearn: 0.0237030\ttotal: 10m 36s\tremaining: 5m 6s\n",
      "675:\tlearn: 0.0236969\ttotal: 10m 37s\tremaining: 5m 5s\n",
      "676:\tlearn: 0.0236932\ttotal: 10m 38s\tremaining: 5m 4s\n",
      "677:\tlearn: 0.0236922\ttotal: 10m 39s\tremaining: 5m 3s\n",
      "678:\tlearn: 0.0236768\ttotal: 10m 40s\tremaining: 5m 2s\n",
      "679:\tlearn: 0.0236757\ttotal: 10m 40s\tremaining: 5m 1s\n",
      "680:\tlearn: 0.0236731\ttotal: 10m 41s\tremaining: 5m\n",
      "681:\tlearn: 0.0236658\ttotal: 10m 42s\tremaining: 4m 59s\n",
      "682:\tlearn: 0.0236569\ttotal: 10m 43s\tremaining: 4m 58s\n",
      "683:\tlearn: 0.0236554\ttotal: 10m 44s\tremaining: 4m 57s\n",
      "684:\tlearn: 0.0236483\ttotal: 10m 45s\tremaining: 4m 56s\n",
      "685:\tlearn: 0.0236307\ttotal: 10m 46s\tremaining: 4m 56s\n",
      "686:\tlearn: 0.0236255\ttotal: 10m 47s\tremaining: 4m 55s\n",
      "687:\tlearn: 0.0236211\ttotal: 10m 48s\tremaining: 4m 54s\n",
      "688:\tlearn: 0.0236200\ttotal: 10m 49s\tremaining: 4m 53s\n",
      "689:\tlearn: 0.0236190\ttotal: 10m 50s\tremaining: 4m 52s\n",
      "690:\tlearn: 0.0236030\ttotal: 10m 51s\tremaining: 4m 51s\n",
      "691:\tlearn: 0.0235987\ttotal: 10m 52s\tremaining: 4m 50s\n",
      "692:\tlearn: 0.0235960\ttotal: 10m 53s\tremaining: 4m 49s\n",
      "693:\tlearn: 0.0235938\ttotal: 10m 54s\tremaining: 4m 48s\n",
      "694:\tlearn: 0.0235894\ttotal: 10m 55s\tremaining: 4m 47s\n",
      "695:\tlearn: 0.0235779\ttotal: 10m 56s\tremaining: 4m 46s\n",
      "696:\tlearn: 0.0235768\ttotal: 10m 56s\tremaining: 4m 45s\n",
      "697:\tlearn: 0.0235722\ttotal: 10m 57s\tremaining: 4m 44s\n",
      "698:\tlearn: 0.0235706\ttotal: 10m 58s\tremaining: 4m 43s\n",
      "699:\tlearn: 0.0235685\ttotal: 10m 59s\tremaining: 4m 42s\n",
      "700:\tlearn: 0.0235645\ttotal: 11m\tremaining: 4m 41s\n",
      "701:\tlearn: 0.0235514\ttotal: 11m 1s\tremaining: 4m 40s\n",
      "702:\tlearn: 0.0235504\ttotal: 11m 2s\tremaining: 4m 39s\n",
      "703:\tlearn: 0.0235439\ttotal: 11m 3s\tremaining: 4m 38s\n",
      "704:\tlearn: 0.0235397\ttotal: 11m 4s\tremaining: 4m 37s\n",
      "705:\tlearn: 0.0235338\ttotal: 11m 5s\tremaining: 4m 37s\n",
      "706:\tlearn: 0.0235282\ttotal: 11m 6s\tremaining: 4m 36s\n",
      "707:\tlearn: 0.0235227\ttotal: 11m 7s\tremaining: 4m 35s\n",
      "708:\tlearn: 0.0235201\ttotal: 11m 8s\tremaining: 4m 34s\n",
      "709:\tlearn: 0.0235150\ttotal: 11m 8s\tremaining: 4m 33s\n",
      "710:\tlearn: 0.0235117\ttotal: 11m 9s\tremaining: 4m 32s\n",
      "711:\tlearn: 0.0235061\ttotal: 11m 10s\tremaining: 4m 31s\n",
      "712:\tlearn: 0.0235029\ttotal: 11m 11s\tremaining: 4m 30s\n",
      "713:\tlearn: 0.0234944\ttotal: 11m 12s\tremaining: 4m 29s\n",
      "714:\tlearn: 0.0234892\ttotal: 11m 13s\tremaining: 4m 28s\n",
      "715:\tlearn: 0.0234823\ttotal: 11m 14s\tremaining: 4m 27s\n",
      "716:\tlearn: 0.0234813\ttotal: 11m 15s\tremaining: 4m 26s\n",
      "717:\tlearn: 0.0234763\ttotal: 11m 16s\tremaining: 4m 25s\n",
      "718:\tlearn: 0.0234706\ttotal: 11m 17s\tremaining: 4m 24s\n",
      "719:\tlearn: 0.0234696\ttotal: 11m 18s\tremaining: 4m 23s\n",
      "720:\tlearn: 0.0234666\ttotal: 11m 19s\tremaining: 4m 22s\n",
      "721:\tlearn: 0.0234608\ttotal: 11m 20s\tremaining: 4m 21s\n",
      "722:\tlearn: 0.0234400\ttotal: 11m 21s\tremaining: 4m 20s\n",
      "723:\tlearn: 0.0234372\ttotal: 11m 22s\tremaining: 4m 19s\n",
      "724:\tlearn: 0.0234320\ttotal: 11m 22s\tremaining: 4m 19s\n",
      "725:\tlearn: 0.0234261\ttotal: 11m 23s\tremaining: 4m 18s\n",
      "726:\tlearn: 0.0234252\ttotal: 11m 24s\tremaining: 4m 17s\n",
      "727:\tlearn: 0.0234242\ttotal: 11m 25s\tremaining: 4m 16s\n",
      "728:\tlearn: 0.0234226\ttotal: 11m 26s\tremaining: 4m 15s\n",
      "729:\tlearn: 0.0234167\ttotal: 11m 27s\tremaining: 4m 14s\n",
      "730:\tlearn: 0.0234118\ttotal: 11m 28s\tremaining: 4m 13s\n",
      "731:\tlearn: 0.0234074\ttotal: 11m 29s\tremaining: 4m 12s\n",
      "732:\tlearn: 0.0234058\ttotal: 11m 30s\tremaining: 4m 11s\n",
      "733:\tlearn: 0.0233974\ttotal: 11m 31s\tremaining: 4m 10s\n",
      "734:\tlearn: 0.0233965\ttotal: 11m 32s\tremaining: 4m 9s\n",
      "735:\tlearn: 0.0233943\ttotal: 11m 33s\tremaining: 4m 8s\n",
      "736:\tlearn: 0.0233910\ttotal: 11m 33s\tremaining: 4m 7s\n",
      "737:\tlearn: 0.0233867\ttotal: 11m 34s\tremaining: 4m 6s\n",
      "738:\tlearn: 0.0233809\ttotal: 11m 35s\tremaining: 4m 5s\n",
      "739:\tlearn: 0.0233744\ttotal: 11m 36s\tremaining: 4m 4s\n",
      "740:\tlearn: 0.0233687\ttotal: 11m 37s\tremaining: 4m 3s\n",
      "741:\tlearn: 0.0233639\ttotal: 11m 38s\tremaining: 4m 2s\n",
      "742:\tlearn: 0.0233571\ttotal: 11m 39s\tremaining: 4m 1s\n",
      "743:\tlearn: 0.0233510\ttotal: 11m 40s\tremaining: 4m 1s\n",
      "744:\tlearn: 0.0233462\ttotal: 11m 41s\tremaining: 4m\n",
      "745:\tlearn: 0.0233378\ttotal: 11m 42s\tremaining: 3m 59s\n",
      "746:\tlearn: 0.0233337\ttotal: 11m 43s\tremaining: 3m 58s\n",
      "747:\tlearn: 0.0233187\ttotal: 11m 44s\tremaining: 3m 57s\n",
      "748:\tlearn: 0.0233126\ttotal: 11m 45s\tremaining: 3m 56s\n",
      "749:\tlearn: 0.0233099\ttotal: 11m 45s\tremaining: 3m 55s\n",
      "750:\tlearn: 0.0233015\ttotal: 11m 46s\tremaining: 3m 54s\n",
      "751:\tlearn: 0.0232968\ttotal: 11m 47s\tremaining: 3m 53s\n",
      "752:\tlearn: 0.0232941\ttotal: 11m 48s\tremaining: 3m 52s\n",
      "753:\tlearn: 0.0232905\ttotal: 11m 49s\tremaining: 3m 51s\n",
      "754:\tlearn: 0.0232862\ttotal: 11m 50s\tremaining: 3m 50s\n",
      "755:\tlearn: 0.0232843\ttotal: 11m 51s\tremaining: 3m 49s\n",
      "756:\tlearn: 0.0232781\ttotal: 11m 52s\tremaining: 3m 48s\n",
      "757:\tlearn: 0.0232772\ttotal: 11m 53s\tremaining: 3m 47s\n",
      "758:\tlearn: 0.0232725\ttotal: 11m 54s\tremaining: 3m 46s\n",
      "759:\tlearn: 0.0232670\ttotal: 11m 55s\tremaining: 3m 45s\n",
      "760:\tlearn: 0.0232596\ttotal: 11m 55s\tremaining: 3m 44s\n",
      "761:\tlearn: 0.0232537\ttotal: 11m 56s\tremaining: 3m 43s\n",
      "762:\tlearn: 0.0232516\ttotal: 11m 57s\tremaining: 3m 42s\n",
      "763:\tlearn: 0.0232506\ttotal: 11m 58s\tremaining: 3m 42s\n",
      "764:\tlearn: 0.0232462\ttotal: 11m 59s\tremaining: 3m 41s\n",
      "765:\tlearn: 0.0232444\ttotal: 12m 1s\tremaining: 3m 40s\n",
      "766:\tlearn: 0.0232420\ttotal: 12m 2s\tremaining: 3m 39s\n",
      "767:\tlearn: 0.0232386\ttotal: 12m 3s\tremaining: 3m 38s\n",
      "768:\tlearn: 0.0232377\ttotal: 12m 4s\tremaining: 3m 37s\n",
      "769:\tlearn: 0.0232352\ttotal: 12m 5s\tremaining: 3m 36s\n",
      "770:\tlearn: 0.0232339\ttotal: 12m 6s\tremaining: 3m 35s\n",
      "771:\tlearn: 0.0232279\ttotal: 12m 7s\tremaining: 3m 34s\n",
      "772:\tlearn: 0.0232230\ttotal: 12m 8s\tremaining: 3m 33s\n",
      "773:\tlearn: 0.0232154\ttotal: 12m 9s\tremaining: 3m 32s\n",
      "774:\tlearn: 0.0232088\ttotal: 12m 10s\tremaining: 3m 32s\n",
      "775:\tlearn: 0.0232042\ttotal: 12m 11s\tremaining: 3m 31s\n",
      "776:\tlearn: 0.0232019\ttotal: 12m 12s\tremaining: 3m 30s\n",
      "777:\tlearn: 0.0231999\ttotal: 12m 13s\tremaining: 3m 29s\n",
      "778:\tlearn: 0.0231962\ttotal: 12m 14s\tremaining: 3m 28s\n",
      "779:\tlearn: 0.0231866\ttotal: 12m 15s\tremaining: 3m 27s\n",
      "780:\tlearn: 0.0231754\ttotal: 12m 16s\tremaining: 3m 26s\n",
      "781:\tlearn: 0.0231699\ttotal: 12m 16s\tremaining: 3m 25s\n",
      "782:\tlearn: 0.0231686\ttotal: 12m 17s\tremaining: 3m 24s\n",
      "783:\tlearn: 0.0231632\ttotal: 12m 18s\tremaining: 3m 23s\n",
      "784:\tlearn: 0.0231616\ttotal: 12m 19s\tremaining: 3m 22s\n",
      "785:\tlearn: 0.0231582\ttotal: 12m 20s\tremaining: 3m 21s\n",
      "786:\tlearn: 0.0231572\ttotal: 12m 21s\tremaining: 3m 20s\n",
      "787:\tlearn: 0.0231558\ttotal: 12m 22s\tremaining: 3m 19s\n",
      "788:\tlearn: 0.0231496\ttotal: 12m 23s\tremaining: 3m 18s\n",
      "789:\tlearn: 0.0231416\ttotal: 12m 24s\tremaining: 3m 17s\n",
      "790:\tlearn: 0.0231370\ttotal: 12m 25s\tremaining: 3m 16s\n",
      "791:\tlearn: 0.0231349\ttotal: 12m 26s\tremaining: 3m 15s\n",
      "792:\tlearn: 0.0231331\ttotal: 12m 27s\tremaining: 3m 15s\n",
      "793:\tlearn: 0.0231281\ttotal: 12m 28s\tremaining: 3m 14s\n",
      "794:\tlearn: 0.0231216\ttotal: 12m 29s\tremaining: 3m 13s\n",
      "795:\tlearn: 0.0231086\ttotal: 12m 30s\tremaining: 3m 12s\n",
      "796:\tlearn: 0.0231049\ttotal: 12m 31s\tremaining: 3m 11s\n",
      "797:\tlearn: 0.0231039\ttotal: 12m 31s\tremaining: 3m 10s\n",
      "798:\tlearn: 0.0231008\ttotal: 12m 32s\tremaining: 3m 9s\n",
      "799:\tlearn: 0.0230994\ttotal: 12m 33s\tremaining: 3m 8s\n",
      "800:\tlearn: 0.0230945\ttotal: 12m 34s\tremaining: 3m 7s\n",
      "801:\tlearn: 0.0230891\ttotal: 12m 36s\tremaining: 3m 6s\n",
      "802:\tlearn: 0.0230881\ttotal: 12m 36s\tremaining: 3m 5s\n",
      "803:\tlearn: 0.0230868\ttotal: 12m 38s\tremaining: 3m 4s\n",
      "804:\tlearn: 0.0230856\ttotal: 12m 39s\tremaining: 3m 3s\n",
      "805:\tlearn: 0.0230819\ttotal: 12m 40s\tremaining: 3m 2s\n",
      "806:\tlearn: 0.0230809\ttotal: 12m 41s\tremaining: 3m 2s\n",
      "807:\tlearn: 0.0230783\ttotal: 12m 42s\tremaining: 3m 1s\n",
      "808:\tlearn: 0.0230739\ttotal: 12m 42s\tremaining: 3m\n",
      "809:\tlearn: 0.0230731\ttotal: 12m 43s\tremaining: 2m 59s\n",
      "810:\tlearn: 0.0230674\ttotal: 12m 44s\tremaining: 2m 58s\n",
      "811:\tlearn: 0.0230581\ttotal: 12m 45s\tremaining: 2m 57s\n",
      "812:\tlearn: 0.0230532\ttotal: 12m 46s\tremaining: 2m 56s\n",
      "813:\tlearn: 0.0230494\ttotal: 12m 47s\tremaining: 2m 55s\n",
      "814:\tlearn: 0.0230436\ttotal: 12m 48s\tremaining: 2m 54s\n",
      "815:\tlearn: 0.0230387\ttotal: 12m 49s\tremaining: 2m 53s\n",
      "816:\tlearn: 0.0230367\ttotal: 12m 50s\tremaining: 2m 52s\n",
      "817:\tlearn: 0.0230358\ttotal: 12m 51s\tremaining: 2m 51s\n",
      "818:\tlearn: 0.0230337\ttotal: 12m 52s\tremaining: 2m 50s\n",
      "819:\tlearn: 0.0230244\ttotal: 12m 53s\tremaining: 2m 49s\n",
      "820:\tlearn: 0.0230196\ttotal: 12m 54s\tremaining: 2m 48s\n",
      "821:\tlearn: 0.0230177\ttotal: 12m 55s\tremaining: 2m 47s\n",
      "822:\tlearn: 0.0230139\ttotal: 12m 56s\tremaining: 2m 46s\n",
      "823:\tlearn: 0.0230071\ttotal: 12m 56s\tremaining: 2m 45s\n",
      "824:\tlearn: 0.0230063\ttotal: 12m 57s\tremaining: 2m 44s\n",
      "825:\tlearn: 0.0230038\ttotal: 12m 58s\tremaining: 2m 44s\n",
      "826:\tlearn: 0.0230000\ttotal: 12m 59s\tremaining: 2m 43s\n",
      "827:\tlearn: 0.0229931\ttotal: 13m\tremaining: 2m 42s\n",
      "828:\tlearn: 0.0229922\ttotal: 13m 1s\tremaining: 2m 41s\n",
      "829:\tlearn: 0.0229863\ttotal: 13m 2s\tremaining: 2m 40s\n",
      "830:\tlearn: 0.0229850\ttotal: 13m 3s\tremaining: 2m 39s\n",
      "831:\tlearn: 0.0229829\ttotal: 13m 4s\tremaining: 2m 38s\n",
      "832:\tlearn: 0.0229783\ttotal: 13m 5s\tremaining: 2m 37s\n",
      "833:\tlearn: 0.0229756\ttotal: 13m 6s\tremaining: 2m 36s\n",
      "834:\tlearn: 0.0229698\ttotal: 13m 7s\tremaining: 2m 35s\n",
      "835:\tlearn: 0.0229555\ttotal: 13m 8s\tremaining: 2m 34s\n",
      "836:\tlearn: 0.0229517\ttotal: 13m 9s\tremaining: 2m 33s\n",
      "837:\tlearn: 0.0229508\ttotal: 13m 10s\tremaining: 2m 32s\n",
      "838:\tlearn: 0.0229488\ttotal: 13m 11s\tremaining: 2m 31s\n",
      "839:\tlearn: 0.0229434\ttotal: 13m 11s\tremaining: 2m 30s\n",
      "840:\tlearn: 0.0229425\ttotal: 13m 12s\tremaining: 2m 29s\n",
      "841:\tlearn: 0.0229382\ttotal: 13m 13s\tremaining: 2m 28s\n",
      "842:\tlearn: 0.0229326\ttotal: 13m 14s\tremaining: 2m 28s\n",
      "843:\tlearn: 0.0229309\ttotal: 13m 15s\tremaining: 2m 27s\n",
      "844:\tlearn: 0.0229260\ttotal: 13m 16s\tremaining: 2m 26s\n",
      "845:\tlearn: 0.0229209\ttotal: 13m 17s\tremaining: 2m 25s\n",
      "846:\tlearn: 0.0229189\ttotal: 13m 18s\tremaining: 2m 24s\n",
      "847:\tlearn: 0.0229159\ttotal: 13m 19s\tremaining: 2m 23s\n",
      "848:\tlearn: 0.0229135\ttotal: 13m 20s\tremaining: 2m 22s\n",
      "849:\tlearn: 0.0229120\ttotal: 13m 21s\tremaining: 2m 21s\n",
      "850:\tlearn: 0.0229107\ttotal: 13m 22s\tremaining: 2m 20s\n",
      "851:\tlearn: 0.0229094\ttotal: 13m 23s\tremaining: 2m 19s\n",
      "852:\tlearn: 0.0229040\ttotal: 13m 23s\tremaining: 2m 18s\n",
      "853:\tlearn: 0.0229028\ttotal: 13m 25s\tremaining: 2m 17s\n",
      "854:\tlearn: 0.0229008\ttotal: 13m 26s\tremaining: 2m 16s\n",
      "855:\tlearn: 0.0228996\ttotal: 13m 27s\tremaining: 2m 15s\n",
      "856:\tlearn: 0.0228943\ttotal: 13m 27s\tremaining: 2m 14s\n",
      "857:\tlearn: 0.0228901\ttotal: 13m 28s\tremaining: 2m 13s\n",
      "858:\tlearn: 0.0228868\ttotal: 13m 29s\tremaining: 2m 12s\n",
      "859:\tlearn: 0.0228852\ttotal: 13m 30s\tremaining: 2m 11s\n",
      "860:\tlearn: 0.0228838\ttotal: 13m 31s\tremaining: 2m 10s\n",
      "861:\tlearn: 0.0228779\ttotal: 13m 32s\tremaining: 2m 10s\n",
      "862:\tlearn: 0.0228771\ttotal: 13m 33s\tremaining: 2m 9s\n",
      "863:\tlearn: 0.0228721\ttotal: 13m 34s\tremaining: 2m 8s\n",
      "864:\tlearn: 0.0228683\ttotal: 13m 35s\tremaining: 2m 7s\n",
      "865:\tlearn: 0.0228644\ttotal: 13m 36s\tremaining: 2m 6s\n",
      "866:\tlearn: 0.0228600\ttotal: 13m 37s\tremaining: 2m 5s\n",
      "867:\tlearn: 0.0228551\ttotal: 13m 37s\tremaining: 2m 4s\n",
      "868:\tlearn: 0.0228535\ttotal: 13m 38s\tremaining: 2m 3s\n",
      "869:\tlearn: 0.0228516\ttotal: 13m 39s\tremaining: 2m 2s\n",
      "870:\tlearn: 0.0228486\ttotal: 13m 40s\tremaining: 2m 1s\n",
      "871:\tlearn: 0.0228450\ttotal: 13m 41s\tremaining: 2m\n",
      "872:\tlearn: 0.0228411\ttotal: 13m 42s\tremaining: 1m 59s\n",
      "873:\tlearn: 0.0228365\ttotal: 13m 43s\tremaining: 1m 58s\n",
      "874:\tlearn: 0.0228357\ttotal: 13m 44s\tremaining: 1m 57s\n",
      "875:\tlearn: 0.0228320\ttotal: 13m 45s\tremaining: 1m 56s\n",
      "876:\tlearn: 0.0228284\ttotal: 13m 46s\tremaining: 1m 55s\n",
      "877:\tlearn: 0.0228272\ttotal: 13m 47s\tremaining: 1m 54s\n",
      "878:\tlearn: 0.0228249\ttotal: 13m 48s\tremaining: 1m 53s\n",
      "879:\tlearn: 0.0228241\ttotal: 13m 48s\tremaining: 1m 53s\n",
      "880:\tlearn: 0.0228189\ttotal: 13m 49s\tremaining: 1m 52s\n",
      "881:\tlearn: 0.0228154\ttotal: 13m 50s\tremaining: 1m 51s\n",
      "882:\tlearn: 0.0228109\ttotal: 13m 51s\tremaining: 1m 50s\n",
      "883:\tlearn: 0.0228075\ttotal: 13m 52s\tremaining: 1m 49s\n",
      "884:\tlearn: 0.0228059\ttotal: 13m 53s\tremaining: 1m 48s\n",
      "885:\tlearn: 0.0227924\ttotal: 13m 54s\tremaining: 1m 47s\n",
      "886:\tlearn: 0.0227889\ttotal: 13m 55s\tremaining: 1m 46s\n",
      "887:\tlearn: 0.0227839\ttotal: 13m 56s\tremaining: 1m 45s\n",
      "888:\tlearn: 0.0227826\ttotal: 13m 57s\tremaining: 1m 44s\n",
      "889:\tlearn: 0.0227734\ttotal: 13m 58s\tremaining: 1m 43s\n",
      "890:\tlearn: 0.0227713\ttotal: 13m 59s\tremaining: 1m 42s\n",
      "891:\tlearn: 0.0227657\ttotal: 14m\tremaining: 1m 41s\n",
      "892:\tlearn: 0.0227648\ttotal: 14m\tremaining: 1m 40s\n",
      "893:\tlearn: 0.0227624\ttotal: 14m 2s\tremaining: 1m 39s\n",
      "894:\tlearn: 0.0227564\ttotal: 14m 3s\tremaining: 1m 38s\n",
      "895:\tlearn: 0.0227494\ttotal: 14m 4s\tremaining: 1m 37s\n",
      "896:\tlearn: 0.0227412\ttotal: 14m 5s\tremaining: 1m 37s\n",
      "897:\tlearn: 0.0227403\ttotal: 14m 5s\tremaining: 1m 36s\n",
      "898:\tlearn: 0.0227338\ttotal: 14m 6s\tremaining: 1m 35s\n",
      "899:\tlearn: 0.0227276\ttotal: 14m 7s\tremaining: 1m 34s\n",
      "900:\tlearn: 0.0227249\ttotal: 14m 8s\tremaining: 1m 33s\n",
      "901:\tlearn: 0.0227052\ttotal: 14m 9s\tremaining: 1m 32s\n",
      "902:\tlearn: 0.0227031\ttotal: 14m 10s\tremaining: 1m 31s\n",
      "903:\tlearn: 0.0227012\ttotal: 14m 11s\tremaining: 1m 30s\n",
      "904:\tlearn: 0.0226974\ttotal: 14m 12s\tremaining: 1m 29s\n",
      "905:\tlearn: 0.0226912\ttotal: 14m 13s\tremaining: 1m 28s\n",
      "906:\tlearn: 0.0226903\ttotal: 14m 14s\tremaining: 1m 27s\n",
      "907:\tlearn: 0.0226883\ttotal: 14m 15s\tremaining: 1m 26s\n",
      "908:\tlearn: 0.0226875\ttotal: 14m 15s\tremaining: 1m 25s\n",
      "909:\tlearn: 0.0226802\ttotal: 14m 16s\tremaining: 1m 24s\n",
      "910:\tlearn: 0.0226793\ttotal: 14m 17s\tremaining: 1m 23s\n",
      "911:\tlearn: 0.0226776\ttotal: 14m 18s\tremaining: 1m 22s\n",
      "912:\tlearn: 0.0226721\ttotal: 14m 19s\tremaining: 1m 21s\n",
      "913:\tlearn: 0.0226701\ttotal: 14m 20s\tremaining: 1m 20s\n",
      "914:\tlearn: 0.0226660\ttotal: 14m 21s\tremaining: 1m 20s\n",
      "915:\tlearn: 0.0226645\ttotal: 14m 22s\tremaining: 1m 19s\n",
      "916:\tlearn: 0.0226613\ttotal: 14m 23s\tremaining: 1m 18s\n",
      "917:\tlearn: 0.0226577\ttotal: 14m 24s\tremaining: 1m 17s\n",
      "918:\tlearn: 0.0226566\ttotal: 14m 25s\tremaining: 1m 16s\n",
      "919:\tlearn: 0.0226457\ttotal: 14m 26s\tremaining: 1m 15s\n",
      "920:\tlearn: 0.0226429\ttotal: 14m 27s\tremaining: 1m 14s\n",
      "921:\tlearn: 0.0226394\ttotal: 14m 28s\tremaining: 1m 13s\n",
      "922:\tlearn: 0.0226358\ttotal: 14m 29s\tremaining: 1m 12s\n",
      "923:\tlearn: 0.0226322\ttotal: 14m 29s\tremaining: 1m 11s\n",
      "924:\tlearn: 0.0226314\ttotal: 14m 30s\tremaining: 1m 10s\n",
      "925:\tlearn: 0.0226287\ttotal: 14m 31s\tremaining: 1m 9s\n",
      "926:\tlearn: 0.0226227\ttotal: 14m 32s\tremaining: 1m 8s\n",
      "927:\tlearn: 0.0226187\ttotal: 14m 33s\tremaining: 1m 7s\n",
      "928:\tlearn: 0.0226168\ttotal: 14m 34s\tremaining: 1m 6s\n",
      "929:\tlearn: 0.0226113\ttotal: 14m 35s\tremaining: 1m 5s\n",
      "930:\tlearn: 0.0226105\ttotal: 14m 36s\tremaining: 1m 4s\n",
      "931:\tlearn: 0.0226075\ttotal: 14m 37s\tremaining: 1m 4s\n",
      "932:\tlearn: 0.0226064\ttotal: 14m 38s\tremaining: 1m 3s\n",
      "933:\tlearn: 0.0225989\ttotal: 14m 39s\tremaining: 1m 2s\n",
      "934:\tlearn: 0.0225956\ttotal: 14m 40s\tremaining: 1m 1s\n",
      "935:\tlearn: 0.0225948\ttotal: 14m 40s\tremaining: 1m\n",
      "936:\tlearn: 0.0225939\ttotal: 14m 41s\tremaining: 59.3s\n",
      "937:\tlearn: 0.0225930\ttotal: 14m 42s\tremaining: 58.3s\n",
      "938:\tlearn: 0.0225921\ttotal: 14m 43s\tremaining: 57.4s\n",
      "939:\tlearn: 0.0225878\ttotal: 14m 44s\tremaining: 56.5s\n",
      "940:\tlearn: 0.0225835\ttotal: 14m 45s\tremaining: 55.5s\n",
      "941:\tlearn: 0.0225790\ttotal: 14m 46s\tremaining: 54.6s\n",
      "942:\tlearn: 0.0225767\ttotal: 14m 47s\tremaining: 53.6s\n",
      "943:\tlearn: 0.0225712\ttotal: 14m 48s\tremaining: 52.7s\n",
      "944:\tlearn: 0.0225694\ttotal: 14m 49s\tremaining: 51.8s\n",
      "945:\tlearn: 0.0225624\ttotal: 14m 50s\tremaining: 50.8s\n",
      "946:\tlearn: 0.0225567\ttotal: 14m 51s\tremaining: 49.9s\n",
      "947:\tlearn: 0.0225513\ttotal: 14m 52s\tremaining: 48.9s\n",
      "948:\tlearn: 0.0225480\ttotal: 14m 53s\tremaining: 48s\n",
      "949:\tlearn: 0.0225346\ttotal: 14m 54s\tremaining: 47.1s\n",
      "950:\tlearn: 0.0225338\ttotal: 14m 54s\tremaining: 46.1s\n",
      "951:\tlearn: 0.0225271\ttotal: 14m 55s\tremaining: 45.2s\n",
      "952:\tlearn: 0.0225263\ttotal: 14m 56s\tremaining: 44.2s\n",
      "953:\tlearn: 0.0225239\ttotal: 14m 57s\tremaining: 43.3s\n",
      "954:\tlearn: 0.0225183\ttotal: 14m 58s\tremaining: 42.4s\n",
      "955:\tlearn: 0.0225175\ttotal: 14m 59s\tremaining: 41.4s\n",
      "956:\tlearn: 0.0225152\ttotal: 15m\tremaining: 40.5s\n",
      "957:\tlearn: 0.0225144\ttotal: 15m 1s\tremaining: 39.5s\n",
      "958:\tlearn: 0.0225131\ttotal: 15m 2s\tremaining: 38.6s\n",
      "959:\tlearn: 0.0225092\ttotal: 15m 3s\tremaining: 37.6s\n",
      "960:\tlearn: 0.0225005\ttotal: 15m 4s\tremaining: 36.7s\n",
      "961:\tlearn: 0.0224933\ttotal: 15m 5s\tremaining: 35.8s\n",
      "962:\tlearn: 0.0224902\ttotal: 15m 6s\tremaining: 34.8s\n",
      "963:\tlearn: 0.0224894\ttotal: 15m 7s\tremaining: 33.9s\n",
      "964:\tlearn: 0.0224885\ttotal: 15m 8s\tremaining: 32.9s\n",
      "965:\tlearn: 0.0224878\ttotal: 15m 9s\tremaining: 32s\n",
      "966:\tlearn: 0.0224824\ttotal: 15m 10s\tremaining: 31.1s\n",
      "967:\tlearn: 0.0224764\ttotal: 15m 11s\tremaining: 30.1s\n",
      "968:\tlearn: 0.0224724\ttotal: 15m 11s\tremaining: 29.2s\n",
      "969:\tlearn: 0.0224672\ttotal: 15m 12s\tremaining: 28.2s\n",
      "970:\tlearn: 0.0224642\ttotal: 15m 13s\tremaining: 27.3s\n",
      "971:\tlearn: 0.0224624\ttotal: 15m 14s\tremaining: 26.3s\n",
      "972:\tlearn: 0.0224519\ttotal: 15m 15s\tremaining: 25.4s\n",
      "973:\tlearn: 0.0224506\ttotal: 15m 16s\tremaining: 24.5s\n",
      "974:\tlearn: 0.0224476\ttotal: 15m 17s\tremaining: 23.5s\n",
      "975:\tlearn: 0.0224468\ttotal: 15m 18s\tremaining: 22.6s\n",
      "976:\tlearn: 0.0224438\ttotal: 15m 19s\tremaining: 21.6s\n",
      "977:\tlearn: 0.0224406\ttotal: 15m 20s\tremaining: 20.7s\n",
      "978:\tlearn: 0.0224397\ttotal: 15m 21s\tremaining: 19.8s\n",
      "979:\tlearn: 0.0224346\ttotal: 15m 22s\tremaining: 18.8s\n",
      "980:\tlearn: 0.0224264\ttotal: 15m 23s\tremaining: 17.9s\n",
      "981:\tlearn: 0.0224200\ttotal: 15m 24s\tremaining: 16.9s\n",
      "982:\tlearn: 0.0224185\ttotal: 15m 25s\tremaining: 16s\n",
      "983:\tlearn: 0.0224066\ttotal: 15m 26s\tremaining: 15.1s\n",
      "984:\tlearn: 0.0224044\ttotal: 15m 27s\tremaining: 14.1s\n",
      "985:\tlearn: 0.0223996\ttotal: 15m 28s\tremaining: 13.2s\n",
      "986:\tlearn: 0.0223947\ttotal: 15m 29s\tremaining: 12.2s\n",
      "987:\tlearn: 0.0223903\ttotal: 15m 30s\tremaining: 11.3s\n",
      "988:\tlearn: 0.0223876\ttotal: 15m 31s\tremaining: 10.4s\n",
      "989:\tlearn: 0.0223839\ttotal: 15m 32s\tremaining: 9.41s\n",
      "990:\tlearn: 0.0223793\ttotal: 15m 33s\tremaining: 8.47s\n",
      "991:\tlearn: 0.0223745\ttotal: 15m 34s\tremaining: 7.53s\n",
      "992:\tlearn: 0.0223703\ttotal: 15m 34s\tremaining: 6.59s\n",
      "993:\tlearn: 0.0223685\ttotal: 15m 35s\tremaining: 5.65s\n",
      "994:\tlearn: 0.0223597\ttotal: 15m 36s\tremaining: 4.71s\n",
      "995:\tlearn: 0.0223589\ttotal: 15m 37s\tremaining: 3.77s\n",
      "996:\tlearn: 0.0223534\ttotal: 15m 38s\tremaining: 2.82s\n",
      "997:\tlearn: 0.0223486\ttotal: 15m 39s\tremaining: 1.88s\n",
      "998:\tlearn: 0.0223459\ttotal: 15m 40s\tremaining: 941ms\n",
      "999:\tlearn: 0.0223442\ttotal: 15m 41s\tremaining: 0us\n",
      "{'mean_squared_error': 0.0008044268320427006, 'mean_absolute_percentage_error': 66791268120.69517, 'r2': 0.8007101485336192}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Assuming vectorizer is defined outside the snippet\n",
    "\n",
    "# Define a ColumnTransformer to handle both text and numeric features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(), 'body_preprocessed'),  # Text feature\n",
    "        # Add other numeric features here if any\n",
    "        # ('numeric', 'passthrough', ['numeric_feature1', 'numeric_feature2']),\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep the remaining columns as they are\n",
    ")\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_merged.drop(['date', 'symbol', 'weekly_return'], axis=1),\n",
    "    df_merged[\"weekly_return\"],\n",
    "    test_size=0.3\n",
    ")\n",
    "\n",
    "# Preprocess data\n",
    "X_train_processed = pipeline.fit_transform(X_train)\n",
    "X_test_processed = pipeline.transform(X_test)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = CatBoostRegressor()\n",
    "model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_processed)\n",
    "\n",
    "# Calculate scores\n",
    "scores = {\n",
    "    'mean_squared_error': mean_squared_error(y_test, y_pred),\n",
    "    'mean_absolute_percentage_error': mean_absolute_percentage_error(y_test, y_pred),\n",
    "    'r2': r2_score(y_test, y_pred),\n",
    "}\n",
    "print(scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
